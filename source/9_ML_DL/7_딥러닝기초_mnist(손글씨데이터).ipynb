{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T04:20:08.664321Z",
     "start_time": "2021-03-24T04:20:08.648364Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist  # mnist 데이터셋\n",
    "import tensorflow.keras.utils as utils #원핫인코딩\n",
    "from tensorflow.keras.models import Sequential #모델\n",
    "from tensorflow.keras.layers import Dense, Activation # Layer add \n",
    "from matplotlib import pyplot as plt \n",
    "import numpy as np\n",
    "np.random.seed(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# < 1> 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:03:24.394808Z",
     "start_time": "2021-03-23T07:03:23.973930Z"
    }
   },
   "outputs": [],
   "source": [
    "# 1. 데이터 셋 준비하기 \n",
    "# 훈련셋, 검증셋 분리 \n",
    "(X_train, Y_train), (X_test,Y_test) = mnist.load_data()    # X_train 독립변수, Y_train 종속변수  #mnist는 패키지안에 들어있다\n",
    "                                                           # mnist.load_data() == 알아서 나눠서 출력하는 메소드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:03:24.766346Z",
     "start_time": "2021-03-23T07:03:24.756372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,Y_train.shape,X_test.shape,Y_test.shape  #60000면 28행 28열   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:05:36.045223Z",
     "start_time": "2021-03-23T07:05:36.037243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:07:28.342853Z",
     "start_time": "2021-03-23T07:07:27.921103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec863a1b20>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])  #위에서 숫자 있는게 여기서 노랑부분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:08:55.673598Z",
     "start_time": "2021-03-23T07:08:55.662629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#결과는 Y_train에 있다.  컴퓨터에게 위위 데이터를 알려줌\n",
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:15:03.341607Z",
     "start_time": "2021-03-23T07:15:03.332630Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 검증셋 분리  (X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]  #50000개부터 끝까지 \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:15:04.759814Z",
     "start_time": "2021-03-23T07:15:04.749848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 28, 28), (50000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋 - 학습할 때 사용      (accuracy높고,loss가 낮고)\n",
    "X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:15:40.742025Z",
     "start_time": "2021-03-23T07:15:40.730058Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검증셋 - 학습할 때 사용 \n",
    "len(X_val),len(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:15:54.266510Z",
     "start_time": "2021-03-23T07:15:54.247560Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 훈련셋 - 모델 평가할 때 사용 \n",
    "len(X_test), len(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결국 2줄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련셋, 검증셋 분리 \n",
    "(X_train, Y_train), (X_test,Y_test) = mnist.load_data()   \n",
    "\n",
    "X_val = X_train[50000:]  #50000개부터 끝까지 \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalize하기 위해 색상값으로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:24:50.997253Z",
     "start_time": "2021-03-23T07:24:50.850599Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(50000,784).astype('float32')/255.0    #28x28=784********************\n",
    "X_val = X_val.reshape(10000,784).astype('float32')/255.0  # '데이터 784개' 한꺼번에 1차원으로 들어가  *******************************************\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0    #255.0는 색상값 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:25:03.952819Z",
     "start_time": "2021-03-23T07:25:03.933868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (10000, 784), (10000, 784))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:53:15.140666Z",
     "start_time": "2021-03-23T07:53:15.115732Z"
    }
   },
   "outputs": [],
   "source": [
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴 \n",
    "#1부터50000까지 700개를 random하게 뽑자\n",
    "train_rand_idxs = np.random.choice(50000,700) #50000개중 700개를 뽑음\n",
    "val_rand_idxs = np.random.choice(10000,300)  #10000개 중 300개를 뽑아라   0부터99999까지 300개의 수   random.choice를 쓴 이유: 중복되면 안됨\n",
    "                                                #학습하는데 시간 줄여볼려고\n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "\n",
    "#300개의 index만 사용\n",
    "X_val = X_val[val_rand_idxs]      #X_val, Y_val이 같아야   \n",
    "Y_val = Y_val[val_rand_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:53:17.014242Z",
     "start_time": "2021-03-23T07:53:16.872454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec851a8c40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28,28))      #.reshap(28,28)하면 화면출력해서 그림 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:53:20.280381Z",
     "start_time": "2021-03-23T07:53:20.271380Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:53:22.086818Z",
     "start_time": "2021-03-23T07:53:22.069863Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 9, 6, 0, 4, 6, 4, 9, 9, 1, 9, 8, 1, 9, 0, 1, 5, 1, 9],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:54:37.207330Z",
     "start_time": "2021-03-23T07:54:37.198354Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700,), (300,), (10000,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape,Y_val.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:56:02.940189Z",
     "start_time": "2021-03-23T07:56:02.931213Z"
    }
   },
   "outputs": [],
   "source": [
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "# 0  => 1 0 0 0 0 0 0 0 0 0\n",
    "# 3 => 0 0 0 1 0 0 0 0 0 0 \n",
    "Y_train =  utils.to_categorical(Y_train)\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:56:04.073281Z",
     "start_time": "2021-03-23T07:56:04.058321Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 10), (300, 10), (10000, 10))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, Y_val.shape,Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T07:56:14.603096Z",
     "start_time": "2021-03-23T07:56:14.598128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]\n",
    "# 데이터 전치리 끝 #######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 모델 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:08:04.624337Z",
     "start_time": "2021-03-23T08:08:04.531382Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))  #layer output 2개 \n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 모델 학습과정 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:08:06.262865Z",
     "start_time": "2021-03-23T08:08:06.243915Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"sgd\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 모델 학습 시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:13:44.478261Z",
     "start_time": "2021-03-23T08:12:16.448616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 1s 4ms/step - loss: 2.2746 - accuracy: 0.1115 - val_loss: 2.2478 - val_accuracy: 0.1033\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2240 - accuracy: 0.1493 - val_loss: 2.1927 - val_accuracy: 0.1333\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1745 - accuracy: 0.1595 - val_loss: 2.1448 - val_accuracy: 0.1767\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1013 - accuracy: 0.2380 - val_loss: 2.1116 - val_accuracy: 0.2500\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0754 - accuracy: 0.2698 - val_loss: 2.0769 - val_accuracy: 0.2767\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0295 - accuracy: 0.3034 - val_loss: 2.0451 - val_accuracy: 0.2867\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9890 - accuracy: 0.2897 - val_loss: 2.0263 - val_accuracy: 0.2833\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9756 - accuracy: 0.3093 - val_loss: 1.9895 - val_accuracy: 0.2833\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9560 - accuracy: 0.3019 - val_loss: 1.9701 - val_accuracy: 0.2933\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8913 - accuracy: 0.3183 - val_loss: 1.9489 - val_accuracy: 0.2867\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9223 - accuracy: 0.3131 - val_loss: 1.9218 - val_accuracy: 0.2933\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8481 - accuracy: 0.3423 - val_loss: 1.9014 - val_accuracy: 0.3033\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8607 - accuracy: 0.3242 - val_loss: 1.8917 - val_accuracy: 0.2933\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8704 - accuracy: 0.3070 - val_loss: 1.8711 - val_accuracy: 0.3000\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8032 - accuracy: 0.3423 - val_loss: 1.8569 - val_accuracy: 0.3033\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7997 - accuracy: 0.3347 - val_loss: 1.8492 - val_accuracy: 0.3067\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7562 - accuracy: 0.3495 - val_loss: 1.8141 - val_accuracy: 0.3167\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7103 - accuracy: 0.3800 - val_loss: 1.8059 - val_accuracy: 0.3033\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7484 - accuracy: 0.3539 - val_loss: 1.7977 - val_accuracy: 0.3200\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7142 - accuracy: 0.3855 - val_loss: 1.7713 - val_accuracy: 0.3133\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6612 - accuracy: 0.4052 - val_loss: 1.7616 - val_accuracy: 0.3200\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6393 - accuracy: 0.4234 - val_loss: 1.7474 - val_accuracy: 0.3267\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6631 - accuracy: 0.4003 - val_loss: 1.7344 - val_accuracy: 0.3267\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6145 - accuracy: 0.4231 - val_loss: 1.7280 - val_accuracy: 0.3333\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6426 - accuracy: 0.3938 - val_loss: 1.7259 - val_accuracy: 0.3267\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6395 - accuracy: 0.3748 - val_loss: 1.7057 - val_accuracy: 0.3400\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6031 - accuracy: 0.4137 - val_loss: 1.6959 - val_accuracy: 0.3567\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6123 - accuracy: 0.4026 - val_loss: 1.6824 - val_accuracy: 0.3633\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5767 - accuracy: 0.4240 - val_loss: 1.6718 - val_accuracy: 0.3633\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5903 - accuracy: 0.4285 - val_loss: 1.6734 - val_accuracy: 0.3700\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5771 - accuracy: 0.4174 - val_loss: 1.6528 - val_accuracy: 0.3733\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5585 - accuracy: 0.4454 - val_loss: 1.6534 - val_accuracy: 0.3833\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5539 - accuracy: 0.4729 - val_loss: 1.6414 - val_accuracy: 0.3800\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5482 - accuracy: 0.4439 - val_loss: 1.6449 - val_accuracy: 0.3633\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5684 - accuracy: 0.4328 - val_loss: 1.6270 - val_accuracy: 0.3800\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5119 - accuracy: 0.4440 - val_loss: 1.6168 - val_accuracy: 0.4067\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - ETA: 0s - loss: 1.6683 - accuracy: 0.40 - 0s 1ms/step - loss: 1.5259 - accuracy: 0.4456 - val_loss: 1.6160 - val_accuracy: 0.4000\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5107 - accuracy: 0.4190 - val_loss: 1.6133 - val_accuracy: 0.3867\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4729 - accuracy: 0.4617 - val_loss: 1.6055 - val_accuracy: 0.4133\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4787 - accuracy: 0.4332 - val_loss: 1.5924 - val_accuracy: 0.4067\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4712 - accuracy: 0.4690 - val_loss: 1.5980 - val_accuracy: 0.4067\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4767 - accuracy: 0.4389 - val_loss: 1.5870 - val_accuracy: 0.4067\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4170 - accuracy: 0.4684 - val_loss: 1.5829 - val_accuracy: 0.4033\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4451 - accuracy: 0.4493 - val_loss: 1.5740 - val_accuracy: 0.4100\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4195 - accuracy: 0.4567 - val_loss: 1.5708 - val_accuracy: 0.4067\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4156 - accuracy: 0.4730 - val_loss: 1.5739 - val_accuracy: 0.4100\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4417 - accuracy: 0.4811 - val_loss: 1.5644 - val_accuracy: 0.3967\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4334 - accuracy: 0.4302 - val_loss: 1.5609 - val_accuracy: 0.4133\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4256 - accuracy: 0.4569 - val_loss: 1.5578 - val_accuracy: 0.4100\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4162 - accuracy: 0.4452 - val_loss: 1.5506 - val_accuracy: 0.4100\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3549 - accuracy: 0.4689 - val_loss: 1.5477 - val_accuracy: 0.4200\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4070 - accuracy: 0.4462 - val_loss: 1.5458 - val_accuracy: 0.4067\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3986 - accuracy: 0.4407 - val_loss: 1.5490 - val_accuracy: 0.4000\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3509 - accuracy: 0.4867 - val_loss: 1.5440 - val_accuracy: 0.4133\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3587 - accuracy: 0.4417 - val_loss: 1.5365 - val_accuracy: 0.4100\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3482 - accuracy: 0.4772 - val_loss: 1.5400 - val_accuracy: 0.4100\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3524 - accuracy: 0.4717 - val_loss: 1.5388 - val_accuracy: 0.4100\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3293 - accuracy: 0.5024 - val_loss: 1.5337 - val_accuracy: 0.4167\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3747 - accuracy: 0.4562 - val_loss: 1.5364 - val_accuracy: 0.4133\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3641 - accuracy: 0.4715 - val_loss: 1.5354 - val_accuracy: 0.4300\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3416 - accuracy: 0.4864 - val_loss: 1.5251 - val_accuracy: 0.4233\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2607 - accuracy: 0.5208 - val_loss: 1.5262 - val_accuracy: 0.4267\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3049 - accuracy: 0.5004 - val_loss: 1.5534 - val_accuracy: 0.4133\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2839 - accuracy: 0.5131 - val_loss: 1.5276 - val_accuracy: 0.4433\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2949 - accuracy: 0.5282 - val_loss: 1.5203 - val_accuracy: 0.4367\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3061 - accuracy: 0.5083 - val_loss: 1.5183 - val_accuracy: 0.4367\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2429 - accuracy: 0.5394 - val_loss: 1.5273 - val_accuracy: 0.4433\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3357 - accuracy: 0.4626 - val_loss: 1.5231 - val_accuracy: 0.4333\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2703 - accuracy: 0.5097 - val_loss: 1.5148 - val_accuracy: 0.4433\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3179 - accuracy: 0.4819 - val_loss: 1.5099 - val_accuracy: 0.4533\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3251 - accuracy: 0.4741 - val_loss: 1.5201 - val_accuracy: 0.4400\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2978 - accuracy: 0.4941 - val_loss: 1.5268 - val_accuracy: 0.4433\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3497 - accuracy: 0.5058 - val_loss: 1.5109 - val_accuracy: 0.4500\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2473 - accuracy: 0.5416 - val_loss: 1.5134 - val_accuracy: 0.4533\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2734 - accuracy: 0.5197 - val_loss: 1.5136 - val_accuracy: 0.4633\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2788 - accuracy: 0.5434 - val_loss: 1.5143 - val_accuracy: 0.4600\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2299 - accuracy: 0.5620 - val_loss: 1.4986 - val_accuracy: 0.4767\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2270 - accuracy: 0.5528 - val_loss: 1.5058 - val_accuracy: 0.4733\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2592 - accuracy: 0.5056 - val_loss: 1.5022 - val_accuracy: 0.4800\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2313 - accuracy: 0.5573 - val_loss: 1.4951 - val_accuracy: 0.4800\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2446 - accuracy: 0.5205 - val_loss: 1.5140 - val_accuracy: 0.4700\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2133 - accuracy: 0.5398 - val_loss: 1.5022 - val_accuracy: 0.4800\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2267 - accuracy: 0.5535 - val_loss: 1.4980 - val_accuracy: 0.4900\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2079 - accuracy: 0.5457 - val_loss: 1.4974 - val_accuracy: 0.4800\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2336 - accuracy: 0.5657 - val_loss: 1.4933 - val_accuracy: 0.4833\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2030 - accuracy: 0.5462 - val_loss: 1.4916 - val_accuracy: 0.4867\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2028 - accuracy: 0.5565 - val_loss: 1.4867 - val_accuracy: 0.5100\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2098 - accuracy: 0.5608 - val_loss: 1.4883 - val_accuracy: 0.5000\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1773 - accuracy: 0.5708 - val_loss: 1.4868 - val_accuracy: 0.5000\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1776 - accuracy: 0.6034 - val_loss: 1.4833 - val_accuracy: 0.5067\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1880 - accuracy: 0.5763 - val_loss: 1.4843 - val_accuracy: 0.5100\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1859 - accuracy: 0.5771 - val_loss: 1.4937 - val_accuracy: 0.5000\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1601 - accuracy: 0.5788 - val_loss: 1.4732 - val_accuracy: 0.5133\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1590 - accuracy: 0.6070 - val_loss: 1.4885 - val_accuracy: 0.5000\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1422 - accuracy: 0.6072 - val_loss: 1.4820 - val_accuracy: 0.5167\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1777 - accuracy: 0.5862 - val_loss: 1.4837 - val_accuracy: 0.5100\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1356 - accuracy: 0.5920 - val_loss: 1.4779 - val_accuracy: 0.5100\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1903 - accuracy: 0.5702 - val_loss: 1.4777 - val_accuracy: 0.5167\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1540 - accuracy: 0.5731 - val_loss: 1.4834 - val_accuracy: 0.5133\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2059 - accuracy: 0.5418 - val_loss: 1.4766 - val_accuracy: 0.5167\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1415 - accuracy: 0.5914 - val_loss: 1.4794 - val_accuracy: 0.5100\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1454 - accuracy: 0.5684 - val_loss: 1.4760 - val_accuracy: 0.5233\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1561 - accuracy: 0.5844 - val_loss: 1.4821 - val_accuracy: 0.5100\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1368 - accuracy: 0.5853 - val_loss: 1.4762 - val_accuracy: 0.5133\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1349 - accuracy: 0.5679 - val_loss: 1.4855 - val_accuracy: 0.5167\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1447 - accuracy: 0.5837 - val_loss: 1.4843 - val_accuracy: 0.5200\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1718 - accuracy: 0.5880 - val_loss: 1.4752 - val_accuracy: 0.5200\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0947 - accuracy: 0.6058 - val_loss: 1.4753 - val_accuracy: 0.5200\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1195 - accuracy: 0.5775 - val_loss: 1.4690 - val_accuracy: 0.5200\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1227 - accuracy: 0.6083 - val_loss: 1.4705 - val_accuracy: 0.5133\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1308 - accuracy: 0.5827 - val_loss: 1.4808 - val_accuracy: 0.5200\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1083 - accuracy: 0.5963 - val_loss: 1.4915 - val_accuracy: 0.5233\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1169 - accuracy: 0.5977 - val_loss: 1.4900 - val_accuracy: 0.5233\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1357 - accuracy: 0.5991 - val_loss: 1.4893 - val_accuracy: 0.5133\n",
      "Epoch 115/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1194 - accuracy: 0.5734 - val_loss: 1.4817 - val_accuracy: 0.5167\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0909 - accuracy: 0.6029 - val_loss: 1.4820 - val_accuracy: 0.5100\n",
      "Epoch 117/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0641 - accuracy: 0.5943 - val_loss: 1.4816 - val_accuracy: 0.5167\n",
      "Epoch 118/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0897 - accuracy: 0.6062 - val_loss: 1.4813 - val_accuracy: 0.5167\n",
      "Epoch 119/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0885 - accuracy: 0.6157 - val_loss: 1.4788 - val_accuracy: 0.5200\n",
      "Epoch 120/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1264 - accuracy: 0.6033 - val_loss: 1.4865 - val_accuracy: 0.5133\n",
      "Epoch 121/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0764 - accuracy: 0.6158 - val_loss: 1.4846 - val_accuracy: 0.5200\n",
      "Epoch 122/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1127 - accuracy: 0.6152 - val_loss: 1.5036 - val_accuracy: 0.5100\n",
      "Epoch 123/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1044 - accuracy: 0.6185 - val_loss: 1.4980 - val_accuracy: 0.5200\n",
      "Epoch 124/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0737 - accuracy: 0.5902 - val_loss: 1.4912 - val_accuracy: 0.5200\n",
      "Epoch 125/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0999 - accuracy: 0.6118 - val_loss: 1.4986 - val_accuracy: 0.5200\n",
      "Epoch 126/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1079 - accuracy: 0.6056 - val_loss: 1.4984 - val_accuracy: 0.5233\n",
      "Epoch 127/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0681 - accuracy: 0.6284 - val_loss: 1.4843 - val_accuracy: 0.5100\n",
      "Epoch 128/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0887 - accuracy: 0.6300 - val_loss: 1.4820 - val_accuracy: 0.5267\n",
      "Epoch 129/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1046 - accuracy: 0.5834 - val_loss: 1.5056 - val_accuracy: 0.5200\n",
      "Epoch 130/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0863 - accuracy: 0.6193 - val_loss: 1.4956 - val_accuracy: 0.5233\n",
      "Epoch 131/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0424 - accuracy: 0.6332 - val_loss: 1.4993 - val_accuracy: 0.5233\n",
      "Epoch 132/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0510 - accuracy: 0.6346 - val_loss: 1.5232 - val_accuracy: 0.5167\n",
      "Epoch 133/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0566 - accuracy: 0.6043 - val_loss: 1.5042 - val_accuracy: 0.5267\n",
      "Epoch 134/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0545 - accuracy: 0.6282 - val_loss: 1.4990 - val_accuracy: 0.5233\n",
      "Epoch 135/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0504 - accuracy: 0.6187 - val_loss: 1.5049 - val_accuracy: 0.5233\n",
      "Epoch 136/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0185 - accuracy: 0.6610 - val_loss: 1.5062 - val_accuracy: 0.5167\n",
      "Epoch 137/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9934 - accuracy: 0.6714 - val_loss: 1.4971 - val_accuracy: 0.4900\n",
      "Epoch 138/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0375 - accuracy: 0.6386 - val_loss: 1.5056 - val_accuracy: 0.5167\n",
      "Epoch 139/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0291 - accuracy: 0.6294 - val_loss: 1.5039 - val_accuracy: 0.5133\n",
      "Epoch 140/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0477 - accuracy: 0.6034 - val_loss: 1.5124 - val_accuracy: 0.5233\n",
      "Epoch 141/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0134 - accuracy: 0.6557 - val_loss: 1.5115 - val_accuracy: 0.5233\n",
      "Epoch 142/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0482 - accuracy: 0.6094 - val_loss: 1.5216 - val_accuracy: 0.5133\n",
      "Epoch 143/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0289 - accuracy: 0.6355 - val_loss: 1.5334 - val_accuracy: 0.4933\n",
      "Epoch 144/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0430 - accuracy: 0.6132 - val_loss: 1.5198 - val_accuracy: 0.4967\n",
      "Epoch 145/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0542 - accuracy: 0.6357 - val_loss: 1.5191 - val_accuracy: 0.5067\n",
      "Epoch 146/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0355 - accuracy: 0.6205 - val_loss: 1.5175 - val_accuracy: 0.4867\n",
      "Epoch 147/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0568 - accuracy: 0.6176 - val_loss: 1.5206 - val_accuracy: 0.5200\n",
      "Epoch 148/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0724 - accuracy: 0.5933 - val_loss: 1.5288 - val_accuracy: 0.5200\n",
      "Epoch 149/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0231 - accuracy: 0.6362 - val_loss: 1.5108 - val_accuracy: 0.5133\n",
      "Epoch 150/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9947 - accuracy: 0.6670 - val_loss: 1.5107 - val_accuracy: 0.5100\n",
      "Epoch 151/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9867 - accuracy: 0.6793 - val_loss: 1.5280 - val_accuracy: 0.5200\n",
      "Epoch 152/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0266 - accuracy: 0.6297 - val_loss: 1.5268 - val_accuracy: 0.5000\n",
      "Epoch 153/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0149 - accuracy: 0.6036 - val_loss: 1.5308 - val_accuracy: 0.5167\n",
      "Epoch 154/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9929 - accuracy: 0.6389 - val_loss: 1.5281 - val_accuracy: 0.4967\n",
      "Epoch 155/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0258 - accuracy: 0.6357 - val_loss: 1.5302 - val_accuracy: 0.5000\n",
      "Epoch 156/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0501 - accuracy: 0.6214 - val_loss: 1.5477 - val_accuracy: 0.5033\n",
      "Epoch 157/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9908 - accuracy: 0.6487 - val_loss: 1.5232 - val_accuracy: 0.5067\n",
      "Epoch 158/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0320 - accuracy: 0.6361 - val_loss: 1.5204 - val_accuracy: 0.5033\n",
      "Epoch 159/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9943 - accuracy: 0.6408 - val_loss: 1.5403 - val_accuracy: 0.5000\n",
      "Epoch 160/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0061 - accuracy: 0.6383 - val_loss: 1.5413 - val_accuracy: 0.4967\n",
      "Epoch 161/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0381 - accuracy: 0.6002 - val_loss: 1.5290 - val_accuracy: 0.5100\n",
      "Epoch 162/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9876 - accuracy: 0.6454 - val_loss: 1.5435 - val_accuracy: 0.5067\n",
      "Epoch 163/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0116 - accuracy: 0.6311 - val_loss: 1.5488 - val_accuracy: 0.5000\n",
      "Epoch 164/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0548 - accuracy: 0.6046 - val_loss: 1.5598 - val_accuracy: 0.5000\n",
      "Epoch 165/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0226 - accuracy: 0.6264 - val_loss: 1.5403 - val_accuracy: 0.5033\n",
      "Epoch 166/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0016 - accuracy: 0.6470 - val_loss: 1.5553 - val_accuracy: 0.5133\n",
      "Epoch 167/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0394 - accuracy: 0.6061 - val_loss: 1.5337 - val_accuracy: 0.5167\n",
      "Epoch 168/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0069 - accuracy: 0.6477 - val_loss: 1.5521 - val_accuracy: 0.4933\n",
      "Epoch 169/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0051 - accuracy: 0.6542 - val_loss: 1.5379 - val_accuracy: 0.5167\n",
      "Epoch 170/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9575 - accuracy: 0.6714 - val_loss: 1.5410 - val_accuracy: 0.5033\n",
      "Epoch 171/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0077 - accuracy: 0.6422 - val_loss: 1.5567 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0155 - accuracy: 0.6419 - val_loss: 1.5488 - val_accuracy: 0.4933\n",
      "Epoch 173/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0324 - accuracy: 0.6339 - val_loss: 1.5595 - val_accuracy: 0.5033\n",
      "Epoch 174/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9474 - accuracy: 0.6494 - val_loss: 1.5509 - val_accuracy: 0.5067\n",
      "Epoch 175/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9785 - accuracy: 0.6520 - val_loss: 1.5671 - val_accuracy: 0.4967\n",
      "Epoch 176/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9931 - accuracy: 0.6373 - val_loss: 1.5582 - val_accuracy: 0.5000\n",
      "Epoch 177/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0335 - accuracy: 0.5948 - val_loss: 1.5775 - val_accuracy: 0.5000\n",
      "Epoch 178/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9641 - accuracy: 0.6494 - val_loss: 1.5890 - val_accuracy: 0.5033\n",
      "Epoch 179/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0346 - accuracy: 0.6290 - val_loss: 1.5725 - val_accuracy: 0.5000\n",
      "Epoch 180/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9686 - accuracy: 0.6729 - val_loss: 1.5687 - val_accuracy: 0.4933\n",
      "Epoch 181/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9970 - accuracy: 0.6433 - val_loss: 1.5617 - val_accuracy: 0.5000\n",
      "Epoch 182/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9687 - accuracy: 0.6583 - val_loss: 1.5776 - val_accuracy: 0.4967\n",
      "Epoch 183/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9834 - accuracy: 0.6513 - val_loss: 1.5790 - val_accuracy: 0.5000\n",
      "Epoch 184/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9678 - accuracy: 0.6564 - val_loss: 1.5686 - val_accuracy: 0.5000\n",
      "Epoch 185/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9625 - accuracy: 0.6278 - val_loss: 1.5912 - val_accuracy: 0.5000\n",
      "Epoch 186/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0020 - accuracy: 0.6227 - val_loss: 1.5818 - val_accuracy: 0.5000\n",
      "Epoch 187/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9514 - accuracy: 0.6598 - val_loss: 1.5859 - val_accuracy: 0.5033\n",
      "Epoch 188/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9168 - accuracy: 0.6776 - val_loss: 1.5732 - val_accuracy: 0.5033\n",
      "Epoch 189/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0168 - accuracy: 0.6217 - val_loss: 1.5946 - val_accuracy: 0.4900\n",
      "Epoch 190/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9830 - accuracy: 0.6341 - val_loss: 1.5797 - val_accuracy: 0.4933\n",
      "Epoch 191/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9536 - accuracy: 0.6684 - val_loss: 1.5907 - val_accuracy: 0.5033\n",
      "Epoch 192/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9516 - accuracy: 0.6277 - val_loss: 1.5860 - val_accuracy: 0.5000\n",
      "Epoch 193/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9672 - accuracy: 0.6552 - val_loss: 1.5830 - val_accuracy: 0.5033\n",
      "Epoch 194/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9159 - accuracy: 0.6887 - val_loss: 1.5777 - val_accuracy: 0.5100\n",
      "Epoch 195/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9674 - accuracy: 0.6351 - val_loss: 1.5791 - val_accuracy: 0.5133\n",
      "Epoch 196/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9329 - accuracy: 0.6601 - val_loss: 1.6125 - val_accuracy: 0.5033\n",
      "Epoch 197/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9690 - accuracy: 0.6442 - val_loss: 1.6177 - val_accuracy: 0.4933\n",
      "Epoch 198/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9444 - accuracy: 0.6672 - val_loss: 1.5878 - val_accuracy: 0.5000\n",
      "Epoch 199/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9579 - accuracy: 0.6536 - val_loss: 1.5696 - val_accuracy: 0.5033\n",
      "Epoch 200/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9810 - accuracy: 0.6479 - val_loss: 1.6126 - val_accuracy: 0.5033\n",
      "Epoch 201/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9941 - accuracy: 0.6265 - val_loss: 1.6082 - val_accuracy: 0.5133\n",
      "Epoch 202/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9378 - accuracy: 0.6482 - val_loss: 1.5866 - val_accuracy: 0.5033\n",
      "Epoch 203/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9620 - accuracy: 0.6668 - val_loss: 1.6091 - val_accuracy: 0.4967\n",
      "Epoch 204/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9441 - accuracy: 0.6664 - val_loss: 1.5987 - val_accuracy: 0.5067\n",
      "Epoch 205/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9558 - accuracy: 0.6722 - val_loss: 1.6172 - val_accuracy: 0.4933\n",
      "Epoch 206/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9574 - accuracy: 0.6488 - val_loss: 1.6137 - val_accuracy: 0.4967\n",
      "Epoch 207/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9677 - accuracy: 0.6350 - val_loss: 1.5949 - val_accuracy: 0.5067\n",
      "Epoch 208/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9492 - accuracy: 0.6270 - val_loss: 1.6067 - val_accuracy: 0.4967\n",
      "Epoch 209/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9519 - accuracy: 0.6802 - val_loss: 1.6118 - val_accuracy: 0.5000\n",
      "Epoch 210/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9924 - accuracy: 0.6571 - val_loss: 1.5998 - val_accuracy: 0.4967\n",
      "Epoch 211/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9421 - accuracy: 0.6325 - val_loss: 1.6163 - val_accuracy: 0.4933\n",
      "Epoch 212/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9608 - accuracy: 0.6559 - val_loss: 1.6271 - val_accuracy: 0.4967\n",
      "Epoch 213/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9238 - accuracy: 0.6342 - val_loss: 1.6202 - val_accuracy: 0.4933\n",
      "Epoch 214/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9795 - accuracy: 0.6303 - val_loss: 1.6274 - val_accuracy: 0.4933\n",
      "Epoch 215/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9307 - accuracy: 0.6483 - val_loss: 1.6373 - val_accuracy: 0.4900\n",
      "Epoch 216/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9273 - accuracy: 0.6554 - val_loss: 1.6253 - val_accuracy: 0.4900\n",
      "Epoch 217/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9293 - accuracy: 0.6905 - val_loss: 1.6271 - val_accuracy: 0.4900\n",
      "Epoch 218/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9116 - accuracy: 0.6774 - val_loss: 1.6283 - val_accuracy: 0.4900\n",
      "Epoch 219/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8948 - accuracy: 0.6643 - val_loss: 1.6322 - val_accuracy: 0.4967\n",
      "Epoch 220/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9063 - accuracy: 0.6827 - val_loss: 1.6211 - val_accuracy: 0.4900\n",
      "Epoch 221/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9316 - accuracy: 0.6409 - val_loss: 1.6115 - val_accuracy: 0.4967\n",
      "Epoch 222/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9170 - accuracy: 0.6668 - val_loss: 1.6257 - val_accuracy: 0.4900\n",
      "Epoch 223/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8972 - accuracy: 0.6861 - val_loss: 1.6634 - val_accuracy: 0.4900\n",
      "Epoch 224/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9206 - accuracy: 0.6652 - val_loss: 1.6138 - val_accuracy: 0.4967\n",
      "Epoch 225/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8967 - accuracy: 0.6801 - val_loss: 1.6395 - val_accuracy: 0.5000\n",
      "Epoch 226/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9165 - accuracy: 0.6796 - val_loss: 1.6474 - val_accuracy: 0.4867\n",
      "Epoch 227/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9088 - accuracy: 0.6724 - val_loss: 1.6296 - val_accuracy: 0.4967\n",
      "Epoch 228/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9157 - accuracy: 0.6622 - val_loss: 1.6445 - val_accuracy: 0.4933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9486 - accuracy: 0.6851 - val_loss: 1.6327 - val_accuracy: 0.4933\n",
      "Epoch 230/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8687 - accuracy: 0.6670 - val_loss: 1.6766 - val_accuracy: 0.4900\n",
      "Epoch 231/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9161 - accuracy: 0.6844 - val_loss: 1.6425 - val_accuracy: 0.4900\n",
      "Epoch 232/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9263 - accuracy: 0.6579 - val_loss: 1.6695 - val_accuracy: 0.4900\n",
      "Epoch 233/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9437 - accuracy: 0.6672 - val_loss: 1.6477 - val_accuracy: 0.4867\n",
      "Epoch 234/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9164 - accuracy: 0.6725 - val_loss: 1.6387 - val_accuracy: 0.4900\n",
      "Epoch 235/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9243 - accuracy: 0.6640 - val_loss: 1.6653 - val_accuracy: 0.4833\n",
      "Epoch 236/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9001 - accuracy: 0.6781 - val_loss: 1.6502 - val_accuracy: 0.4933\n",
      "Epoch 237/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9536 - accuracy: 0.6604 - val_loss: 1.6631 - val_accuracy: 0.4933\n",
      "Epoch 238/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9108 - accuracy: 0.6825 - val_loss: 1.6680 - val_accuracy: 0.4900\n",
      "Epoch 239/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9402 - accuracy: 0.6477 - val_loss: 1.6374 - val_accuracy: 0.4900\n",
      "Epoch 240/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9030 - accuracy: 0.6386 - val_loss: 1.6605 - val_accuracy: 0.4867\n",
      "Epoch 241/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8926 - accuracy: 0.6792 - val_loss: 1.6683 - val_accuracy: 0.4933\n",
      "Epoch 242/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.6639 - val_loss: 1.6605 - val_accuracy: 0.4867\n",
      "Epoch 243/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9424 - accuracy: 0.6420 - val_loss: 1.6726 - val_accuracy: 0.4867\n",
      "Epoch 244/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8936 - accuracy: 0.6967 - val_loss: 1.6886 - val_accuracy: 0.4933\n",
      "Epoch 245/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9136 - accuracy: 0.6546 - val_loss: 1.6625 - val_accuracy: 0.4867\n",
      "Epoch 246/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9036 - accuracy: 0.6710 - val_loss: 1.6645 - val_accuracy: 0.4900\n",
      "Epoch 247/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8933 - accuracy: 0.6801 - val_loss: 1.6692 - val_accuracy: 0.4867\n",
      "Epoch 248/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8919 - accuracy: 0.6867 - val_loss: 1.6795 - val_accuracy: 0.4867\n",
      "Epoch 249/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.6525 - val_loss: 1.6911 - val_accuracy: 0.4867\n",
      "Epoch 250/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8961 - accuracy: 0.6897 - val_loss: 1.6797 - val_accuracy: 0.4900\n",
      "Epoch 251/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8889 - accuracy: 0.6976 - val_loss: 1.6830 - val_accuracy: 0.4900\n",
      "Epoch 252/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8777 - accuracy: 0.6919 - val_loss: 1.7113 - val_accuracy: 0.4867\n",
      "Epoch 253/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9254 - accuracy: 0.6750 - val_loss: 1.6824 - val_accuracy: 0.4933\n",
      "Epoch 254/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8995 - accuracy: 0.6836 - val_loss: 1.7074 - val_accuracy: 0.4833\n",
      "Epoch 255/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8983 - accuracy: 0.6882 - val_loss: 1.7022 - val_accuracy: 0.4800\n",
      "Epoch 256/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9275 - accuracy: 0.6687 - val_loss: 1.6871 - val_accuracy: 0.4900\n",
      "Epoch 257/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8454 - accuracy: 0.6962 - val_loss: 1.6935 - val_accuracy: 0.4867\n",
      "Epoch 258/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8677 - accuracy: 0.7016 - val_loss: 1.7093 - val_accuracy: 0.4900\n",
      "Epoch 259/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8993 - accuracy: 0.6994 - val_loss: 1.6765 - val_accuracy: 0.4900\n",
      "Epoch 260/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9369 - accuracy: 0.6541 - val_loss: 1.6875 - val_accuracy: 0.4900\n",
      "Epoch 261/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9097 - accuracy: 0.6902 - val_loss: 1.7033 - val_accuracy: 0.4933\n",
      "Epoch 262/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8892 - accuracy: 0.6681 - val_loss: 1.7092 - val_accuracy: 0.4867\n",
      "Epoch 263/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8863 - accuracy: 0.6985 - val_loss: 1.6837 - val_accuracy: 0.4867\n",
      "Epoch 264/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8296 - accuracy: 0.6853 - val_loss: 1.6862 - val_accuracy: 0.4900\n",
      "Epoch 265/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8794 - accuracy: 0.6962 - val_loss: 1.7202 - val_accuracy: 0.4767\n",
      "Epoch 266/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9013 - accuracy: 0.6827 - val_loss: 1.7130 - val_accuracy: 0.4867\n",
      "Epoch 267/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8656 - accuracy: 0.6833 - val_loss: 1.7043 - val_accuracy: 0.4900\n",
      "Epoch 268/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8807 - accuracy: 0.6923 - val_loss: 1.7150 - val_accuracy: 0.4867\n",
      "Epoch 269/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9017 - accuracy: 0.6686 - val_loss: 1.7392 - val_accuracy: 0.4767\n",
      "Epoch 270/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8801 - accuracy: 0.7088 - val_loss: 1.7202 - val_accuracy: 0.4900\n",
      "Epoch 271/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9120 - accuracy: 0.6573 - val_loss: 1.7155 - val_accuracy: 0.4867\n",
      "Epoch 272/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8595 - accuracy: 0.7001 - val_loss: 1.7145 - val_accuracy: 0.4867\n",
      "Epoch 273/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8793 - accuracy: 0.6816 - val_loss: 1.7284 - val_accuracy: 0.4900\n",
      "Epoch 274/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9096 - accuracy: 0.6738 - val_loss: 1.7155 - val_accuracy: 0.4900\n",
      "Epoch 275/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9077 - accuracy: 0.6559 - val_loss: 1.7189 - val_accuracy: 0.4900\n",
      "Epoch 276/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9060 - accuracy: 0.6795 - val_loss: 1.7313 - val_accuracy: 0.4933\n",
      "Epoch 277/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8451 - accuracy: 0.6830 - val_loss: 1.7475 - val_accuracy: 0.4833\n",
      "Epoch 278/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8640 - accuracy: 0.6618 - val_loss: 1.7202 - val_accuracy: 0.4900\n",
      "Epoch 279/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8857 - accuracy: 0.6902 - val_loss: 1.7304 - val_accuracy: 0.4833\n",
      "Epoch 280/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8867 - accuracy: 0.6911 - val_loss: 1.7406 - val_accuracy: 0.4833\n",
      "Epoch 281/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8966 - accuracy: 0.6746 - val_loss: 1.7356 - val_accuracy: 0.4833\n",
      "Epoch 282/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8461 - accuracy: 0.7054 - val_loss: 1.7453 - val_accuracy: 0.4733\n",
      "Epoch 283/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9224 - accuracy: 0.6630 - val_loss: 1.7512 - val_accuracy: 0.4733\n",
      "Epoch 284/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8487 - accuracy: 0.7064 - val_loss: 1.7122 - val_accuracy: 0.4900\n",
      "Epoch 285/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8866 - accuracy: 0.6620 - val_loss: 1.7470 - val_accuracy: 0.4833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8444 - accuracy: 0.6891 - val_loss: 1.7643 - val_accuracy: 0.4867\n",
      "Epoch 287/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8613 - accuracy: 0.7036 - val_loss: 1.7504 - val_accuracy: 0.4833\n",
      "Epoch 288/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9051 - accuracy: 0.6788 - val_loss: 1.7438 - val_accuracy: 0.4900\n",
      "Epoch 289/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8570 - accuracy: 0.6959 - val_loss: 1.7380 - val_accuracy: 0.4867\n",
      "Epoch 290/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8779 - accuracy: 0.6757 - val_loss: 1.7540 - val_accuracy: 0.4800\n",
      "Epoch 291/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8588 - accuracy: 0.6911 - val_loss: 1.7662 - val_accuracy: 0.4900\n",
      "Epoch 292/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7937 - accuracy: 0.7353 - val_loss: 1.7797 - val_accuracy: 0.4833\n",
      "Epoch 293/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8582 - accuracy: 0.6714 - val_loss: 1.7232 - val_accuracy: 0.4933\n",
      "Epoch 294/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8706 - accuracy: 0.6915 - val_loss: 1.7630 - val_accuracy: 0.4833\n",
      "Epoch 295/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8886 - accuracy: 0.6729 - val_loss: 1.7922 - val_accuracy: 0.4800\n",
      "Epoch 296/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9093 - accuracy: 0.6935 - val_loss: 1.7625 - val_accuracy: 0.4800\n",
      "Epoch 297/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8743 - accuracy: 0.7037 - val_loss: 1.7780 - val_accuracy: 0.4833\n",
      "Epoch 298/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8721 - accuracy: 0.7182 - val_loss: 1.7633 - val_accuracy: 0.4800\n",
      "Epoch 299/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8556 - accuracy: 0.6749 - val_loss: 1.7952 - val_accuracy: 0.4867\n",
      "Epoch 300/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9275 - accuracy: 0.6775 - val_loss: 1.7542 - val_accuracy: 0.4933\n",
      "Epoch 301/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8830 - accuracy: 0.6803 - val_loss: 1.7425 - val_accuracy: 0.4867\n",
      "Epoch 302/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8379 - accuracy: 0.7110 - val_loss: 1.7573 - val_accuracy: 0.4900\n",
      "Epoch 303/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8244 - accuracy: 0.7145 - val_loss: 1.7633 - val_accuracy: 0.4833\n",
      "Epoch 304/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8557 - accuracy: 0.6964 - val_loss: 1.7768 - val_accuracy: 0.4767\n",
      "Epoch 305/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8700 - accuracy: 0.7012 - val_loss: 1.7895 - val_accuracy: 0.4833\n",
      "Epoch 306/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8304 - accuracy: 0.7191 - val_loss: 1.7485 - val_accuracy: 0.4933\n",
      "Epoch 307/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8337 - accuracy: 0.6889 - val_loss: 1.7837 - val_accuracy: 0.4733\n",
      "Epoch 308/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8636 - accuracy: 0.7117 - val_loss: 1.8088 - val_accuracy: 0.4767\n",
      "Epoch 309/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8124 - accuracy: 0.7106 - val_loss: 1.7794 - val_accuracy: 0.4800\n",
      "Epoch 310/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8391 - accuracy: 0.7146 - val_loss: 1.7683 - val_accuracy: 0.4867\n",
      "Epoch 311/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8874 - accuracy: 0.6838 - val_loss: 1.7797 - val_accuracy: 0.4900\n",
      "Epoch 312/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8121 - accuracy: 0.7309 - val_loss: 1.8027 - val_accuracy: 0.4800\n",
      "Epoch 313/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8520 - accuracy: 0.7001 - val_loss: 1.8037 - val_accuracy: 0.4800\n",
      "Epoch 314/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8350 - accuracy: 0.6823 - val_loss: 1.7914 - val_accuracy: 0.4933\n",
      "Epoch 315/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8476 - accuracy: 0.7196 - val_loss: 1.8144 - val_accuracy: 0.4867\n",
      "Epoch 316/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8653 - accuracy: 0.7089 - val_loss: 1.8100 - val_accuracy: 0.4767\n",
      "Epoch 317/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8709 - accuracy: 0.6926 - val_loss: 1.7931 - val_accuracy: 0.4833\n",
      "Epoch 318/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8595 - accuracy: 0.7132 - val_loss: 1.8040 - val_accuracy: 0.4800\n",
      "Epoch 319/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8098 - accuracy: 0.6964 - val_loss: 1.8072 - val_accuracy: 0.4833\n",
      "Epoch 320/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8604 - accuracy: 0.7191 - val_loss: 1.8149 - val_accuracy: 0.4800\n",
      "Epoch 321/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9007 - accuracy: 0.6744 - val_loss: 1.8134 - val_accuracy: 0.4833\n",
      "Epoch 322/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8339 - accuracy: 0.7022 - val_loss: 1.8244 - val_accuracy: 0.4767\n",
      "Epoch 323/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8320 - accuracy: 0.7035 - val_loss: 1.8029 - val_accuracy: 0.4900\n",
      "Epoch 324/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8327 - accuracy: 0.7047 - val_loss: 1.8340 - val_accuracy: 0.4767\n",
      "Epoch 325/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7923 - accuracy: 0.7208 - val_loss: 1.8085 - val_accuracy: 0.4867\n",
      "Epoch 326/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8673 - accuracy: 0.7025 - val_loss: 1.8165 - val_accuracy: 0.4933\n",
      "Epoch 327/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8592 - accuracy: 0.6991 - val_loss: 1.8424 - val_accuracy: 0.4733\n",
      "Epoch 328/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8899 - accuracy: 0.6745 - val_loss: 1.8151 - val_accuracy: 0.4767\n",
      "Epoch 329/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8498 - accuracy: 0.6678 - val_loss: 1.8336 - val_accuracy: 0.4767\n",
      "Epoch 330/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8791 - accuracy: 0.6813 - val_loss: 1.8425 - val_accuracy: 0.4767\n",
      "Epoch 331/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8334 - accuracy: 0.7208 - val_loss: 1.8121 - val_accuracy: 0.4867\n",
      "Epoch 332/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8503 - accuracy: 0.7129 - val_loss: 1.8260 - val_accuracy: 0.4833\n",
      "Epoch 333/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8405 - accuracy: 0.7062 - val_loss: 1.8587 - val_accuracy: 0.4767\n",
      "Epoch 334/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8296 - accuracy: 0.7103 - val_loss: 1.8481 - val_accuracy: 0.4867\n",
      "Epoch 335/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8316 - accuracy: 0.7071 - val_loss: 1.8282 - val_accuracy: 0.4867\n",
      "Epoch 336/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8095 - accuracy: 0.7139 - val_loss: 1.8453 - val_accuracy: 0.4833\n",
      "Epoch 337/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8270 - accuracy: 0.7075 - val_loss: 1.8483 - val_accuracy: 0.4733\n",
      "Epoch 338/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8879 - accuracy: 0.6933 - val_loss: 1.8624 - val_accuracy: 0.4800\n",
      "Epoch 339/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8238 - accuracy: 0.7133 - val_loss: 1.8403 - val_accuracy: 0.4833\n",
      "Epoch 340/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8061 - accuracy: 0.7182 - val_loss: 1.8627 - val_accuracy: 0.4833\n",
      "Epoch 341/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8296 - accuracy: 0.6754 - val_loss: 1.8418 - val_accuracy: 0.4800\n",
      "Epoch 342/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8513 - accuracy: 0.6937 - val_loss: 1.8659 - val_accuracy: 0.4867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8052 - accuracy: 0.7010 - val_loss: 1.8443 - val_accuracy: 0.4800\n",
      "Epoch 344/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8501 - accuracy: 0.6947 - val_loss: 1.8439 - val_accuracy: 0.4833\n",
      "Epoch 345/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7704 - accuracy: 0.7485 - val_loss: 1.8517 - val_accuracy: 0.4867\n",
      "Epoch 346/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8264 - accuracy: 0.7119 - val_loss: 1.8492 - val_accuracy: 0.4800\n",
      "Epoch 347/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8135 - accuracy: 0.7132 - val_loss: 1.8483 - val_accuracy: 0.4800\n",
      "Epoch 348/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8483 - accuracy: 0.7278 - val_loss: 1.8629 - val_accuracy: 0.4867\n",
      "Epoch 349/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8658 - accuracy: 0.7128 - val_loss: 1.8643 - val_accuracy: 0.4800\n",
      "Epoch 350/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7992 - accuracy: 0.7363 - val_loss: 1.8623 - val_accuracy: 0.4767\n",
      "Epoch 351/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8340 - accuracy: 0.6938 - val_loss: 1.8644 - val_accuracy: 0.4867\n",
      "Epoch 352/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8274 - accuracy: 0.7159 - val_loss: 1.8328 - val_accuracy: 0.5033\n",
      "Epoch 353/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8794 - accuracy: 0.6991 - val_loss: 1.8736 - val_accuracy: 0.4800\n",
      "Epoch 354/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8307 - accuracy: 0.7109 - val_loss: 1.8795 - val_accuracy: 0.4800\n",
      "Epoch 355/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8353 - accuracy: 0.7141 - val_loss: 1.8589 - val_accuracy: 0.4800\n",
      "Epoch 356/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8124 - accuracy: 0.7194 - val_loss: 1.8936 - val_accuracy: 0.4800\n",
      "Epoch 357/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8455 - accuracy: 0.6921 - val_loss: 1.8656 - val_accuracy: 0.4767\n",
      "Epoch 358/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8027 - accuracy: 0.7145 - val_loss: 1.8643 - val_accuracy: 0.4867\n",
      "Epoch 359/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8144 - accuracy: 0.7207 - val_loss: 1.8825 - val_accuracy: 0.4700\n",
      "Epoch 360/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8033 - accuracy: 0.6956 - val_loss: 1.8899 - val_accuracy: 0.4667\n",
      "Epoch 361/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8103 - accuracy: 0.7328 - val_loss: 1.8768 - val_accuracy: 0.4833\n",
      "Epoch 362/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8639 - accuracy: 0.7095 - val_loss: 1.8970 - val_accuracy: 0.4733\n",
      "Epoch 363/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7754 - accuracy: 0.7183 - val_loss: 1.8543 - val_accuracy: 0.4967\n",
      "Epoch 364/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8487 - accuracy: 0.6889 - val_loss: 1.8983 - val_accuracy: 0.4800\n",
      "Epoch 365/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7976 - accuracy: 0.7054 - val_loss: 1.8737 - val_accuracy: 0.4867\n",
      "Epoch 366/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8007 - accuracy: 0.7082 - val_loss: 1.8754 - val_accuracy: 0.4800\n",
      "Epoch 367/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7989 - accuracy: 0.7318 - val_loss: 1.8878 - val_accuracy: 0.4833\n",
      "Epoch 368/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8375 - accuracy: 0.6969 - val_loss: 1.8723 - val_accuracy: 0.4900\n",
      "Epoch 369/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7899 - accuracy: 0.7312 - val_loss: 1.8919 - val_accuracy: 0.4867\n",
      "Epoch 370/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8162 - accuracy: 0.7097 - val_loss: 1.8990 - val_accuracy: 0.4833\n",
      "Epoch 371/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7750 - accuracy: 0.7180 - val_loss: 1.9026 - val_accuracy: 0.4900\n",
      "Epoch 372/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8078 - accuracy: 0.7363 - val_loss: 1.8958 - val_accuracy: 0.4867\n",
      "Epoch 373/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.7068 - val_loss: 1.8888 - val_accuracy: 0.4833\n",
      "Epoch 374/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8077 - accuracy: 0.6947 - val_loss: 1.9106 - val_accuracy: 0.4800\n",
      "Epoch 375/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7978 - accuracy: 0.7285 - val_loss: 1.9122 - val_accuracy: 0.4833\n",
      "Epoch 376/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7938 - accuracy: 0.7153 - val_loss: 1.8866 - val_accuracy: 0.4900\n",
      "Epoch 377/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7909 - accuracy: 0.7418 - val_loss: 1.9230 - val_accuracy: 0.4833\n",
      "Epoch 378/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8008 - accuracy: 0.7309 - val_loss: 1.9165 - val_accuracy: 0.4867\n",
      "Epoch 379/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7887 - accuracy: 0.7276 - val_loss: 1.9294 - val_accuracy: 0.4767\n",
      "Epoch 380/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7991 - accuracy: 0.7418 - val_loss: 1.9128 - val_accuracy: 0.4767\n",
      "Epoch 381/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8387 - accuracy: 0.7120 - val_loss: 1.9668 - val_accuracy: 0.4733\n",
      "Epoch 382/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7925 - accuracy: 0.7093 - val_loss: 1.9190 - val_accuracy: 0.4900\n",
      "Epoch 383/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8055 - accuracy: 0.7300 - val_loss: 1.9183 - val_accuracy: 0.4800\n",
      "Epoch 384/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8278 - accuracy: 0.7332 - val_loss: 1.8925 - val_accuracy: 0.4767\n",
      "Epoch 385/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7897 - accuracy: 0.7337 - val_loss: 1.9133 - val_accuracy: 0.4900\n",
      "Epoch 386/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7792 - accuracy: 0.7148 - val_loss: 1.9353 - val_accuracy: 0.4733\n",
      "Epoch 387/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7879 - accuracy: 0.7347 - val_loss: 1.9555 - val_accuracy: 0.4733\n",
      "Epoch 388/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8112 - accuracy: 0.7126 - val_loss: 1.9109 - val_accuracy: 0.4900\n",
      "Epoch 389/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8420 - accuracy: 0.7003 - val_loss: 1.9338 - val_accuracy: 0.4800\n",
      "Epoch 390/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.7085 - val_loss: 1.9294 - val_accuracy: 0.4800\n",
      "Epoch 391/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8373 - accuracy: 0.7097 - val_loss: 1.9497 - val_accuracy: 0.4733\n",
      "Epoch 392/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8246 - accuracy: 0.6834 - val_loss: 1.9232 - val_accuracy: 0.4867\n",
      "Epoch 393/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7416 - accuracy: 0.7517 - val_loss: 1.9179 - val_accuracy: 0.4867\n",
      "Epoch 394/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8368 - accuracy: 0.6986 - val_loss: 1.9621 - val_accuracy: 0.4733\n",
      "Epoch 395/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8300 - accuracy: 0.6931 - val_loss: 1.9514 - val_accuracy: 0.4733\n",
      "Epoch 396/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7777 - accuracy: 0.7073 - val_loss: 1.9508 - val_accuracy: 0.4800\n",
      "Epoch 397/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8255 - accuracy: 0.7121 - val_loss: 1.9595 - val_accuracy: 0.4733\n",
      "Epoch 398/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7651 - accuracy: 0.7385 - val_loss: 1.9261 - val_accuracy: 0.4900\n",
      "Epoch 399/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8089 - accuracy: 0.7286 - val_loss: 1.9646 - val_accuracy: 0.4700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8021 - accuracy: 0.7237 - val_loss: 1.9717 - val_accuracy: 0.4700\n",
      "Epoch 401/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7977 - accuracy: 0.7512 - val_loss: 1.9559 - val_accuracy: 0.4767\n",
      "Epoch 402/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7702 - accuracy: 0.7109 - val_loss: 1.9754 - val_accuracy: 0.4633\n",
      "Epoch 403/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8082 - accuracy: 0.7068 - val_loss: 1.9712 - val_accuracy: 0.4733\n",
      "Epoch 404/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7640 - accuracy: 0.7244 - val_loss: 1.9850 - val_accuracy: 0.4833\n",
      "Epoch 405/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8066 - accuracy: 0.7119 - val_loss: 2.0011 - val_accuracy: 0.4733\n",
      "Epoch 406/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7397 - accuracy: 0.7387 - val_loss: 1.9626 - val_accuracy: 0.4800\n",
      "Epoch 407/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7906 - accuracy: 0.7363 - val_loss: 1.9667 - val_accuracy: 0.4700\n",
      "Epoch 408/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8361 - accuracy: 0.7008 - val_loss: 1.9824 - val_accuracy: 0.4733\n",
      "Epoch 409/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8293 - accuracy: 0.6926 - val_loss: 1.9716 - val_accuracy: 0.4833\n",
      "Epoch 410/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7779 - accuracy: 0.7372 - val_loss: 1.9723 - val_accuracy: 0.4800\n",
      "Epoch 411/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7994 - accuracy: 0.7199 - val_loss: 1.9925 - val_accuracy: 0.4800\n",
      "Epoch 412/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7884 - accuracy: 0.6907 - val_loss: 1.9829 - val_accuracy: 0.4767\n",
      "Epoch 413/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8177 - accuracy: 0.7224 - val_loss: 1.9849 - val_accuracy: 0.4667\n",
      "Epoch 414/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7924 - accuracy: 0.7030 - val_loss: 1.9867 - val_accuracy: 0.4833\n",
      "Epoch 415/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8043 - accuracy: 0.7168 - val_loss: 1.9792 - val_accuracy: 0.4733\n",
      "Epoch 416/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7801 - accuracy: 0.7364 - val_loss: 1.9687 - val_accuracy: 0.4733\n",
      "Epoch 417/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7808 - accuracy: 0.7041 - val_loss: 1.9911 - val_accuracy: 0.4733\n",
      "Epoch 418/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7802 - accuracy: 0.7160 - val_loss: 1.9784 - val_accuracy: 0.4700\n",
      "Epoch 419/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7941 - accuracy: 0.7230 - val_loss: 1.9952 - val_accuracy: 0.4833\n",
      "Epoch 420/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8034 - accuracy: 0.7341 - val_loss: 2.0043 - val_accuracy: 0.4633\n",
      "Epoch 421/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8110 - accuracy: 0.7179 - val_loss: 1.9986 - val_accuracy: 0.4833\n",
      "Epoch 422/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7685 - accuracy: 0.7266 - val_loss: 1.9821 - val_accuracy: 0.4767\n",
      "Epoch 423/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7552 - accuracy: 0.7329 - val_loss: 1.9754 - val_accuracy: 0.4833\n",
      "Epoch 424/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7807 - accuracy: 0.7336 - val_loss: 2.0208 - val_accuracy: 0.4700\n",
      "Epoch 425/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7778 - accuracy: 0.7341 - val_loss: 2.0135 - val_accuracy: 0.4767\n",
      "Epoch 426/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7794 - accuracy: 0.7338 - val_loss: 1.9896 - val_accuracy: 0.4667\n",
      "Epoch 427/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7518 - accuracy: 0.7477 - val_loss: 1.9972 - val_accuracy: 0.4867\n",
      "Epoch 428/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7645 - accuracy: 0.7352 - val_loss: 2.0049 - val_accuracy: 0.4733\n",
      "Epoch 429/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7551 - accuracy: 0.7431 - val_loss: 2.0327 - val_accuracy: 0.4667\n",
      "Epoch 430/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8199 - accuracy: 0.6692 - val_loss: 2.0077 - val_accuracy: 0.4800\n",
      "Epoch 431/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7599 - accuracy: 0.7278 - val_loss: 2.0047 - val_accuracy: 0.4800\n",
      "Epoch 432/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7415 - accuracy: 0.7401 - val_loss: 1.9963 - val_accuracy: 0.4800\n",
      "Epoch 433/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7419 - accuracy: 0.7309 - val_loss: 2.0333 - val_accuracy: 0.4833\n",
      "Epoch 434/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7485 - accuracy: 0.7464 - val_loss: 2.0111 - val_accuracy: 0.4867\n",
      "Epoch 435/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7854 - accuracy: 0.7292 - val_loss: 2.0217 - val_accuracy: 0.4767\n",
      "Epoch 436/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7857 - accuracy: 0.7342 - val_loss: 2.0121 - val_accuracy: 0.4667\n",
      "Epoch 437/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7845 - accuracy: 0.7150 - val_loss: 2.0086 - val_accuracy: 0.4767\n",
      "Epoch 438/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7418 - accuracy: 0.7260 - val_loss: 2.0135 - val_accuracy: 0.4933\n",
      "Epoch 439/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8048 - accuracy: 0.7268 - val_loss: 2.0087 - val_accuracy: 0.4633\n",
      "Epoch 440/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8111 - accuracy: 0.7170 - val_loss: 2.0264 - val_accuracy: 0.4767\n",
      "Epoch 441/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7403 - accuracy: 0.7445 - val_loss: 2.0007 - val_accuracy: 0.4733\n",
      "Epoch 442/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8189 - accuracy: 0.7349 - val_loss: 1.9971 - val_accuracy: 0.4833\n",
      "Epoch 443/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8094 - accuracy: 0.7137 - val_loss: 2.0268 - val_accuracy: 0.4900\n",
      "Epoch 444/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7692 - accuracy: 0.7248 - val_loss: 2.0595 - val_accuracy: 0.4767\n",
      "Epoch 445/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.7491 - val_loss: 2.0450 - val_accuracy: 0.4700\n",
      "Epoch 446/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7857 - accuracy: 0.7205 - val_loss: 2.0399 - val_accuracy: 0.4733\n",
      "Epoch 447/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7937 - accuracy: 0.7228 - val_loss: 2.0510 - val_accuracy: 0.4800\n",
      "Epoch 448/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7491 - accuracy: 0.7543 - val_loss: 2.0306 - val_accuracy: 0.4833\n",
      "Epoch 449/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.7570 - val_loss: 2.0356 - val_accuracy: 0.4900\n",
      "Epoch 450/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7725 - accuracy: 0.7571 - val_loss: 2.0460 - val_accuracy: 0.4600\n",
      "Epoch 451/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7811 - accuracy: 0.7162 - val_loss: 2.0626 - val_accuracy: 0.4800\n",
      "Epoch 452/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.7722 - val_loss: 2.0570 - val_accuracy: 0.4800\n",
      "Epoch 453/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7528 - accuracy: 0.7617 - val_loss: 2.0364 - val_accuracy: 0.4667\n",
      "Epoch 454/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7604 - accuracy: 0.7324 - val_loss: 2.0496 - val_accuracy: 0.4700\n",
      "Epoch 455/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6986 - accuracy: 0.7578 - val_loss: 2.0328 - val_accuracy: 0.4800\n",
      "Epoch 456/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7301 - accuracy: 0.7673 - val_loss: 2.0680 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7907 - accuracy: 0.7507 - val_loss: 2.0663 - val_accuracy: 0.4733\n",
      "Epoch 458/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8037 - accuracy: 0.7364 - val_loss: 2.0226 - val_accuracy: 0.4700\n",
      "Epoch 459/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8199 - accuracy: 0.7127 - val_loss: 2.0642 - val_accuracy: 0.4733\n",
      "Epoch 460/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7687 - accuracy: 0.7294 - val_loss: 2.0821 - val_accuracy: 0.4767\n",
      "Epoch 461/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.7428 - val_loss: 2.0468 - val_accuracy: 0.4733\n",
      "Epoch 462/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7425 - accuracy: 0.7614 - val_loss: 2.0796 - val_accuracy: 0.4667\n",
      "Epoch 463/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7469 - accuracy: 0.7621 - val_loss: 2.0468 - val_accuracy: 0.4767\n",
      "Epoch 464/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7881 - accuracy: 0.7010 - val_loss: 2.0631 - val_accuracy: 0.4833\n",
      "Epoch 465/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7452 - accuracy: 0.7646 - val_loss: 2.0702 - val_accuracy: 0.4700\n",
      "Epoch 466/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7701 - accuracy: 0.7462 - val_loss: 2.0755 - val_accuracy: 0.4767\n",
      "Epoch 467/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7862 - accuracy: 0.7121 - val_loss: 2.0888 - val_accuracy: 0.4633\n",
      "Epoch 468/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8011 - accuracy: 0.7281 - val_loss: 2.0714 - val_accuracy: 0.4567\n",
      "Epoch 469/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7263 - accuracy: 0.7582 - val_loss: 2.0812 - val_accuracy: 0.4667\n",
      "Epoch 470/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7327 - accuracy: 0.7343 - val_loss: 2.0951 - val_accuracy: 0.4833\n",
      "Epoch 471/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.7591 - val_loss: 2.1049 - val_accuracy: 0.4767\n",
      "Epoch 472/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.7597 - val_loss: 2.0793 - val_accuracy: 0.4733\n",
      "Epoch 473/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7631 - accuracy: 0.7381 - val_loss: 2.0793 - val_accuracy: 0.4733\n",
      "Epoch 474/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7697 - accuracy: 0.7363 - val_loss: 2.0801 - val_accuracy: 0.4733\n",
      "Epoch 475/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7813 - accuracy: 0.7374 - val_loss: 2.1236 - val_accuracy: 0.4633\n",
      "Epoch 476/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7240 - accuracy: 0.7477 - val_loss: 2.0844 - val_accuracy: 0.4667\n",
      "Epoch 477/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7361 - accuracy: 0.7663 - val_loss: 2.1157 - val_accuracy: 0.4667\n",
      "Epoch 478/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7227 - accuracy: 0.7567 - val_loss: 2.0930 - val_accuracy: 0.4700\n",
      "Epoch 479/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7298 - accuracy: 0.7583 - val_loss: 2.0894 - val_accuracy: 0.4867\n",
      "Epoch 480/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7375 - accuracy: 0.7433 - val_loss: 2.0706 - val_accuracy: 0.4733\n",
      "Epoch 481/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7297 - accuracy: 0.7530 - val_loss: 2.1143 - val_accuracy: 0.4767\n",
      "Epoch 482/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7565 - accuracy: 0.7410 - val_loss: 2.1099 - val_accuracy: 0.4633\n",
      "Epoch 483/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7680 - accuracy: 0.7137 - val_loss: 2.1013 - val_accuracy: 0.4833\n",
      "Epoch 484/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7382 - accuracy: 0.7592 - val_loss: 2.1212 - val_accuracy: 0.4733\n",
      "Epoch 485/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7333 - accuracy: 0.7333 - val_loss: 2.1119 - val_accuracy: 0.4600\n",
      "Epoch 486/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7548 - accuracy: 0.7577 - val_loss: 2.1196 - val_accuracy: 0.4600\n",
      "Epoch 487/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.7655 - val_loss: 2.1320 - val_accuracy: 0.4667\n",
      "Epoch 488/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7730 - accuracy: 0.7545 - val_loss: 2.1257 - val_accuracy: 0.4767\n",
      "Epoch 489/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.7536 - val_loss: 2.1024 - val_accuracy: 0.4833\n",
      "Epoch 490/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8012 - accuracy: 0.7145 - val_loss: 2.1197 - val_accuracy: 0.4667\n",
      "Epoch 491/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7523 - accuracy: 0.7607 - val_loss: 2.1109 - val_accuracy: 0.4700\n",
      "Epoch 492/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8036 - accuracy: 0.7524 - val_loss: 2.1331 - val_accuracy: 0.4667\n",
      "Epoch 493/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7749 - val_loss: 2.1363 - val_accuracy: 0.4767\n",
      "Epoch 494/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7285 - accuracy: 0.7443 - val_loss: 2.1410 - val_accuracy: 0.4733\n",
      "Epoch 495/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7608 - accuracy: 0.7447 - val_loss: 2.1266 - val_accuracy: 0.4667\n",
      "Epoch 496/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.7540 - val_loss: 2.1440 - val_accuracy: 0.4867\n",
      "Epoch 497/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7284 - accuracy: 0.7659 - val_loss: 2.1437 - val_accuracy: 0.4767\n",
      "Epoch 498/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7201 - accuracy: 0.7701 - val_loss: 2.1216 - val_accuracy: 0.4800\n",
      "Epoch 499/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7393 - accuracy: 0.7281 - val_loss: 2.1570 - val_accuracy: 0.4733\n",
      "Epoch 500/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.8063 - accuracy: 0.7512 - val_loss: 2.1499 - val_accuracy: 0.4767\n",
      "Epoch 501/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7987 - accuracy: 0.7173 - val_loss: 2.1373 - val_accuracy: 0.4767\n",
      "Epoch 502/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7013 - accuracy: 0.7790 - val_loss: 2.1303 - val_accuracy: 0.4800\n",
      "Epoch 503/1000\n",
      "70/70 [==============================] - 0s 2ms/step - loss: 0.7646 - accuracy: 0.7191 - val_loss: 2.1592 - val_accuracy: 0.4633\n",
      "Epoch 504/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7169 - accuracy: 0.7694 - val_loss: 2.1217 - val_accuracy: 0.4667\n",
      "Epoch 505/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7352 - accuracy: 0.7539 - val_loss: 2.1700 - val_accuracy: 0.4700\n",
      "Epoch 506/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7614 - accuracy: 0.7264 - val_loss: 2.1537 - val_accuracy: 0.4700\n",
      "Epoch 507/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7861 - accuracy: 0.7405 - val_loss: 2.1520 - val_accuracy: 0.4633\n",
      "Epoch 508/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7837 - accuracy: 0.7479 - val_loss: 2.1391 - val_accuracy: 0.4733\n",
      "Epoch 509/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7446 - accuracy: 0.7511 - val_loss: 2.1356 - val_accuracy: 0.4733\n",
      "Epoch 510/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7723 - accuracy: 0.7265 - val_loss: 2.1781 - val_accuracy: 0.4700\n",
      "Epoch 511/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7225 - accuracy: 0.7536 - val_loss: 2.1352 - val_accuracy: 0.4767\n",
      "Epoch 512/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7405 - accuracy: 0.7783 - val_loss: 2.1769 - val_accuracy: 0.4600\n",
      "Epoch 513/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7567 - accuracy: 0.7515 - val_loss: 2.1666 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7474 - accuracy: 0.7356 - val_loss: 2.1317 - val_accuracy: 0.4800\n",
      "Epoch 515/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7747 - accuracy: 0.7163 - val_loss: 2.1677 - val_accuracy: 0.4633\n",
      "Epoch 516/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7628 - accuracy: 0.7482 - val_loss: 2.1696 - val_accuracy: 0.4633\n",
      "Epoch 517/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7243 - accuracy: 0.7487 - val_loss: 2.1759 - val_accuracy: 0.4700\n",
      "Epoch 518/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7246 - accuracy: 0.7572 - val_loss: 2.1665 - val_accuracy: 0.4767\n",
      "Epoch 519/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7258 - accuracy: 0.7452 - val_loss: 2.1907 - val_accuracy: 0.4533\n",
      "Epoch 520/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.7431 - val_loss: 2.1729 - val_accuracy: 0.4767\n",
      "Epoch 521/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7468 - accuracy: 0.7471 - val_loss: 2.1666 - val_accuracy: 0.4500\n",
      "Epoch 522/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7001 - accuracy: 0.7496 - val_loss: 2.1703 - val_accuracy: 0.4700\n",
      "Epoch 523/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7631 - accuracy: 0.7410 - val_loss: 2.1560 - val_accuracy: 0.4633\n",
      "Epoch 524/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7888 - accuracy: 0.7486 - val_loss: 2.1946 - val_accuracy: 0.4533\n",
      "Epoch 525/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7429 - accuracy: 0.7506 - val_loss: 2.2065 - val_accuracy: 0.4767\n",
      "Epoch 526/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7636 - accuracy: 0.7272 - val_loss: 2.1821 - val_accuracy: 0.4533\n",
      "Epoch 527/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7272 - accuracy: 0.7456 - val_loss: 2.1988 - val_accuracy: 0.4700\n",
      "Epoch 528/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7402 - accuracy: 0.7593 - val_loss: 2.1837 - val_accuracy: 0.4567\n",
      "Epoch 529/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.7595 - val_loss: 2.2037 - val_accuracy: 0.4667\n",
      "Epoch 530/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7034 - accuracy: 0.7857 - val_loss: 2.1868 - val_accuracy: 0.4633\n",
      "Epoch 531/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7064 - accuracy: 0.7492 - val_loss: 2.2008 - val_accuracy: 0.4533\n",
      "Epoch 532/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7197 - accuracy: 0.7665 - val_loss: 2.2123 - val_accuracy: 0.4567\n",
      "Epoch 533/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.7499 - val_loss: 2.1954 - val_accuracy: 0.4567\n",
      "Epoch 534/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7053 - accuracy: 0.7698 - val_loss: 2.1950 - val_accuracy: 0.4800\n",
      "Epoch 535/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.7629 - val_loss: 2.1972 - val_accuracy: 0.4567\n",
      "Epoch 536/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7314 - accuracy: 0.7639 - val_loss: 2.1945 - val_accuracy: 0.4600\n",
      "Epoch 537/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7231 - accuracy: 0.7843 - val_loss: 2.2201 - val_accuracy: 0.4567\n",
      "Epoch 538/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.7839 - val_loss: 2.2218 - val_accuracy: 0.4600\n",
      "Epoch 539/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7512 - accuracy: 0.7309 - val_loss: 2.2305 - val_accuracy: 0.4633\n",
      "Epoch 540/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7106 - accuracy: 0.7535 - val_loss: 2.2012 - val_accuracy: 0.4767\n",
      "Epoch 541/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.7629 - val_loss: 2.1961 - val_accuracy: 0.4733\n",
      "Epoch 542/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7316 - accuracy: 0.7654 - val_loss: 2.2342 - val_accuracy: 0.4633\n",
      "Epoch 543/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.7478 - val_loss: 2.2121 - val_accuracy: 0.4867\n",
      "Epoch 544/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7025 - accuracy: 0.7664 - val_loss: 2.2117 - val_accuracy: 0.4567\n",
      "Epoch 545/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6810 - accuracy: 0.7665 - val_loss: 2.2442 - val_accuracy: 0.4600\n",
      "Epoch 546/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7406 - accuracy: 0.7297 - val_loss: 2.2421 - val_accuracy: 0.4700\n",
      "Epoch 547/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7360 - accuracy: 0.7409 - val_loss: 2.2358 - val_accuracy: 0.4733\n",
      "Epoch 548/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7836 - accuracy: 0.7513 - val_loss: 2.2176 - val_accuracy: 0.4633\n",
      "Epoch 549/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7542 - accuracy: 0.7425 - val_loss: 2.2436 - val_accuracy: 0.4633\n",
      "Epoch 550/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7776 - accuracy: 0.7359 - val_loss: 2.2196 - val_accuracy: 0.4600\n",
      "Epoch 551/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6837 - accuracy: 0.7909 - val_loss: 2.2211 - val_accuracy: 0.4567\n",
      "Epoch 552/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7544 - accuracy: 0.7442 - val_loss: 2.2286 - val_accuracy: 0.4533\n",
      "Epoch 553/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7707 - val_loss: 2.2385 - val_accuracy: 0.4733\n",
      "Epoch 554/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7059 - accuracy: 0.7646 - val_loss: 2.2123 - val_accuracy: 0.4600\n",
      "Epoch 555/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6887 - accuracy: 0.7553 - val_loss: 2.2466 - val_accuracy: 0.4600\n",
      "Epoch 556/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7430 - accuracy: 0.7344 - val_loss: 2.2544 - val_accuracy: 0.4600\n",
      "Epoch 557/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7397 - val_loss: 2.2395 - val_accuracy: 0.4733\n",
      "Epoch 558/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7294 - accuracy: 0.7618 - val_loss: 2.2484 - val_accuracy: 0.4733\n",
      "Epoch 559/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7247 - accuracy: 0.7387 - val_loss: 2.2292 - val_accuracy: 0.4700\n",
      "Epoch 560/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6912 - accuracy: 0.7578 - val_loss: 2.2475 - val_accuracy: 0.4767\n",
      "Epoch 561/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7504 - val_loss: 2.2626 - val_accuracy: 0.4667\n",
      "Epoch 562/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7111 - accuracy: 0.7641 - val_loss: 2.2838 - val_accuracy: 0.4633\n",
      "Epoch 563/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7126 - accuracy: 0.7591 - val_loss: 2.2407 - val_accuracy: 0.4533\n",
      "Epoch 564/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.7721 - val_loss: 2.2413 - val_accuracy: 0.4700\n",
      "Epoch 565/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.7579 - val_loss: 2.2394 - val_accuracy: 0.4467\n",
      "Epoch 566/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7974 - accuracy: 0.7330 - val_loss: 2.2541 - val_accuracy: 0.4633\n",
      "Epoch 567/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.7604 - val_loss: 2.2443 - val_accuracy: 0.4767\n",
      "Epoch 568/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7204 - accuracy: 0.7725 - val_loss: 2.2405 - val_accuracy: 0.4800\n",
      "Epoch 569/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7471 - accuracy: 0.7335 - val_loss: 2.2768 - val_accuracy: 0.4700\n",
      "Epoch 570/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7360 - accuracy: 0.7553 - val_loss: 2.2727 - val_accuracy: 0.4700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7041 - accuracy: 0.7697 - val_loss: 2.2841 - val_accuracy: 0.4633\n",
      "Epoch 572/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7709 - val_loss: 2.2848 - val_accuracy: 0.4467\n",
      "Epoch 573/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7476 - accuracy: 0.7518 - val_loss: 2.2851 - val_accuracy: 0.4733\n",
      "Epoch 574/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7040 - accuracy: 0.7667 - val_loss: 2.2875 - val_accuracy: 0.4600\n",
      "Epoch 575/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7432 - accuracy: 0.7500 - val_loss: 2.2663 - val_accuracy: 0.4733\n",
      "Epoch 576/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7166 - accuracy: 0.7551 - val_loss: 2.2748 - val_accuracy: 0.4800\n",
      "Epoch 577/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6811 - accuracy: 0.7729 - val_loss: 2.2857 - val_accuracy: 0.4467\n",
      "Epoch 578/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6906 - accuracy: 0.7440 - val_loss: 2.2305 - val_accuracy: 0.4733\n",
      "Epoch 579/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7026 - accuracy: 0.7596 - val_loss: 2.2932 - val_accuracy: 0.4500\n",
      "Epoch 580/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6984 - accuracy: 0.7619 - val_loss: 2.3148 - val_accuracy: 0.4600\n",
      "Epoch 581/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.7615 - val_loss: 2.2587 - val_accuracy: 0.4667\n",
      "Epoch 582/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7154 - accuracy: 0.7606 - val_loss: 2.2903 - val_accuracy: 0.4767\n",
      "Epoch 583/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.7659 - val_loss: 2.2874 - val_accuracy: 0.4767\n",
      "Epoch 584/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7495 - accuracy: 0.7615 - val_loss: 2.2794 - val_accuracy: 0.4733\n",
      "Epoch 585/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6990 - accuracy: 0.7634 - val_loss: 2.2960 - val_accuracy: 0.4467\n",
      "Epoch 586/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7146 - accuracy: 0.7477 - val_loss: 2.3087 - val_accuracy: 0.4433\n",
      "Epoch 587/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7408 - accuracy: 0.7510 - val_loss: 2.2742 - val_accuracy: 0.4467\n",
      "Epoch 588/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.7565 - val_loss: 2.2773 - val_accuracy: 0.4733\n",
      "Epoch 589/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7060 - accuracy: 0.7625 - val_loss: 2.2834 - val_accuracy: 0.4767\n",
      "Epoch 590/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.7679 - val_loss: 2.2732 - val_accuracy: 0.4767\n",
      "Epoch 591/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7244 - accuracy: 0.7328 - val_loss: 2.3069 - val_accuracy: 0.4400\n",
      "Epoch 592/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.7405 - val_loss: 2.3092 - val_accuracy: 0.4733\n",
      "Epoch 593/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.7615 - val_loss: 2.2966 - val_accuracy: 0.4500\n",
      "Epoch 594/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7390 - accuracy: 0.7343 - val_loss: 2.2984 - val_accuracy: 0.4533\n",
      "Epoch 595/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7317 - accuracy: 0.7445 - val_loss: 2.2986 - val_accuracy: 0.4733\n",
      "Epoch 596/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7275 - accuracy: 0.7270 - val_loss: 2.3255 - val_accuracy: 0.4567\n",
      "Epoch 597/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.7719 - val_loss: 2.2996 - val_accuracy: 0.4400\n",
      "Epoch 598/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.7675 - val_loss: 2.3266 - val_accuracy: 0.4767\n",
      "Epoch 599/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7289 - accuracy: 0.7546 - val_loss: 2.3063 - val_accuracy: 0.4667\n",
      "Epoch 600/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7310 - accuracy: 0.7409 - val_loss: 2.3069 - val_accuracy: 0.4567\n",
      "Epoch 601/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6972 - accuracy: 0.7614 - val_loss: 2.2927 - val_accuracy: 0.4667\n",
      "Epoch 602/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7254 - accuracy: 0.7654 - val_loss: 2.3110 - val_accuracy: 0.4600\n",
      "Epoch 603/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7431 - accuracy: 0.7628 - val_loss: 2.3284 - val_accuracy: 0.4633\n",
      "Epoch 604/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7167 - accuracy: 0.7786 - val_loss: 2.3005 - val_accuracy: 0.4567\n",
      "Epoch 605/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6999 - accuracy: 0.7651 - val_loss: 2.3458 - val_accuracy: 0.4467\n",
      "Epoch 606/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6623 - accuracy: 0.7685 - val_loss: 2.3251 - val_accuracy: 0.4433\n",
      "Epoch 607/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.7781 - val_loss: 2.3337 - val_accuracy: 0.4467\n",
      "Epoch 608/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7359 - accuracy: 0.7406 - val_loss: 2.3483 - val_accuracy: 0.4467\n",
      "Epoch 609/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7535 - accuracy: 0.7730 - val_loss: 2.3637 - val_accuracy: 0.4667\n",
      "Epoch 610/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7653 - accuracy: 0.7521 - val_loss: 2.3209 - val_accuracy: 0.4500\n",
      "Epoch 611/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7165 - accuracy: 0.7593 - val_loss: 2.3148 - val_accuracy: 0.4633\n",
      "Epoch 612/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.7663 - val_loss: 2.3562 - val_accuracy: 0.4567\n",
      "Epoch 613/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.7431 - val_loss: 2.3384 - val_accuracy: 0.4433\n",
      "Epoch 614/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7031 - accuracy: 0.7337 - val_loss: 2.3431 - val_accuracy: 0.4533\n",
      "Epoch 615/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6881 - accuracy: 0.7567 - val_loss: 2.3418 - val_accuracy: 0.4767\n",
      "Epoch 616/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7805 - val_loss: 2.3532 - val_accuracy: 0.4533\n",
      "Epoch 617/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.7662 - val_loss: 2.3555 - val_accuracy: 0.4567\n",
      "Epoch 618/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6752 - accuracy: 0.7968 - val_loss: 2.3282 - val_accuracy: 0.4667\n",
      "Epoch 619/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6692 - accuracy: 0.7682 - val_loss: 2.3851 - val_accuracy: 0.4400\n",
      "Epoch 620/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7033 - accuracy: 0.7711 - val_loss: 2.3432 - val_accuracy: 0.4533\n",
      "Epoch 621/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7364 - accuracy: 0.7210 - val_loss: 2.3615 - val_accuracy: 0.4667\n",
      "Epoch 622/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7049 - accuracy: 0.7733 - val_loss: 2.3571 - val_accuracy: 0.4500\n",
      "Epoch 623/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6757 - accuracy: 0.7667 - val_loss: 2.3437 - val_accuracy: 0.4633\n",
      "Epoch 624/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7004 - accuracy: 0.7559 - val_loss: 2.3400 - val_accuracy: 0.4633\n",
      "Epoch 625/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7092 - accuracy: 0.7573 - val_loss: 2.3789 - val_accuracy: 0.4600\n",
      "Epoch 626/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.7460 - val_loss: 2.3717 - val_accuracy: 0.4533\n",
      "Epoch 627/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7045 - accuracy: 0.7646 - val_loss: 2.3621 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 628/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6683 - accuracy: 0.7858 - val_loss: 2.3648 - val_accuracy: 0.4600\n",
      "Epoch 629/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6865 - accuracy: 0.7625 - val_loss: 2.3618 - val_accuracy: 0.4633\n",
      "Epoch 630/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7046 - accuracy: 0.7721 - val_loss: 2.3709 - val_accuracy: 0.4433\n",
      "Epoch 631/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6936 - accuracy: 0.7605 - val_loss: 2.3609 - val_accuracy: 0.4567\n",
      "Epoch 632/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6974 - accuracy: 0.7655 - val_loss: 2.3779 - val_accuracy: 0.4433\n",
      "Epoch 633/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7103 - accuracy: 0.7545 - val_loss: 2.3494 - val_accuracy: 0.4600\n",
      "Epoch 634/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6884 - accuracy: 0.7729 - val_loss: 2.3983 - val_accuracy: 0.4433\n",
      "Epoch 635/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7100 - accuracy: 0.7464 - val_loss: 2.4064 - val_accuracy: 0.4433\n",
      "Epoch 636/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6773 - accuracy: 0.7891 - val_loss: 2.3903 - val_accuracy: 0.4433\n",
      "Epoch 637/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6806 - accuracy: 0.7574 - val_loss: 2.3869 - val_accuracy: 0.4667\n",
      "Epoch 638/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6608 - accuracy: 0.7775 - val_loss: 2.3847 - val_accuracy: 0.4467\n",
      "Epoch 639/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7022 - accuracy: 0.7701 - val_loss: 2.3655 - val_accuracy: 0.4633\n",
      "Epoch 640/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7396 - accuracy: 0.7436 - val_loss: 2.3694 - val_accuracy: 0.4600\n",
      "Epoch 641/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.7421 - val_loss: 2.3669 - val_accuracy: 0.4533\n",
      "Epoch 642/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6771 - accuracy: 0.7746 - val_loss: 2.3968 - val_accuracy: 0.4633\n",
      "Epoch 643/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7125 - accuracy: 0.7540 - val_loss: 2.3948 - val_accuracy: 0.4467\n",
      "Epoch 644/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7133 - accuracy: 0.7619 - val_loss: 2.3799 - val_accuracy: 0.4733\n",
      "Epoch 645/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7803 - val_loss: 2.3935 - val_accuracy: 0.4633\n",
      "Epoch 646/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.7496 - val_loss: 2.4051 - val_accuracy: 0.4467\n",
      "Epoch 647/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7202 - accuracy: 0.7668 - val_loss: 2.4063 - val_accuracy: 0.4433\n",
      "Epoch 648/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7187 - accuracy: 0.7363 - val_loss: 2.4026 - val_accuracy: 0.4700\n",
      "Epoch 649/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6745 - accuracy: 0.7560 - val_loss: 2.4016 - val_accuracy: 0.4600\n",
      "Epoch 650/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7305 - accuracy: 0.7610 - val_loss: 2.4128 - val_accuracy: 0.4533\n",
      "Epoch 651/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6753 - accuracy: 0.7559 - val_loss: 2.4063 - val_accuracy: 0.4567\n",
      "Epoch 652/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6993 - accuracy: 0.7789 - val_loss: 2.3845 - val_accuracy: 0.4633\n",
      "Epoch 653/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7039 - accuracy: 0.7440 - val_loss: 2.4121 - val_accuracy: 0.4533\n",
      "Epoch 654/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7009 - accuracy: 0.7670 - val_loss: 2.4226 - val_accuracy: 0.4467\n",
      "Epoch 655/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.7569 - val_loss: 2.3914 - val_accuracy: 0.4567\n",
      "Epoch 656/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6430 - accuracy: 0.7591 - val_loss: 2.3980 - val_accuracy: 0.4500\n",
      "Epoch 657/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.7583 - val_loss: 2.4517 - val_accuracy: 0.4467\n",
      "Epoch 658/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6980 - accuracy: 0.7715 - val_loss: 2.4037 - val_accuracy: 0.4600\n",
      "Epoch 659/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7110 - accuracy: 0.7723 - val_loss: 2.4177 - val_accuracy: 0.4667\n",
      "Epoch 660/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6911 - accuracy: 0.7679 - val_loss: 2.3925 - val_accuracy: 0.4600\n",
      "Epoch 661/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7074 - accuracy: 0.7338 - val_loss: 2.4669 - val_accuracy: 0.4567\n",
      "Epoch 662/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6391 - accuracy: 0.7845 - val_loss: 2.4457 - val_accuracy: 0.4467\n",
      "Epoch 663/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6997 - accuracy: 0.7486 - val_loss: 2.4220 - val_accuracy: 0.4667\n",
      "Epoch 664/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6682 - accuracy: 0.7613 - val_loss: 2.4106 - val_accuracy: 0.4633\n",
      "Epoch 665/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7346 - accuracy: 0.7441 - val_loss: 2.4393 - val_accuracy: 0.4467\n",
      "Epoch 666/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7915 - val_loss: 2.4031 - val_accuracy: 0.4567\n",
      "Epoch 667/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7207 - accuracy: 0.7553 - val_loss: 2.4087 - val_accuracy: 0.4633\n",
      "Epoch 668/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6775 - accuracy: 0.7486 - val_loss: 2.4281 - val_accuracy: 0.4600\n",
      "Epoch 669/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6767 - accuracy: 0.7748 - val_loss: 2.4602 - val_accuracy: 0.4567\n",
      "Epoch 670/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6633 - accuracy: 0.7602 - val_loss: 2.4431 - val_accuracy: 0.4500\n",
      "Epoch 671/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.7813 - val_loss: 2.4427 - val_accuracy: 0.4633\n",
      "Epoch 672/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6670 - accuracy: 0.7814 - val_loss: 2.4280 - val_accuracy: 0.4600\n",
      "Epoch 673/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7428 - accuracy: 0.7454 - val_loss: 2.4316 - val_accuracy: 0.4733\n",
      "Epoch 674/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7152 - accuracy: 0.7605 - val_loss: 2.4395 - val_accuracy: 0.4500\n",
      "Epoch 675/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6631 - accuracy: 0.7712 - val_loss: 2.4220 - val_accuracy: 0.4700\n",
      "Epoch 676/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.7666 - val_loss: 2.4286 - val_accuracy: 0.4700\n",
      "Epoch 677/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6587 - accuracy: 0.7885 - val_loss: 2.4802 - val_accuracy: 0.4567\n",
      "Epoch 678/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7423 - accuracy: 0.7388 - val_loss: 2.4637 - val_accuracy: 0.4533\n",
      "Epoch 679/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6665 - accuracy: 0.7680 - val_loss: 2.4538 - val_accuracy: 0.4500\n",
      "Epoch 680/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6922 - accuracy: 0.7579 - val_loss: 2.4581 - val_accuracy: 0.4600\n",
      "Epoch 681/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.7987 - val_loss: 2.4503 - val_accuracy: 0.4600\n",
      "Epoch 682/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6863 - accuracy: 0.7652 - val_loss: 2.4407 - val_accuracy: 0.4600\n",
      "Epoch 683/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6956 - accuracy: 0.7509 - val_loss: 2.4610 - val_accuracy: 0.4733\n",
      "Epoch 684/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.7701 - val_loss: 2.4554 - val_accuracy: 0.4567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 685/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6994 - accuracy: 0.7586 - val_loss: 2.4572 - val_accuracy: 0.4667\n",
      "Epoch 686/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7021 - accuracy: 0.7538 - val_loss: 2.4742 - val_accuracy: 0.4700\n",
      "Epoch 687/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6770 - accuracy: 0.7896 - val_loss: 2.4385 - val_accuracy: 0.4667\n",
      "Epoch 688/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6991 - accuracy: 0.7732 - val_loss: 2.4550 - val_accuracy: 0.4533\n",
      "Epoch 689/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7044 - accuracy: 0.7669 - val_loss: 2.4569 - val_accuracy: 0.4600\n",
      "Epoch 690/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6975 - accuracy: 0.7635 - val_loss: 2.4740 - val_accuracy: 0.4600\n",
      "Epoch 691/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7219 - accuracy: 0.7452 - val_loss: 2.4656 - val_accuracy: 0.4533\n",
      "Epoch 692/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7350 - accuracy: 0.7434 - val_loss: 2.5125 - val_accuracy: 0.4500\n",
      "Epoch 693/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7229 - accuracy: 0.7730 - val_loss: 2.4864 - val_accuracy: 0.4467\n",
      "Epoch 694/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6673 - accuracy: 0.7700 - val_loss: 2.4782 - val_accuracy: 0.4567\n",
      "Epoch 695/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6326 - accuracy: 0.7709 - val_loss: 2.4678 - val_accuracy: 0.4700\n",
      "Epoch 696/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7030 - accuracy: 0.7620 - val_loss: 2.4960 - val_accuracy: 0.4600\n",
      "Epoch 697/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6576 - accuracy: 0.8007 - val_loss: 2.4355 - val_accuracy: 0.4633\n",
      "Epoch 698/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7082 - accuracy: 0.7624 - val_loss: 2.4911 - val_accuracy: 0.4567\n",
      "Epoch 699/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6467 - accuracy: 0.7755 - val_loss: 2.4957 - val_accuracy: 0.4467\n",
      "Epoch 700/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7304 - accuracy: 0.7365 - val_loss: 2.4781 - val_accuracy: 0.4533\n",
      "Epoch 701/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6642 - accuracy: 0.7788 - val_loss: 2.4800 - val_accuracy: 0.4600\n",
      "Epoch 702/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6944 - accuracy: 0.7655 - val_loss: 2.5114 - val_accuracy: 0.4533\n",
      "Epoch 703/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.7589 - val_loss: 2.4493 - val_accuracy: 0.4667\n",
      "Epoch 704/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7008 - accuracy: 0.7510 - val_loss: 2.5081 - val_accuracy: 0.4567\n",
      "Epoch 705/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6349 - accuracy: 0.7785 - val_loss: 2.4809 - val_accuracy: 0.4533\n",
      "Epoch 706/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7501 - accuracy: 0.7661 - val_loss: 2.4747 - val_accuracy: 0.4633\n",
      "Epoch 707/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7292 - accuracy: 0.7383 - val_loss: 2.5206 - val_accuracy: 0.4567\n",
      "Epoch 708/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7083 - accuracy: 0.7694 - val_loss: 2.4853 - val_accuracy: 0.4600\n",
      "Epoch 709/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6000 - accuracy: 0.8053 - val_loss: 2.5019 - val_accuracy: 0.4733\n",
      "Epoch 710/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.7710 - val_loss: 2.5065 - val_accuracy: 0.4600\n",
      "Epoch 711/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6778 - accuracy: 0.7571 - val_loss: 2.4766 - val_accuracy: 0.4633\n",
      "Epoch 712/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.7530 - val_loss: 2.4872 - val_accuracy: 0.4600\n",
      "Epoch 713/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6383 - accuracy: 0.7793 - val_loss: 2.5214 - val_accuracy: 0.4633\n",
      "Epoch 714/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6473 - accuracy: 0.7681 - val_loss: 2.4839 - val_accuracy: 0.4567\n",
      "Epoch 715/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.7797 - val_loss: 2.4990 - val_accuracy: 0.4567\n",
      "Epoch 716/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6119 - accuracy: 0.7933 - val_loss: 2.4914 - val_accuracy: 0.4633\n",
      "Epoch 717/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7880 - val_loss: 2.4715 - val_accuracy: 0.4567\n",
      "Epoch 718/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6436 - accuracy: 0.7835 - val_loss: 2.5000 - val_accuracy: 0.4567\n",
      "Epoch 719/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6823 - accuracy: 0.7894 - val_loss: 2.4939 - val_accuracy: 0.4633\n",
      "Epoch 720/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6445 - accuracy: 0.7845 - val_loss: 2.4993 - val_accuracy: 0.4600\n",
      "Epoch 721/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6716 - accuracy: 0.7484 - val_loss: 2.5226 - val_accuracy: 0.4600\n",
      "Epoch 722/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7037 - accuracy: 0.7624 - val_loss: 2.4939 - val_accuracy: 0.4533\n",
      "Epoch 723/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6686 - accuracy: 0.7596 - val_loss: 2.5008 - val_accuracy: 0.4567\n",
      "Epoch 724/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6970 - accuracy: 0.7484 - val_loss: 2.5169 - val_accuracy: 0.4600\n",
      "Epoch 725/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7093 - accuracy: 0.7608 - val_loss: 2.5315 - val_accuracy: 0.4667\n",
      "Epoch 726/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7311 - accuracy: 0.7564 - val_loss: 2.4933 - val_accuracy: 0.4567\n",
      "Epoch 727/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6224 - accuracy: 0.7873 - val_loss: 2.5230 - val_accuracy: 0.4600\n",
      "Epoch 728/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6695 - accuracy: 0.7593 - val_loss: 2.5388 - val_accuracy: 0.4567\n",
      "Epoch 729/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.7732 - val_loss: 2.5204 - val_accuracy: 0.4600\n",
      "Epoch 730/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6557 - accuracy: 0.7491 - val_loss: 2.5380 - val_accuracy: 0.4600\n",
      "Epoch 731/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7099 - accuracy: 0.7670 - val_loss: 2.5378 - val_accuracy: 0.4633\n",
      "Epoch 732/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6877 - accuracy: 0.7617 - val_loss: 2.5281 - val_accuracy: 0.4600\n",
      "Epoch 733/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6820 - accuracy: 0.7609 - val_loss: 2.5291 - val_accuracy: 0.4667\n",
      "Epoch 734/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6543 - accuracy: 0.7768 - val_loss: 2.5406 - val_accuracy: 0.4567\n",
      "Epoch 735/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.7834 - val_loss: 2.5350 - val_accuracy: 0.4600\n",
      "Epoch 736/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6885 - accuracy: 0.7687 - val_loss: 2.5427 - val_accuracy: 0.4567\n",
      "Epoch 737/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6671 - accuracy: 0.7681 - val_loss: 2.5434 - val_accuracy: 0.4633\n",
      "Epoch 738/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6814 - accuracy: 0.7401 - val_loss: 2.5303 - val_accuracy: 0.4633\n",
      "Epoch 739/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6816 - accuracy: 0.7775 - val_loss: 2.5398 - val_accuracy: 0.4533\n",
      "Epoch 740/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6646 - accuracy: 0.7764 - val_loss: 2.5411 - val_accuracy: 0.4567\n",
      "Epoch 741/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7121 - accuracy: 0.7726 - val_loss: 2.5278 - val_accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 742/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6527 - accuracy: 0.7833 - val_loss: 2.5216 - val_accuracy: 0.4567\n",
      "Epoch 743/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6431 - accuracy: 0.7827 - val_loss: 2.5739 - val_accuracy: 0.4600\n",
      "Epoch 744/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6712 - accuracy: 0.7877 - val_loss: 2.5408 - val_accuracy: 0.4600\n",
      "Epoch 745/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6763 - accuracy: 0.7754 - val_loss: 2.5635 - val_accuracy: 0.4633\n",
      "Epoch 746/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7115 - accuracy: 0.7341 - val_loss: 2.5359 - val_accuracy: 0.4700\n",
      "Epoch 747/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6476 - accuracy: 0.7931 - val_loss: 2.5511 - val_accuracy: 0.4633\n",
      "Epoch 748/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6758 - accuracy: 0.7446 - val_loss: 2.5592 - val_accuracy: 0.4533\n",
      "Epoch 749/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6795 - accuracy: 0.7802 - val_loss: 2.5444 - val_accuracy: 0.4567\n",
      "Epoch 750/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6386 - accuracy: 0.7637 - val_loss: 2.5488 - val_accuracy: 0.4567\n",
      "Epoch 751/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.7518 - val_loss: 2.5638 - val_accuracy: 0.4600\n",
      "Epoch 752/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6166 - accuracy: 0.7816 - val_loss: 2.5524 - val_accuracy: 0.4600\n",
      "Epoch 753/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6733 - accuracy: 0.7559 - val_loss: 2.5730 - val_accuracy: 0.4600\n",
      "Epoch 754/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6336 - accuracy: 0.7775 - val_loss: 2.5300 - val_accuracy: 0.4667\n",
      "Epoch 755/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5829 - accuracy: 0.8017 - val_loss: 2.5715 - val_accuracy: 0.4567\n",
      "Epoch 756/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.7935 - val_loss: 2.5685 - val_accuracy: 0.4633\n",
      "Epoch 757/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6786 - accuracy: 0.7752 - val_loss: 2.5992 - val_accuracy: 0.4600\n",
      "Epoch 758/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7138 - accuracy: 0.7731 - val_loss: 2.6156 - val_accuracy: 0.4633\n",
      "Epoch 759/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6644 - accuracy: 0.7622 - val_loss: 2.5602 - val_accuracy: 0.4567\n",
      "Epoch 760/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6750 - accuracy: 0.7679 - val_loss: 2.5800 - val_accuracy: 0.4600\n",
      "Epoch 761/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6209 - accuracy: 0.7866 - val_loss: 2.5831 - val_accuracy: 0.4600\n",
      "Epoch 762/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6294 - accuracy: 0.7976 - val_loss: 2.5631 - val_accuracy: 0.4567\n",
      "Epoch 763/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6870 - accuracy: 0.7708 - val_loss: 2.6012 - val_accuracy: 0.4633\n",
      "Epoch 764/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6352 - accuracy: 0.7738 - val_loss: 2.6000 - val_accuracy: 0.4567\n",
      "Epoch 765/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6432 - accuracy: 0.7883 - val_loss: 2.5986 - val_accuracy: 0.4600\n",
      "Epoch 766/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6268 - accuracy: 0.8000 - val_loss: 2.6116 - val_accuracy: 0.4567\n",
      "Epoch 767/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6361 - accuracy: 0.7787 - val_loss: 2.6034 - val_accuracy: 0.4567\n",
      "Epoch 768/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.7922 - val_loss: 2.6108 - val_accuracy: 0.4633\n",
      "Epoch 769/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7472 - accuracy: 0.7704 - val_loss: 2.5847 - val_accuracy: 0.4567\n",
      "Epoch 770/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5921 - accuracy: 0.7961 - val_loss: 2.6151 - val_accuracy: 0.4667\n",
      "Epoch 771/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6011 - accuracy: 0.7787 - val_loss: 2.5904 - val_accuracy: 0.4600\n",
      "Epoch 772/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7712 - val_loss: 2.5736 - val_accuracy: 0.4633\n",
      "Epoch 773/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6718 - accuracy: 0.7681 - val_loss: 2.5896 - val_accuracy: 0.4600\n",
      "Epoch 774/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.7552 - val_loss: 2.6110 - val_accuracy: 0.4633\n",
      "Epoch 775/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.7716 - val_loss: 2.5830 - val_accuracy: 0.4600\n",
      "Epoch 776/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.7454 - val_loss: 2.6027 - val_accuracy: 0.4600\n",
      "Epoch 777/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6825 - accuracy: 0.7813 - val_loss: 2.6001 - val_accuracy: 0.4600\n",
      "Epoch 778/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6732 - accuracy: 0.7620 - val_loss: 2.5573 - val_accuracy: 0.4533\n",
      "Epoch 779/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6827 - accuracy: 0.7688 - val_loss: 2.6054 - val_accuracy: 0.4633\n",
      "Epoch 780/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7341 - accuracy: 0.7509 - val_loss: 2.6209 - val_accuracy: 0.4600\n",
      "Epoch 781/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6574 - accuracy: 0.7770 - val_loss: 2.6099 - val_accuracy: 0.4600\n",
      "Epoch 782/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6218 - accuracy: 0.7702 - val_loss: 2.5980 - val_accuracy: 0.4600\n",
      "Epoch 783/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6455 - accuracy: 0.7642 - val_loss: 2.6449 - val_accuracy: 0.4633\n",
      "Epoch 784/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6979 - accuracy: 0.7612 - val_loss: 2.6242 - val_accuracy: 0.4600\n",
      "Epoch 785/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6572 - accuracy: 0.7586 - val_loss: 2.6246 - val_accuracy: 0.4633\n",
      "Epoch 786/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5892 - accuracy: 0.8043 - val_loss: 2.6075 - val_accuracy: 0.4667\n",
      "Epoch 787/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.7478 - val_loss: 2.6138 - val_accuracy: 0.4600\n",
      "Epoch 788/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6982 - accuracy: 0.7627 - val_loss: 2.6422 - val_accuracy: 0.4567\n",
      "Epoch 789/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6699 - accuracy: 0.7788 - val_loss: 2.6273 - val_accuracy: 0.4633\n",
      "Epoch 790/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6256 - accuracy: 0.7745 - val_loss: 2.6078 - val_accuracy: 0.4600\n",
      "Epoch 791/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6134 - accuracy: 0.7919 - val_loss: 2.6525 - val_accuracy: 0.4567\n",
      "Epoch 792/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.7655 - val_loss: 2.6443 - val_accuracy: 0.4633\n",
      "Epoch 793/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6480 - accuracy: 0.7779 - val_loss: 2.6172 - val_accuracy: 0.4633\n",
      "Epoch 794/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6378 - accuracy: 0.7660 - val_loss: 2.6203 - val_accuracy: 0.4700\n",
      "Epoch 795/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6934 - accuracy: 0.7656 - val_loss: 2.6344 - val_accuracy: 0.4600\n",
      "Epoch 796/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7286 - accuracy: 0.7714 - val_loss: 2.6400 - val_accuracy: 0.4533\n",
      "Epoch 797/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6505 - accuracy: 0.7937 - val_loss: 2.6284 - val_accuracy: 0.4633\n",
      "Epoch 798/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6381 - accuracy: 0.7598 - val_loss: 2.6421 - val_accuracy: 0.4600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 799/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6561 - accuracy: 0.7645 - val_loss: 2.6119 - val_accuracy: 0.4633\n",
      "Epoch 800/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6886 - accuracy: 0.7681 - val_loss: 2.6291 - val_accuracy: 0.4500\n",
      "Epoch 801/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6697 - accuracy: 0.7765 - val_loss: 2.6579 - val_accuracy: 0.4600\n",
      "Epoch 802/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.8011 - val_loss: 2.6292 - val_accuracy: 0.4567\n",
      "Epoch 803/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7884 - val_loss: 2.6666 - val_accuracy: 0.4600\n",
      "Epoch 804/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5972 - accuracy: 0.7893 - val_loss: 2.6591 - val_accuracy: 0.4600\n",
      "Epoch 805/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7124 - accuracy: 0.7718 - val_loss: 2.6304 - val_accuracy: 0.4467\n",
      "Epoch 806/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6293 - accuracy: 0.7920 - val_loss: 2.6358 - val_accuracy: 0.4567\n",
      "Epoch 807/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.7840 - val_loss: 2.6634 - val_accuracy: 0.4567\n",
      "Epoch 808/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6703 - accuracy: 0.7771 - val_loss: 2.6435 - val_accuracy: 0.4567\n",
      "Epoch 809/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6496 - accuracy: 0.7791 - val_loss: 2.6579 - val_accuracy: 0.4633\n",
      "Epoch 810/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6252 - accuracy: 0.7641 - val_loss: 2.6723 - val_accuracy: 0.4633\n",
      "Epoch 811/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6283 - accuracy: 0.7879 - val_loss: 2.6490 - val_accuracy: 0.4533\n",
      "Epoch 812/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6652 - accuracy: 0.7751 - val_loss: 2.6526 - val_accuracy: 0.4600\n",
      "Epoch 813/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.7744 - val_loss: 2.6720 - val_accuracy: 0.4533\n",
      "Epoch 814/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6227 - accuracy: 0.7986 - val_loss: 2.6840 - val_accuracy: 0.4533\n",
      "Epoch 815/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6509 - accuracy: 0.7536 - val_loss: 2.6668 - val_accuracy: 0.4567\n",
      "Epoch 816/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6103 - accuracy: 0.7664 - val_loss: 2.6796 - val_accuracy: 0.4567\n",
      "Epoch 817/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.7758 - val_loss: 2.6487 - val_accuracy: 0.4500\n",
      "Epoch 818/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6624 - accuracy: 0.7588 - val_loss: 2.6784 - val_accuracy: 0.4667\n",
      "Epoch 819/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6248 - accuracy: 0.7884 - val_loss: 2.6583 - val_accuracy: 0.4533\n",
      "Epoch 820/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.8007 - val_loss: 2.6487 - val_accuracy: 0.4500\n",
      "Epoch 821/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6751 - accuracy: 0.7640 - val_loss: 2.7177 - val_accuracy: 0.4500\n",
      "Epoch 822/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5805 - accuracy: 0.8178 - val_loss: 2.6833 - val_accuracy: 0.4533\n",
      "Epoch 823/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6537 - accuracy: 0.7863 - val_loss: 2.6756 - val_accuracy: 0.4600\n",
      "Epoch 824/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.7909 - val_loss: 2.7050 - val_accuracy: 0.4600\n",
      "Epoch 825/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6794 - accuracy: 0.7588 - val_loss: 2.6891 - val_accuracy: 0.4633\n",
      "Epoch 826/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5940 - accuracy: 0.8067 - val_loss: 2.6774 - val_accuracy: 0.4500\n",
      "Epoch 827/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6500 - accuracy: 0.7481 - val_loss: 2.6947 - val_accuracy: 0.4467\n",
      "Epoch 828/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6412 - accuracy: 0.7607 - val_loss: 2.6610 - val_accuracy: 0.4533\n",
      "Epoch 829/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.7829 - val_loss: 2.7002 - val_accuracy: 0.4667\n",
      "Epoch 830/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6419 - accuracy: 0.7806 - val_loss: 2.6805 - val_accuracy: 0.4600\n",
      "Epoch 831/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6195 - accuracy: 0.7913 - val_loss: 2.6857 - val_accuracy: 0.4567\n",
      "Epoch 832/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6481 - accuracy: 0.7749 - val_loss: 2.6960 - val_accuracy: 0.4533\n",
      "Epoch 833/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6523 - accuracy: 0.7574 - val_loss: 2.7059 - val_accuracy: 0.4600\n",
      "Epoch 834/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6684 - accuracy: 0.7747 - val_loss: 2.6967 - val_accuracy: 0.4533\n",
      "Epoch 835/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6225 - accuracy: 0.7837 - val_loss: 2.6904 - val_accuracy: 0.4500\n",
      "Epoch 836/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6575 - accuracy: 0.7763 - val_loss: 2.7124 - val_accuracy: 0.4600\n",
      "Epoch 837/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6247 - accuracy: 0.7700 - val_loss: 2.6770 - val_accuracy: 0.4533\n",
      "Epoch 838/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6222 - accuracy: 0.7913 - val_loss: 2.6997 - val_accuracy: 0.4567\n",
      "Epoch 839/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7324 - accuracy: 0.7443 - val_loss: 2.7060 - val_accuracy: 0.4567\n",
      "Epoch 840/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6603 - accuracy: 0.7409 - val_loss: 2.6902 - val_accuracy: 0.4500\n",
      "Epoch 841/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6923 - accuracy: 0.7805 - val_loss: 2.6737 - val_accuracy: 0.4600\n",
      "Epoch 842/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.7943 - val_loss: 2.7167 - val_accuracy: 0.4600\n",
      "Epoch 843/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6066 - accuracy: 0.7639 - val_loss: 2.7205 - val_accuracy: 0.4533\n",
      "Epoch 844/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5920 - accuracy: 0.7752 - val_loss: 2.6957 - val_accuracy: 0.4533\n",
      "Epoch 845/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7136 - accuracy: 0.7656 - val_loss: 2.7078 - val_accuracy: 0.4567\n",
      "Epoch 846/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.7828 - val_loss: 2.7017 - val_accuracy: 0.4533\n",
      "Epoch 847/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6584 - accuracy: 0.7951 - val_loss: 2.7108 - val_accuracy: 0.4533\n",
      "Epoch 848/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5953 - accuracy: 0.8039 - val_loss: 2.7454 - val_accuracy: 0.4633\n",
      "Epoch 849/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.7978 - val_loss: 2.7020 - val_accuracy: 0.4567\n",
      "Epoch 850/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6332 - accuracy: 0.7746 - val_loss: 2.7100 - val_accuracy: 0.4533\n",
      "Epoch 851/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7089 - accuracy: 0.7766 - val_loss: 2.7040 - val_accuracy: 0.4533\n",
      "Epoch 852/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6443 - accuracy: 0.7600 - val_loss: 2.7355 - val_accuracy: 0.4533\n",
      "Epoch 853/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5856 - accuracy: 0.8211 - val_loss: 2.7236 - val_accuracy: 0.4567\n",
      "Epoch 854/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6369 - accuracy: 0.7657 - val_loss: 2.7364 - val_accuracy: 0.4533\n",
      "Epoch 855/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6611 - accuracy: 0.7830 - val_loss: 2.7140 - val_accuracy: 0.4533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 856/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6428 - accuracy: 0.7865 - val_loss: 2.7339 - val_accuracy: 0.4533\n",
      "Epoch 857/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.8046 - val_loss: 2.7137 - val_accuracy: 0.4567\n",
      "Epoch 858/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6528 - accuracy: 0.7642 - val_loss: 2.7231 - val_accuracy: 0.4533\n",
      "Epoch 859/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.8000 - val_loss: 2.7080 - val_accuracy: 0.4533\n",
      "Epoch 860/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6303 - accuracy: 0.7877 - val_loss: 2.7179 - val_accuracy: 0.4500\n",
      "Epoch 861/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6617 - accuracy: 0.7779 - val_loss: 2.7128 - val_accuracy: 0.4533\n",
      "Epoch 862/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6441 - accuracy: 0.7983 - val_loss: 2.7267 - val_accuracy: 0.4533\n",
      "Epoch 863/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6382 - accuracy: 0.7902 - val_loss: 2.7636 - val_accuracy: 0.4600\n",
      "Epoch 864/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6333 - accuracy: 0.7710 - val_loss: 2.7144 - val_accuracy: 0.4567\n",
      "Epoch 865/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6685 - accuracy: 0.7995 - val_loss: 2.7472 - val_accuracy: 0.4567\n",
      "Epoch 866/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6156 - accuracy: 0.7799 - val_loss: 2.7379 - val_accuracy: 0.4500\n",
      "Epoch 867/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6602 - accuracy: 0.7640 - val_loss: 2.7435 - val_accuracy: 0.4500\n",
      "Epoch 868/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6139 - accuracy: 0.7994 - val_loss: 2.7479 - val_accuracy: 0.4567\n",
      "Epoch 869/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7077 - accuracy: 0.7548 - val_loss: 2.7875 - val_accuracy: 0.4567\n",
      "Epoch 870/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6493 - accuracy: 0.7747 - val_loss: 2.7251 - val_accuracy: 0.4533\n",
      "Epoch 871/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6549 - accuracy: 0.7984 - val_loss: 2.7625 - val_accuracy: 0.4567\n",
      "Epoch 872/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6039 - accuracy: 0.7997 - val_loss: 2.7529 - val_accuracy: 0.4567\n",
      "Epoch 873/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5770 - accuracy: 0.8065 - val_loss: 2.7567 - val_accuracy: 0.4567\n",
      "Epoch 874/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6653 - accuracy: 0.7757 - val_loss: 2.7607 - val_accuracy: 0.4567\n",
      "Epoch 875/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6159 - accuracy: 0.7751 - val_loss: 2.7814 - val_accuracy: 0.4633\n",
      "Epoch 876/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6519 - accuracy: 0.7828 - val_loss: 2.7804 - val_accuracy: 0.4567\n",
      "Epoch 877/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.7905 - val_loss: 2.7484 - val_accuracy: 0.4567\n",
      "Epoch 878/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6009 - accuracy: 0.7957 - val_loss: 2.7416 - val_accuracy: 0.4533\n",
      "Epoch 879/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6437 - accuracy: 0.7809 - val_loss: 2.7438 - val_accuracy: 0.4567\n",
      "Epoch 880/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5916 - accuracy: 0.8047 - val_loss: 2.7838 - val_accuracy: 0.4533\n",
      "Epoch 881/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6128 - accuracy: 0.7668 - val_loss: 2.7702 - val_accuracy: 0.4500\n",
      "Epoch 882/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6334 - accuracy: 0.7852 - val_loss: 2.7545 - val_accuracy: 0.4467\n",
      "Epoch 883/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5778 - accuracy: 0.7973 - val_loss: 2.7859 - val_accuracy: 0.4533\n",
      "Epoch 884/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.7580 - val_loss: 2.7727 - val_accuracy: 0.4567\n",
      "Epoch 885/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6849 - accuracy: 0.7742 - val_loss: 2.7746 - val_accuracy: 0.4567\n",
      "Epoch 886/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6604 - accuracy: 0.7747 - val_loss: 2.7642 - val_accuracy: 0.4533\n",
      "Epoch 887/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.7692 - val_loss: 2.7815 - val_accuracy: 0.4533\n",
      "Epoch 888/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7251 - accuracy: 0.7735 - val_loss: 2.7553 - val_accuracy: 0.4533\n",
      "Epoch 889/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6844 - accuracy: 0.7588 - val_loss: 2.7616 - val_accuracy: 0.4533\n",
      "Epoch 890/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.7810 - val_loss: 2.7676 - val_accuracy: 0.4567\n",
      "Epoch 891/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6449 - accuracy: 0.7860 - val_loss: 2.7773 - val_accuracy: 0.4567\n",
      "Epoch 892/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6373 - accuracy: 0.7719 - val_loss: 2.7919 - val_accuracy: 0.4567\n",
      "Epoch 893/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6551 - accuracy: 0.7543 - val_loss: 2.7669 - val_accuracy: 0.4533\n",
      "Epoch 894/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6562 - accuracy: 0.7909 - val_loss: 2.7986 - val_accuracy: 0.4533\n",
      "Epoch 895/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7836 - val_loss: 2.7689 - val_accuracy: 0.4567\n",
      "Epoch 896/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6577 - accuracy: 0.7899 - val_loss: 2.7705 - val_accuracy: 0.4567\n",
      "Epoch 897/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6743 - accuracy: 0.7586 - val_loss: 2.8214 - val_accuracy: 0.4500\n",
      "Epoch 898/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7109 - accuracy: 0.7495 - val_loss: 2.8289 - val_accuracy: 0.4567\n",
      "Epoch 899/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6416 - accuracy: 0.7783 - val_loss: 2.7840 - val_accuracy: 0.4500\n",
      "Epoch 900/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.7992 - val_loss: 2.8036 - val_accuracy: 0.4533\n",
      "Epoch 901/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.7747 - val_loss: 2.7712 - val_accuracy: 0.4467\n",
      "Epoch 902/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.7729 - val_loss: 2.7817 - val_accuracy: 0.4500\n",
      "Epoch 903/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6424 - accuracy: 0.7711 - val_loss: 2.7988 - val_accuracy: 0.4600\n",
      "Epoch 904/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6313 - accuracy: 0.7860 - val_loss: 2.8031 - val_accuracy: 0.4567\n",
      "Epoch 905/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.7641 - val_loss: 2.7908 - val_accuracy: 0.4500\n",
      "Epoch 906/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6449 - accuracy: 0.7657 - val_loss: 2.7940 - val_accuracy: 0.4533\n",
      "Epoch 907/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6172 - accuracy: 0.7750 - val_loss: 2.8062 - val_accuracy: 0.4567\n",
      "Epoch 908/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6595 - accuracy: 0.7479 - val_loss: 2.8197 - val_accuracy: 0.4533\n",
      "Epoch 909/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6045 - accuracy: 0.7690 - val_loss: 2.8501 - val_accuracy: 0.4567\n",
      "Epoch 910/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6569 - accuracy: 0.7727 - val_loss: 2.8087 - val_accuracy: 0.4467\n",
      "Epoch 911/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6254 - accuracy: 0.7803 - val_loss: 2.8491 - val_accuracy: 0.4567\n",
      "Epoch 912/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6379 - accuracy: 0.7895 - val_loss: 2.7929 - val_accuracy: 0.4567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 913/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6709 - accuracy: 0.8007 - val_loss: 2.8091 - val_accuracy: 0.4500\n",
      "Epoch 914/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.7943 - val_loss: 2.8146 - val_accuracy: 0.4500\n",
      "Epoch 915/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6495 - accuracy: 0.7800 - val_loss: 2.8442 - val_accuracy: 0.4567\n",
      "Epoch 916/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6314 - accuracy: 0.7832 - val_loss: 2.8196 - val_accuracy: 0.4533\n",
      "Epoch 917/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5766 - accuracy: 0.8142 - val_loss: 2.8196 - val_accuracy: 0.4600\n",
      "Epoch 918/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.7880 - val_loss: 2.8449 - val_accuracy: 0.4567\n",
      "Epoch 919/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6258 - accuracy: 0.7759 - val_loss: 2.8334 - val_accuracy: 0.4567\n",
      "Epoch 920/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6047 - accuracy: 0.7795 - val_loss: 2.8297 - val_accuracy: 0.4567\n",
      "Epoch 921/1000\n",
      "70/70 [==============================] - ETA: 0s - loss: 0.2435 - accuracy: 0.90 - 0s 1ms/step - loss: 0.5901 - accuracy: 0.7771 - val_loss: 2.8407 - val_accuracy: 0.4567\n",
      "Epoch 922/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6627 - accuracy: 0.7665 - val_loss: 2.8256 - val_accuracy: 0.4567\n",
      "Epoch 923/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6486 - accuracy: 0.7745 - val_loss: 2.8241 - val_accuracy: 0.4533\n",
      "Epoch 924/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6219 - accuracy: 0.7911 - val_loss: 2.7783 - val_accuracy: 0.4500\n",
      "Epoch 925/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6479 - accuracy: 0.7740 - val_loss: 2.8253 - val_accuracy: 0.4500\n",
      "Epoch 926/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6328 - accuracy: 0.7822 - val_loss: 2.7922 - val_accuracy: 0.4500\n",
      "Epoch 927/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6358 - accuracy: 0.7836 - val_loss: 2.8169 - val_accuracy: 0.4600\n",
      "Epoch 928/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5925 - accuracy: 0.7719 - val_loss: 2.8230 - val_accuracy: 0.4500\n",
      "Epoch 929/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6298 - accuracy: 0.7715 - val_loss: 2.8355 - val_accuracy: 0.4533\n",
      "Epoch 930/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6573 - accuracy: 0.7579 - val_loss: 2.8485 - val_accuracy: 0.4533\n",
      "Epoch 931/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6170 - accuracy: 0.7946 - val_loss: 2.7937 - val_accuracy: 0.4433\n",
      "Epoch 932/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6408 - accuracy: 0.7836 - val_loss: 2.8528 - val_accuracy: 0.4533\n",
      "Epoch 933/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6102 - accuracy: 0.7711 - val_loss: 2.8414 - val_accuracy: 0.4533\n",
      "Epoch 934/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6374 - accuracy: 0.7679 - val_loss: 2.8637 - val_accuracy: 0.4500\n",
      "Epoch 935/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6451 - accuracy: 0.7664 - val_loss: 2.8319 - val_accuracy: 0.4533\n",
      "Epoch 936/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5714 - accuracy: 0.7959 - val_loss: 2.8176 - val_accuracy: 0.4500\n",
      "Epoch 937/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6566 - accuracy: 0.7466 - val_loss: 2.8521 - val_accuracy: 0.4567\n",
      "Epoch 938/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5915 - accuracy: 0.7952 - val_loss: 2.8704 - val_accuracy: 0.4567\n",
      "Epoch 939/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6440 - accuracy: 0.7818 - val_loss: 2.8505 - val_accuracy: 0.4567\n",
      "Epoch 940/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6345 - accuracy: 0.7740 - val_loss: 2.8324 - val_accuracy: 0.4500\n",
      "Epoch 941/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.7739 - val_loss: 2.8503 - val_accuracy: 0.4533\n",
      "Epoch 942/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6003 - accuracy: 0.7779 - val_loss: 2.8435 - val_accuracy: 0.4533\n",
      "Epoch 943/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6187 - accuracy: 0.7874 - val_loss: 2.8434 - val_accuracy: 0.4533\n",
      "Epoch 944/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.8072 - val_loss: 2.8300 - val_accuracy: 0.4533\n",
      "Epoch 945/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6019 - accuracy: 0.7833 - val_loss: 2.8557 - val_accuracy: 0.4600\n",
      "Epoch 946/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5427 - accuracy: 0.8168 - val_loss: 2.8583 - val_accuracy: 0.4500\n",
      "Epoch 947/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6249 - accuracy: 0.7778 - val_loss: 2.8564 - val_accuracy: 0.4433\n",
      "Epoch 948/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6580 - accuracy: 0.7637 - val_loss: 2.8540 - val_accuracy: 0.4500\n",
      "Epoch 949/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6127 - accuracy: 0.7835 - val_loss: 2.8399 - val_accuracy: 0.4500\n",
      "Epoch 950/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6250 - accuracy: 0.7735 - val_loss: 2.8514 - val_accuracy: 0.4533\n",
      "Epoch 951/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6398 - accuracy: 0.7756 - val_loss: 2.8453 - val_accuracy: 0.4533\n",
      "Epoch 952/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6654 - accuracy: 0.7845 - val_loss: 2.8885 - val_accuracy: 0.4533\n",
      "Epoch 953/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6512 - accuracy: 0.7928 - val_loss: 2.8821 - val_accuracy: 0.4600\n",
      "Epoch 954/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6583 - accuracy: 0.7535 - val_loss: 2.8907 - val_accuracy: 0.4533\n",
      "Epoch 955/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6824 - accuracy: 0.7654 - val_loss: 2.8657 - val_accuracy: 0.4500\n",
      "Epoch 956/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.7875 - val_loss: 2.8867 - val_accuracy: 0.4533\n",
      "Epoch 957/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.7780 - val_loss: 2.8795 - val_accuracy: 0.4533\n",
      "Epoch 958/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5485 - accuracy: 0.8144 - val_loss: 2.9163 - val_accuracy: 0.4467\n",
      "Epoch 959/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6264 - accuracy: 0.7999 - val_loss: 2.8718 - val_accuracy: 0.4500\n",
      "Epoch 960/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5865 - accuracy: 0.8171 - val_loss: 2.8836 - val_accuracy: 0.4433\n",
      "Epoch 961/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5880 - accuracy: 0.7908 - val_loss: 2.8543 - val_accuracy: 0.4467\n",
      "Epoch 962/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6048 - accuracy: 0.7822 - val_loss: 2.8866 - val_accuracy: 0.4567\n",
      "Epoch 963/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6366 - accuracy: 0.7797 - val_loss: 2.8887 - val_accuracy: 0.4533\n",
      "Epoch 964/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6001 - accuracy: 0.7994 - val_loss: 2.9045 - val_accuracy: 0.4467\n",
      "Epoch 965/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6091 - accuracy: 0.7859 - val_loss: 2.9195 - val_accuracy: 0.4500\n",
      "Epoch 966/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6308 - accuracy: 0.7979 - val_loss: 2.8661 - val_accuracy: 0.4467\n",
      "Epoch 967/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6397 - accuracy: 0.7526 - val_loss: 2.8747 - val_accuracy: 0.4567\n",
      "Epoch 968/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5845 - accuracy: 0.7819 - val_loss: 2.8932 - val_accuracy: 0.4533\n",
      "Epoch 969/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5943 - accuracy: 0.8005 - val_loss: 2.9154 - val_accuracy: 0.4533\n",
      "Epoch 970/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.7951 - val_loss: 2.8965 - val_accuracy: 0.4533\n",
      "Epoch 971/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6167 - accuracy: 0.7831 - val_loss: 2.8706 - val_accuracy: 0.4467\n",
      "Epoch 972/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5542 - accuracy: 0.8060 - val_loss: 2.8827 - val_accuracy: 0.4500\n",
      "Epoch 973/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6221 - accuracy: 0.7763 - val_loss: 2.9180 - val_accuracy: 0.4533\n",
      "Epoch 974/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5675 - accuracy: 0.8013 - val_loss: 2.8802 - val_accuracy: 0.4467\n",
      "Epoch 975/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6526 - accuracy: 0.7675 - val_loss: 2.8922 - val_accuracy: 0.4567\n",
      "Epoch 976/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6286 - accuracy: 0.7752 - val_loss: 2.8851 - val_accuracy: 0.4467\n",
      "Epoch 977/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.8113 - val_loss: 2.9370 - val_accuracy: 0.4500\n",
      "Epoch 978/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6498 - accuracy: 0.7692 - val_loss: 2.9194 - val_accuracy: 0.4467\n",
      "Epoch 979/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6513 - accuracy: 0.7860 - val_loss: 2.9205 - val_accuracy: 0.4433\n",
      "Epoch 980/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6491 - accuracy: 0.7670 - val_loss: 2.9396 - val_accuracy: 0.4500\n",
      "Epoch 981/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5839 - accuracy: 0.8128 - val_loss: 2.9292 - val_accuracy: 0.4533\n",
      "Epoch 982/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5930 - accuracy: 0.7971 - val_loss: 2.8998 - val_accuracy: 0.4567\n",
      "Epoch 983/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5633 - accuracy: 0.8036 - val_loss: 2.9002 - val_accuracy: 0.4467\n",
      "Epoch 984/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.8105 - val_loss: 2.9157 - val_accuracy: 0.4567\n",
      "Epoch 985/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.8155 - val_loss: 2.9364 - val_accuracy: 0.4567\n",
      "Epoch 986/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.7735 - val_loss: 2.8918 - val_accuracy: 0.4467\n",
      "Epoch 987/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6297 - accuracy: 0.7746 - val_loss: 2.9022 - val_accuracy: 0.4467\n",
      "Epoch 988/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.7055 - accuracy: 0.7905 - val_loss: 2.8959 - val_accuracy: 0.4533\n",
      "Epoch 989/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6261 - accuracy: 0.7647 - val_loss: 2.8823 - val_accuracy: 0.4533\n",
      "Epoch 990/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.8082 - val_loss: 2.9107 - val_accuracy: 0.4567\n",
      "Epoch 991/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6272 - accuracy: 0.7962 - val_loss: 2.9245 - val_accuracy: 0.4500\n",
      "Epoch 992/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.7916 - val_loss: 2.9085 - val_accuracy: 0.4533\n",
      "Epoch 993/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6835 - accuracy: 0.7728 - val_loss: 2.9469 - val_accuracy: 0.4500\n",
      "Epoch 994/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6315 - accuracy: 0.7628 - val_loss: 2.9113 - val_accuracy: 0.4500\n",
      "Epoch 995/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5481 - accuracy: 0.8238 - val_loss: 2.9353 - val_accuracy: 0.4567\n",
      "Epoch 996/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5875 - accuracy: 0.8166 - val_loss: 2.9107 - val_accuracy: 0.4567\n",
      "Epoch 997/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6216 - accuracy: 0.7852 - val_loss: 2.9120 - val_accuracy: 0.4500\n",
      "Epoch 998/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6114 - accuracy: 0.8075 - val_loss: 2.9211 - val_accuracy: 0.4533\n",
      "Epoch 999/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.5874 - accuracy: 0.7954 - val_loss: 2.9386 - val_accuracy: 0.4567\n",
      "Epoch 1000/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.6335 - accuracy: 0.7759 - val_loss: 2.9431 - val_accuracy: 0.4533\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val,Y_val))  #val_accuracy (이 데이터의 accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 모델학습과정 표시하고 평가하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:17:33.360709Z",
     "start_time": "2021-03-23T08:17:33.351733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:16:55.634674Z",
     "start_time": "2021-03-23T08:16:55.490731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec87431340>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 학습과정 표시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:38:31.391513Z",
     "start_time": "2021-03-23T08:38:31.114227Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ec894c9b50>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#학습과정 표시하기 \n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y',label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')   #val_loss 검증셋 데이어틔 loss   #200번이 넘어가면서 너무 과적합해서 loss가 높아져. 회귀선과 더 멀어짐\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx()  #x축을 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r', label=\"val accuracy\") # accuracy 저조함. 좋은 model 아님.\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 모델 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:43:50.480841Z",
     "start_time": "2021-03-23T08:43:50.047878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 902us/step - loss: 2.8772 - accuracy: 0.4572\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(X_test,Y_test, batch_size=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:44:48.796581Z",
     "start_time": "2021-03-23T08:44:48.790570Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.8772237300872803\n",
      "accuracy: 0.45719999074935913\n"
     ]
    }
   ],
   "source": [
    "print(\"loss:\",loss_and_metrics[0])\n",
    "print(\"accuracy:\",loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 모델 저장 및 로드 하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:46:57.693824Z",
     "start_time": "2021-03-23T08:46:57.451155Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"model/mnist.h5\")  #모델 저장 확장자 반드시 h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:47:36.661570Z",
     "start_time": "2021-03-23T08:47:36.647633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #1600개의 parameter가 위 파일에 저장됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:52:32.564834Z",
     "start_time": "2021-03-23T08:52:32.521968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 2)                 1570      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                30        \n",
      "=================================================================\n",
      "Total params: 1,600\n",
      "Trainable params: 1,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model2 = load_model('model/mnist.h5')\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:58:59.562178Z",
     "start_time": "2021-03-23T08:58:59.430556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec898678b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_val[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:59:42.066481Z",
     "start_time": "2021-03-23T08:59:42.015763Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.8426542e-16 7.6384978e-08 1.2891388e-16 6.1608213e-01 3.0301299e-13\n",
      "  3.7959701e-01 2.9767171e-21 2.7831702e-14 7.7697320e-04 3.5438894e-03]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model2.predict(X_val[3].reshape(1,784))   #784= 28x28   데이터를1차원으로 한꺼번에 \n",
    "print(result)\n",
    "result.argmax()  #3번째 방이 제일큼 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T08:59:52.652517Z",
     "start_time": "2021-03-23T08:59:52.639526Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val[3].argmax()    #train data가 비교적 잘 맞추고, val data가 잘 못맞춰   # 그 다음 5번째 방이 제일큼    (큰 확율 순!!!!!!!) 그러나 잘못맞춤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "argmax를 하거나 predict_classes를 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T09:03:22.092284Z",
     "start_time": "2021-03-23T09:03:22.004940Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict_classes(X_val[0].reshape(1,784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 콜백 함수 \n",
    "- 과적합 전 끝내는것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:19:04.666383Z",
     "start_time": "2021-03-24T01:17:52.150585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss:2.27363657951355,val_loss:2.2613964080810547\n",
      "epoch:10, loss:2.0432112216949463,val_loss:2.0891339778900146\n",
      "epoch:20, loss:1.6864959001541138,val_loss:1.7343831062316895\n",
      "epoch:30, loss:1.4752174615859985,val_loss:1.5322518348693848\n",
      "epoch:40, loss:1.3572018146514893,val_loss:1.4546211957931519\n",
      "epoch:50, loss:1.2775120735168457,val_loss:1.3961310386657715\n",
      "epoch:60, loss:1.219902753829956,val_loss:1.365174651145935\n",
      "epoch:70, loss:1.1708508729934692,val_loss:1.3441760540008545\n",
      "epoch:80, loss:1.1309314966201782,val_loss:1.3395460844039917\n",
      "epoch:90, loss:1.1003856658935547,val_loss:1.3274224996566772\n",
      "epoch:100, loss:1.0735549926757812,val_loss:1.3195595741271973\n",
      "epoch:110, loss:1.0487405061721802,val_loss:1.3278790712356567\n",
      "epoch:120, loss:1.0258347988128662,val_loss:1.3181134462356567\n",
      "epoch:130, loss:1.0057474374771118,val_loss:1.3184642791748047\n",
      "epoch:140, loss:0.9875425696372986,val_loss:1.325779676437378\n",
      "epoch:150, loss:0.9711853861808777,val_loss:1.334330677986145\n",
      "epoch:160, loss:0.9548929333686829,val_loss:1.3327677249908447\n",
      "epoch:170, loss:0.9393771886825562,val_loss:1.3313747644424438\n",
      "epoch:180, loss:0.9249306917190552,val_loss:1.3424440622329712\n",
      "epoch:190, loss:0.9116843938827515,val_loss:1.3468594551086426\n",
      "epoch:200, loss:0.8986675143241882,val_loss:1.3500438928604126\n",
      "epoch:210, loss:0.8872514963150024,val_loss:1.369778037071228\n",
      "epoch:220, loss:0.8762903809547424,val_loss:1.369803786277771\n",
      "epoch:230, loss:0.8654154539108276,val_loss:1.3766906261444092\n",
      "epoch:240, loss:0.8560172915458679,val_loss:1.3857460021972656\n",
      "epoch:250, loss:0.8466717600822449,val_loss:1.3895009756088257\n",
      "epoch:260, loss:0.8353914022445679,val_loss:1.4114819765090942\n",
      "epoch:270, loss:0.8287612199783325,val_loss:1.409395694732666\n",
      "epoch:280, loss:0.8202829360961914,val_loss:1.422035574913025\n",
      "epoch:290, loss:0.8126190900802612,val_loss:1.424633264541626\n",
      "epoch:300, loss:0.8049442768096924,val_loss:1.4404106140136719\n",
      "epoch:310, loss:0.7959020733833313,val_loss:1.4491920471191406\n",
      "epoch:320, loss:0.7901027798652649,val_loss:1.4603703022003174\n",
      "epoch:330, loss:0.7830682396888733,val_loss:1.468718409538269\n",
      "epoch:340, loss:0.7769472002983093,val_loss:1.4860236644744873\n",
      "epoch:350, loss:0.7707768678665161,val_loss:1.4989204406738281\n",
      "epoch:360, loss:0.764458179473877,val_loss:1.5061544179916382\n",
      "epoch:370, loss:0.7585451602935791,val_loss:1.5211564302444458\n",
      "epoch:380, loss:0.7534383535385132,val_loss:1.5261403322219849\n",
      "epoch:390, loss:0.7481386661529541,val_loss:1.5325270891189575\n",
      "epoch:400, loss:0.7431241869926453,val_loss:1.5312141180038452\n",
      "epoch:410, loss:0.7379986643791199,val_loss:1.5484760999679565\n",
      "epoch:420, loss:0.7328395247459412,val_loss:1.5679428577423096\n",
      "epoch:430, loss:0.7285558581352234,val_loss:1.5651072263717651\n",
      "epoch:440, loss:0.7233462333679199,val_loss:1.5682576894760132\n",
      "epoch:450, loss:0.719255268573761,val_loss:1.5777838230133057\n",
      "epoch:460, loss:0.7152542471885681,val_loss:1.594253420829773\n",
      "epoch:470, loss:0.70915287733078,val_loss:1.6132315397262573\n",
      "epoch:480, loss:0.7058310508728027,val_loss:1.6239008903503418\n",
      "epoch:490, loss:0.7019796967506409,val_loss:1.619161605834961\n",
      "epoch:500, loss:0.6940888166427612,val_loss:1.642613172531128\n",
      "epoch:510, loss:0.6894367337226868,val_loss:1.6387442350387573\n",
      "epoch:520, loss:0.6845949292182922,val_loss:1.6545464992523193\n",
      "epoch:530, loss:0.6806766390800476,val_loss:1.6655290126800537\n",
      "epoch:540, loss:0.6769940853118896,val_loss:1.6688693761825562\n",
      "epoch:550, loss:0.6731141209602356,val_loss:1.6786915063858032\n",
      "epoch:560, loss:0.669792890548706,val_loss:1.686057448387146\n",
      "epoch:570, loss:0.6653928756713867,val_loss:1.7064129114151\n",
      "epoch:580, loss:0.6622170805931091,val_loss:1.7131839990615845\n",
      "epoch:590, loss:0.6585134267807007,val_loss:1.7083299160003662\n",
      "epoch:600, loss:0.6555129289627075,val_loss:1.7268118858337402\n",
      "epoch:610, loss:0.6525176167488098,val_loss:1.736967921257019\n",
      "epoch:620, loss:0.6500274538993835,val_loss:1.7406806945800781\n",
      "epoch:630, loss:0.6468145847320557,val_loss:1.7458409070968628\n",
      "epoch:640, loss:0.6443995833396912,val_loss:1.7580214738845825\n",
      "epoch:650, loss:0.6411232352256775,val_loss:1.7676169872283936\n",
      "epoch:660, loss:0.6385472416877747,val_loss:1.7852078676223755\n",
      "epoch:670, loss:0.6361943483352661,val_loss:1.7815099954605103\n",
      "epoch:680, loss:0.6340633630752563,val_loss:1.7856180667877197\n",
      "epoch:690, loss:0.6313750147819519,val_loss:1.7948936223983765\n",
      "epoch:700, loss:0.6289141178131104,val_loss:1.8146313428878784\n",
      "epoch:710, loss:0.6262581944465637,val_loss:1.803991675376892\n",
      "epoch:720, loss:0.6246205568313599,val_loss:1.8127127885818481\n",
      "epoch:730, loss:0.6224071383476257,val_loss:1.818809151649475\n",
      "epoch:740, loss:0.6206703186035156,val_loss:1.8306167125701904\n",
      "epoch:750, loss:0.6184902787208557,val_loss:1.854945421218872\n",
      "epoch:760, loss:0.6161063313484192,val_loss:1.858720302581787\n",
      "epoch:770, loss:0.6143662929534912,val_loss:1.8619663715362549\n",
      "epoch:780, loss:0.6122738718986511,val_loss:1.8579622507095337\n",
      "epoch:790, loss:0.6102098822593689,val_loss:1.8789715766906738\n",
      "epoch:800, loss:0.608748197555542,val_loss:1.8836055994033813\n",
      "epoch:810, loss:0.6068574786186218,val_loss:1.8908815383911133\n",
      "epoch:820, loss:0.6047661900520325,val_loss:1.8940017223358154\n",
      "epoch:830, loss:0.6032149195671082,val_loss:1.899339199066162\n",
      "epoch:840, loss:0.6010377407073975,val_loss:1.9146449565887451\n",
      "epoch:850, loss:0.5991438627243042,val_loss:1.9172359704971313\n",
      "epoch:860, loss:0.5968905687332153,val_loss:1.9264488220214844\n",
      "epoch:870, loss:0.5951006412506104,val_loss:1.9435557126998901\n",
      "epoch:880, loss:0.5935337543487549,val_loss:1.945034384727478\n",
      "epoch:890, loss:0.5915807485580444,val_loss:1.9631788730621338\n",
      "epoch:900, loss:0.5901477336883545,val_loss:1.9591220617294312\n",
      "epoch:910, loss:0.5882851481437683,val_loss:1.9752568006515503\n",
      "epoch:920, loss:0.5875102281570435,val_loss:1.9627339839935303\n",
      "epoch:930, loss:0.5853433012962341,val_loss:1.9846217632293701\n",
      "epoch:940, loss:0.5841325521469116,val_loss:1.9907450675964355\n",
      "epoch:950, loss:0.5827139019966125,val_loss:1.9812262058258057\n",
      "epoch:960, loss:0.5815131664276123,val_loss:1.996476411819458\n",
      "epoch:970, loss:0.5801290273666382,val_loss:2.007366895675659\n",
      "epoch:980, loss:0.5782854557037354,val_loss:2.0037691593170166\n",
      "epoch:990, loss:0.577009916305542,val_loss:2.027773857116699\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "class CustomHistory(tf.keras.callbacks.Callback):   #Callback으로 부터 상속 받은 CustomHistory\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []  # 변수를 만들어줌\n",
    "        self.val_acc = [] \n",
    "    def on_epoch_end(self,batch,logs={}):   #Callback안에 있는 함수 override. 한 epoch끝날때 마다 logs에있는 loss를 train_loss에  apppend,#logs에있는 loss를 val_loss에  apppend\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('accuracy')) \n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        if self.epoch % 10 == 0:  #10으로 나누어지면\n",
    "            print(\"epoch:{}, loss:{},val_loss:{}\".format(self.epoch,logs.get('loss'),logs.get('val_loss')\n",
    "                                                        ))\n",
    "        self.epoch += 1  #epoch 하나씩 늘고 \n",
    "\n",
    "# 1. 데이터 셋 준비하기 \n",
    "# 훈련셋, 검증셋 분리 \n",
    "(X_train, Y_train), (X_test,Y_test) = mnist.load_data() \n",
    "\n",
    "# 훈련셋과 검증셋 분리  (X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]  #50000개부터 끝까지 \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "        \n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32')/255.0    #0부터255너무떨어져있어서 나눠서 normalization ***\n",
    "X_val = X_val.reshape(10000,784).astype('float32')/255.0  # '데이터 784개' 한꺼번에 1차원으로 들어가  *******************************************\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0 \n",
    "        \n",
    "\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴 \n",
    "#1부터50000까지 700개를 random하게 뽑자\n",
    "train_rand_idxs = np.random.choice(50000,700) \n",
    "val_rand_idxs = np.random.choice(10000,300) \n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "#300개의 index만 사용\n",
    "X_val = X_val[val_rand_idxs]      #X_val, Y_val이 같아야   \n",
    "Y_val = Y_val[val_rand_idxs]   \n",
    "    \n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "# 0  => 1 0 0 0 0 0 0 0 0 0\n",
    "# 3 => 0 0 0 1 0 0 0 0 0 0 \n",
    "Y_train =  utils.to_categorical(Y_train)    # to_categorical사용하여면 () 안에 변수는 '숫자'여야\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)    \n",
    "\n",
    "#2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))  #layer output 2개 \n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"sgd\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#4.모델학습시키기\n",
    "custom_hist = CustomHistory()  # 일반 메소드(self)가 호출되려면, '객체'가 만들어져야 *****************8\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val,Y_val), verbose=0,\n",
    "                callbacks=[custom_hist])  #val_accuracy (이 데이터의 accuracy)  #custom_hist안에 있는것 자동 실행  verbose=0꼭 넣어야 효과가 나타남 \n",
    "                #callbacks=[custom_hist]이렇게 하면 1000번 뿌리게됨 ********************우리가 원하는 것은 과적합전에 조기종료\n",
    "#loss가 늘어나고 있다. 과적합이 되어가고 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:16:44.127651Z",
     "start_time": "2021-03-24T01:16:44.113690Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_hist = CustomHistory() \n",
    "custom_hist.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <2>Eraly Stopping\n",
    "- 199번이 198번과 비교했을때 더 크면 stop (과적합 stop)\n",
    "- **from tensorflow.keras.callbacks import EarlyStopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:56:45.596128Z",
     "start_time": "2021-03-24T01:56:34.354037Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "70/70 [==============================] - 1s 3ms/step - loss: 2.3019 - accuracy: 0.0641 - val_loss: 2.2946 - val_accuracy: 0.0400\n",
      "Epoch 2/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2837 - accuracy: 0.0693 - val_loss: 2.2559 - val_accuracy: 0.0900\n",
      "Epoch 3/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.2411 - accuracy: 0.1081 - val_loss: 2.2223 - val_accuracy: 0.1000\n",
      "Epoch 4/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1866 - accuracy: 0.1473 - val_loss: 2.1983 - val_accuracy: 0.1667\n",
      "Epoch 5/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1685 - accuracy: 0.1356 - val_loss: 2.1752 - val_accuracy: 0.1767\n",
      "Epoch 6/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1303 - accuracy: 0.2303 - val_loss: 2.1516 - val_accuracy: 0.1833\n",
      "Epoch 7/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.1113 - accuracy: 0.2057 - val_loss: 2.1211 - val_accuracy: 0.1633\n",
      "Epoch 8/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0793 - accuracy: 0.2031 - val_loss: 2.0861 - val_accuracy: 0.2067\n",
      "Epoch 9/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 2.0548 - accuracy: 0.1803 - val_loss: 2.0468 - val_accuracy: 0.2067\n",
      "Epoch 10/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9985 - accuracy: 0.2252 - val_loss: 2.0156 - val_accuracy: 0.2167\n",
      "Epoch 11/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9310 - accuracy: 0.2394 - val_loss: 1.9854 - val_accuracy: 0.2333\n",
      "Epoch 12/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8890 - accuracy: 0.2770 - val_loss: 1.9597 - val_accuracy: 0.2633\n",
      "Epoch 13/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.9127 - accuracy: 0.2672 - val_loss: 1.9347 - val_accuracy: 0.2833\n",
      "Epoch 14/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8643 - accuracy: 0.2848 - val_loss: 1.9110 - val_accuracy: 0.3000\n",
      "Epoch 15/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8334 - accuracy: 0.3164 - val_loss: 1.8889 - val_accuracy: 0.2967\n",
      "Epoch 16/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.8117 - accuracy: 0.3065 - val_loss: 1.8584 - val_accuracy: 0.3767\n",
      "Epoch 17/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7629 - accuracy: 0.3335 - val_loss: 1.8372 - val_accuracy: 0.3800\n",
      "Epoch 18/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7225 - accuracy: 0.3562 - val_loss: 1.8127 - val_accuracy: 0.3900\n",
      "Epoch 19/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7271 - accuracy: 0.3658 - val_loss: 1.7929 - val_accuracy: 0.4000\n",
      "Epoch 20/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.7119 - accuracy: 0.3635 - val_loss: 1.7714 - val_accuracy: 0.4167\n",
      "Epoch 21/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6768 - accuracy: 0.3846 - val_loss: 1.7536 - val_accuracy: 0.4267\n",
      "Epoch 22/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.6518 - accuracy: 0.4014 - val_loss: 1.7322 - val_accuracy: 0.4300\n",
      "Epoch 23/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5781 - accuracy: 0.4312 - val_loss: 1.7181 - val_accuracy: 0.4367\n",
      "Epoch 24/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5686 - accuracy: 0.4548 - val_loss: 1.7050 - val_accuracy: 0.4200\n",
      "Epoch 25/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5292 - accuracy: 0.4370 - val_loss: 1.6880 - val_accuracy: 0.4300\n",
      "Epoch 26/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5426 - accuracy: 0.4367 - val_loss: 1.6774 - val_accuracy: 0.4133\n",
      "Epoch 27/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5117 - accuracy: 0.4424 - val_loss: 1.6657 - val_accuracy: 0.4333\n",
      "Epoch 28/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5364 - accuracy: 0.4279 - val_loss: 1.6568 - val_accuracy: 0.4167\n",
      "Epoch 29/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.5064 - accuracy: 0.4231 - val_loss: 1.6457 - val_accuracy: 0.4167\n",
      "Epoch 30/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4895 - accuracy: 0.4013 - val_loss: 1.6338 - val_accuracy: 0.4367\n",
      "Epoch 31/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4650 - accuracy: 0.4504 - val_loss: 1.6291 - val_accuracy: 0.4267\n",
      "Epoch 32/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4662 - accuracy: 0.4533 - val_loss: 1.6222 - val_accuracy: 0.4333\n",
      "Epoch 33/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4648 - accuracy: 0.4254 - val_loss: 1.6164 - val_accuracy: 0.4367\n",
      "Epoch 34/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4459 - accuracy: 0.4259 - val_loss: 1.6041 - val_accuracy: 0.4400\n",
      "Epoch 35/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4040 - accuracy: 0.4336 - val_loss: 1.5962 - val_accuracy: 0.4367\n",
      "Epoch 36/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4238 - accuracy: 0.4283 - val_loss: 1.5927 - val_accuracy: 0.4500\n",
      "Epoch 37/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3860 - accuracy: 0.4758 - val_loss: 1.5885 - val_accuracy: 0.4467\n",
      "Epoch 38/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3880 - accuracy: 0.4549 - val_loss: 1.5807 - val_accuracy: 0.4400\n",
      "Epoch 39/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4085 - accuracy: 0.4315 - val_loss: 1.5839 - val_accuracy: 0.4267\n",
      "Epoch 40/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.4002 - accuracy: 0.4323 - val_loss: 1.5745 - val_accuracy: 0.4167\n",
      "Epoch 41/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3451 - accuracy: 0.4823 - val_loss: 1.5625 - val_accuracy: 0.4433\n",
      "Epoch 42/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3807 - accuracy: 0.4859 - val_loss: 1.5637 - val_accuracy: 0.4533\n",
      "Epoch 43/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3504 - accuracy: 0.4697 - val_loss: 1.5654 - val_accuracy: 0.4467\n",
      "Epoch 44/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3431 - accuracy: 0.4630 - val_loss: 1.5638 - val_accuracy: 0.4133\n",
      "Epoch 45/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3377 - accuracy: 0.5036 - val_loss: 1.5548 - val_accuracy: 0.4367\n",
      "Epoch 46/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3153 - accuracy: 0.5107 - val_loss: 1.5504 - val_accuracy: 0.4400\n",
      "Epoch 47/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2938 - accuracy: 0.4798 - val_loss: 1.5342 - val_accuracy: 0.4567\n",
      "Epoch 48/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.3058 - accuracy: 0.5146 - val_loss: 1.5360 - val_accuracy: 0.4533\n",
      "Epoch 49/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2752 - accuracy: 0.5027 - val_loss: 1.5378 - val_accuracy: 0.4500\n",
      "Epoch 50/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2787 - accuracy: 0.5189 - val_loss: 1.5425 - val_accuracy: 0.4267\n",
      "Epoch 51/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2864 - accuracy: 0.5218 - val_loss: 1.5265 - val_accuracy: 0.4767\n",
      "Epoch 52/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2476 - accuracy: 0.5396 - val_loss: 1.5240 - val_accuracy: 0.4500\n",
      "Epoch 53/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2918 - accuracy: 0.5309 - val_loss: 1.5217 - val_accuracy: 0.4567\n",
      "Epoch 54/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2672 - accuracy: 0.5390 - val_loss: 1.5162 - val_accuracy: 0.4733\n",
      "Epoch 55/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2530 - accuracy: 0.5370 - val_loss: 1.5103 - val_accuracy: 0.4633\n",
      "Epoch 56/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2381 - accuracy: 0.5512 - val_loss: 1.5184 - val_accuracy: 0.4467\n",
      "Epoch 57/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2347 - accuracy: 0.5703 - val_loss: 1.5102 - val_accuracy: 0.4533\n",
      "Epoch 58/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2538 - accuracy: 0.5374 - val_loss: 1.5115 - val_accuracy: 0.4500\n",
      "Epoch 59/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2076 - accuracy: 0.5727 - val_loss: 1.5059 - val_accuracy: 0.4500\n",
      "Epoch 60/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2755 - accuracy: 0.5293 - val_loss: 1.5082 - val_accuracy: 0.4433\n",
      "Epoch 61/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2251 - accuracy: 0.5603 - val_loss: 1.5049 - val_accuracy: 0.4500\n",
      "Epoch 62/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1639 - accuracy: 0.5871 - val_loss: 1.5032 - val_accuracy: 0.4367\n",
      "Epoch 63/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1663 - accuracy: 0.5667 - val_loss: 1.5010 - val_accuracy: 0.4433\n",
      "Epoch 64/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1698 - accuracy: 0.5588 - val_loss: 1.4914 - val_accuracy: 0.4733\n",
      "Epoch 65/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1770 - accuracy: 0.5759 - val_loss: 1.4955 - val_accuracy: 0.4467\n",
      "Epoch 66/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1775 - accuracy: 0.5745 - val_loss: 1.4921 - val_accuracy: 0.4333\n",
      "Epoch 67/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1757 - accuracy: 0.5683 - val_loss: 1.4851 - val_accuracy: 0.4333\n",
      "Epoch 68/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1610 - accuracy: 0.5955 - val_loss: 1.4853 - val_accuracy: 0.4400\n",
      "Epoch 69/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1803 - accuracy: 0.5931 - val_loss: 1.4791 - val_accuracy: 0.4500\n",
      "Epoch 70/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.2282 - accuracy: 0.5435 - val_loss: 1.4801 - val_accuracy: 0.4467\n",
      "Epoch 71/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1665 - accuracy: 0.5697 - val_loss: 1.4737 - val_accuracy: 0.4533\n",
      "Epoch 72/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1471 - accuracy: 0.5918 - val_loss: 1.4747 - val_accuracy: 0.4400\n",
      "Epoch 73/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1343 - accuracy: 0.6098 - val_loss: 1.4819 - val_accuracy: 0.4233\n",
      "Epoch 74/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1563 - accuracy: 0.5943 - val_loss: 1.4754 - val_accuracy: 0.4467\n",
      "Epoch 75/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1596 - accuracy: 0.5929 - val_loss: 1.4717 - val_accuracy: 0.4500\n",
      "Epoch 76/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1195 - accuracy: 0.5994 - val_loss: 1.4732 - val_accuracy: 0.4333\n",
      "Epoch 77/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1322 - accuracy: 0.5939 - val_loss: 1.4708 - val_accuracy: 0.4467\n",
      "Epoch 78/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1270 - accuracy: 0.5830 - val_loss: 1.4701 - val_accuracy: 0.4567\n",
      "Epoch 79/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1786 - accuracy: 0.5701 - val_loss: 1.4664 - val_accuracy: 0.4467\n",
      "Epoch 80/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1537 - accuracy: 0.5753 - val_loss: 1.4714 - val_accuracy: 0.4367\n",
      "Epoch 81/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1191 - accuracy: 0.6035 - val_loss: 1.4717 - val_accuracy: 0.4433\n",
      "Epoch 82/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1197 - accuracy: 0.5966 - val_loss: 1.4704 - val_accuracy: 0.4467\n",
      "Epoch 83/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1386 - accuracy: 0.5907 - val_loss: 1.4690 - val_accuracy: 0.4367\n",
      "Epoch 84/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1021 - accuracy: 0.5946 - val_loss: 1.4583 - val_accuracy: 0.4700\n",
      "Epoch 85/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1115 - accuracy: 0.6125 - val_loss: 1.4694 - val_accuracy: 0.4400\n",
      "Epoch 86/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0997 - accuracy: 0.5790 - val_loss: 1.4551 - val_accuracy: 0.4800\n",
      "Epoch 87/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1221 - accuracy: 0.6029 - val_loss: 1.4631 - val_accuracy: 0.4633\n",
      "Epoch 88/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0746 - accuracy: 0.6007 - val_loss: 1.4590 - val_accuracy: 0.4667\n",
      "Epoch 89/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0848 - accuracy: 0.5882 - val_loss: 1.4569 - val_accuracy: 0.4567\n",
      "Epoch 90/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0719 - accuracy: 0.6111 - val_loss: 1.4567 - val_accuracy: 0.4733\n",
      "Epoch 91/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0378 - accuracy: 0.6328 - val_loss: 1.4586 - val_accuracy: 0.4733\n",
      "Epoch 92/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0845 - accuracy: 0.6214 - val_loss: 1.4646 - val_accuracy: 0.4667\n",
      "Epoch 93/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.1038 - accuracy: 0.6258 - val_loss: 1.4572 - val_accuracy: 0.4667\n",
      "Epoch 94/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0867 - accuracy: 0.5699 - val_loss: 1.4603 - val_accuracy: 0.4500\n",
      "Epoch 95/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0617 - accuracy: 0.6067 - val_loss: 1.4616 - val_accuracy: 0.4533\n",
      "Epoch 96/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0615 - accuracy: 0.6091 - val_loss: 1.4645 - val_accuracy: 0.4567\n",
      "Epoch 97/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0138 - accuracy: 0.6373 - val_loss: 1.4655 - val_accuracy: 0.4767\n",
      "Epoch 98/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0593 - accuracy: 0.6389 - val_loss: 1.4631 - val_accuracy: 0.4700\n",
      "Epoch 99/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0705 - accuracy: 0.6131 - val_loss: 1.4569 - val_accuracy: 0.4800\n",
      "Epoch 100/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0720 - accuracy: 0.5998 - val_loss: 1.4608 - val_accuracy: 0.4933\n",
      "Epoch 101/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0455 - accuracy: 0.5974 - val_loss: 1.4555 - val_accuracy: 0.4833\n",
      "Epoch 102/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0423 - accuracy: 0.6271 - val_loss: 1.4603 - val_accuracy: 0.4700\n",
      "Epoch 103/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0376 - accuracy: 0.5985 - val_loss: 1.4686 - val_accuracy: 0.4667\n",
      "Epoch 104/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0533 - accuracy: 0.6275 - val_loss: 1.4665 - val_accuracy: 0.4533\n",
      "Epoch 105/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0285 - accuracy: 0.6176 - val_loss: 1.4697 - val_accuracy: 0.4733\n",
      "Epoch 106/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0438 - accuracy: 0.6444 - val_loss: 1.4575 - val_accuracy: 0.4867\n",
      "Epoch 107/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0128 - accuracy: 0.6172 - val_loss: 1.4604 - val_accuracy: 0.4733\n",
      "Epoch 108/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0589 - accuracy: 0.5966 - val_loss: 1.4706 - val_accuracy: 0.4800\n",
      "Epoch 109/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0201 - accuracy: 0.6477 - val_loss: 1.4659 - val_accuracy: 0.4700\n",
      "Epoch 110/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0329 - accuracy: 0.6228 - val_loss: 1.4685 - val_accuracy: 0.4767\n",
      "Epoch 111/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0313 - accuracy: 0.6039 - val_loss: 1.4709 - val_accuracy: 0.4733\n",
      "Epoch 112/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0354 - accuracy: 0.6053 - val_loss: 1.4781 - val_accuracy: 0.4500\n",
      "Epoch 113/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0099 - accuracy: 0.6359 - val_loss: 1.4657 - val_accuracy: 0.4900\n",
      "Epoch 114/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9926 - accuracy: 0.6358 - val_loss: 1.4755 - val_accuracy: 0.4800\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/70 [==============================] - 0s 1ms/step - loss: 0.9927 - accuracy: 0.6142 - val_loss: 1.4638 - val_accuracy: 0.4767\n",
      "Epoch 116/1000\n",
      "70/70 [==============================] - 0s 1ms/step - loss: 1.0375 - accuracy: 0.5960 - val_loss: 1.4779 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1cbbb555460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEGCAYAAADBr1rTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABtHklEQVR4nO2dd3hVxdaH30mvpEGAEHqHAKGKgoAiSlEBQcUCWAC9KlesiBWvWD57QxERFAEVEUQUQVGKSJHekRYggSSk937W98ekAenkcFLmfZ7zkL337Jk1J2H/9ppZs0aJCAaDwWAwVCXsbG2AwWAwGAwXYsTJYDAYDFUOI04Gg8FgqHIYcTIYDAZDlcOIk8FgMBiqHA62NqC82NnZiaurq63NMBgMhmpFamqqiEi1cUiqnTi5urqSkpJiazMMBoOhWqGUSrO1DeWh2qiowWAwGGoPRpwMBoPBUOUw4mQwGAyGKke1m3MqiqysLMLCwkhPT7e1KdUWFxcXAgMDcXR0tLUpBoPBUDPEKSwsDE9PT5o1a4ZSytbmVDtEhJiYGMLCwmjevLmtzTEYDIaaMayXnp6On5+fEaYKopTCz8/PeJ4Gg6HKUCPECTDCdImY789gMFQlaow4lYbFkkF6+mlELLY2xWAw2JjlyyEk5PK2uWwZLF4MadVqtZHtqDXilJqZyJmkc2RmRlV63fHx8XzyyScVunfo0KHEx8eXufz06dN5++23K9SWwWCArVthxAgYOvTyCIUITJ8Ot9wCt98ODRrAxIkQHX1+OYtFfwyaWiNO2TgSlwXRKWewWLIrte6SxCknJ6fEe1euXIm3t3el2mMwGIpGBJ58EurUgcOHYdo067aXnQ0PPQQvvwz33gtr1miR+vprLY5JSbrc3r3QooW268orYfJkOHPGurZVdWqNOHk5e+Fs70RspoXMzLOVWvczzzzD8ePHCQ4O5qmnnmLdunVcc8013HnnnXTq1AmAESNG0L17dzp27Mjs2bPz723WrBnR0dGcPHmS9u3bM3HiRDp27Mj1119PWimvdbt376Z379507tyZkSNHEhcXB8CHH35Ihw4d6Ny5M2PGjAFg/fr1BAcHExwcTNeuXUnK+19hMFRDMjKguPc+EXjvPS0AF5ZZvhw2boQ334RHHoEPPoA//yy+HREoKVva0aNaeFJTC87Fx+u6e/QAT0+YNQueeQa++AIGDoR58+D772HnTi1Uf/wB/fppIbv3XnB2hjlzoEsXWLFC27BtG/z3v9r+WoOIVKuPm5ubXMjBgwfzfz5y5FHZubN/kZ+t26+S9Vu6ydZ/usnOnVcXW+7Cz5Ejj17UZmFCQkKkY8eO+cdr164VNzc3OXHiRP65mJgYERFJTU2Vjh07SnR0tIiING3aVKKioiQkJETs7e1l165dIiJy6623ytdff31RWy+99JK89dZbIiLSqVMnWbdunYiIvPDCC/Loo9rOhg0bSnp6uoiIxMXFiYjIjTfeKBs3bhQRkaSkJMnKyirxezQYqiopKSLt2oncfnvR159/XkQ/0kU6dRL5+WeRtDSRzEyRNm30vVlZup42bUQCA0WWLBHJ/S8j2dki+/bpepo1E7GzE3npJX1PYbKzRXr10u1cdZVITIzImTO6TUdHkUGDRJ54QmTFiqLt/PLLAjvbthU5darg2uHDIsHB+lrTpvpfZ2eR11+v+PcGpEgVeIaX9VNrPCcARzsHFIos0QES1qRXr17nrRn68MMP6dKlC7179yY0NJSjR49edE/z5s0JDg4GoHv37pw8ebLY+hMSEoiPj6d///4AjB8/ng0bNgDQuXNn7rrrLhYsWICDg17K1qdPHx5//HE+/PBD4uPj888bDFWdEyfOn4t59VU9JPfdd9r7KMyHH8KMGXD//fDtt9rrufFG8PCA1q3hyBH4v/8DBwdwc4NFi3Tdo0fruaA8b6dTJ3jtNX3PLbdo72jAADh9uqCtOXPgn3/0/NH27XD11XDVVTrQYuVK+O03ePtt3X5RjB8Pn3yi5782boQmTQqutW0LW7bA1KnQrh3Mng0REdoDqy3UuCdU69bvl3j9TOIZwpPDaeYOPp6dsLNztood7u7u+T+vW7eONWvWsHnzZtzc3BgwYECRa4qcnQtssbe3L3VYrzh++eUXNmzYwE8//cQrr7zCgQMHeOaZZxg2bBgrV66kd+/erFmzhnbt2lWofoOhrIjA/v36Ie/iUnB+5kz46y8ICoLgYLjuuvOvg56HmToVVq3S4rFggX7wv/WWFoy1a7Vo5A11LVwIjz4KI0fqoTQHB/3zzz9rEduzBwYPhptuKmije3c4dUoPrS1YAOHh8MADekjt+ushIECXW7AA/vMffX7OHC1EzzwD114Ln30Gd9wBw4frPqxbp+stC//5j/4UhbMzvPFG2eqpidQ4cSoNf3d/IpIjiMsUPLJicHYOuOQ6PT09S5zDSUhIwMfHBzc3Nw4fPsyWLVsuuU0vLy98fHz466+/uPrqq/n666/p378/FouF0NBQrrnmGvr27cuiRYtITk4mJiaGTp060alTJzZv3szhw4eNOBnKxKlT4O0NXl5FXz94UM+XtGsHTk46Au7AAe09LFig52V69YJffoG6deH99+Gxx8DfX3s/oL2GV17R0Wx//AFffglLlug2x42D+fMhJkZ7Oe7u2uP4/HN44QUtPJGRcM892rtZtEgLE2h7brlFf4rDwQFuuEF/iuPuu6F3by1Co0fr4IWUFC2ySsE11+g+OzlB/frl/oqrDEqpwcAHgD0wR0Qukkel1ADgfcARiBaR/tawpdaJk6O9I35ufsSkRlM3Mxonp4aXvADVz8+PPn36EBQUxJAhQxg2bNh51wcPHsysWbPo3Lkzbdu2pXfv3pfUXh5fffUVDz74IKmpqbRo0YJ58+aRk5PD3XffTUJCAiLCY489hre3Ny+88AJr167F3t6eDh06MGTIkEqxwVCzOXNGD3E1aqQ9nbp1z7++ZYuezM/KAkdH7WmEhmoRUUqLxZ13ag+gb1+YMAGeegpGjdLClJqqh7ReeEEPc02apIMdfH11VN0zz+ifBw3SwQLZ2VqY6tfXEW3vvqvvOXhQ27l8+cUeWGXRqhX8/Tc8/7z23p5/XgtyHo0bW6fdy4VSyh6YCQwCwoBtSqmfRORgoTLewCfAYBE5rZTyt5o9ep6s+uDu7i4XbjZ46NAh2rdvX+Y6MrIz2H9uH16O0MynDQ4OdSrbzGpJeb9HQ80iJ0dHrl19dcED/rbb4Kef9M9dumivxsNDH0dG6uErZ2c9vHbgAJw8qYfwunSBK66AwEBddsMGuPlmSEjQQ2ErV+r78rBY9ALVP/+EYcNgyBDthRRmzRrd/owZYG+vz82YoYWtVSstcpfLazlzRgtxdUqsopRKFRH3Eq5fCUwXkRtyj6cBiMjrhco8BASIyPPWtrfWeU4Azg7O1HWrS1RqNCkZ5/Ay4mSo5WRk6OGzxYuhf3/tgWzZokOeX3lFeyW33KLncF58Edq310NwsbGwebMWo5Lo1097Xl9/rcXE+YKpXjs7GDNGf4rjuuv0pzBTpuhhxIkTL+9wWqNGl6+tSsRBKbW90PFsEZld6LgREFroOAy44oI62gCOSql1gCfwgYjMt4qx1qi0OtDQM4Do1GjOpcbj6ZqNnV2t/SoMNZy//4a4OD3B7+QEYWE6Y8HmzTo4YNQoPXz25596aG3RIi1QycnQpo0ehstbezNhgvZg8vj669KFKY9OnfT6osrEw0NH7xnKRLaI9CjhelF+4IVDaw5Ad2Ag4ApsVkptEZEjlWTjeQ3VSpzsnajn5su51FhSMiLxdK2er0IGQ0l8+aUWlJwc8PPTE/c//6yH0a64Qoc654VWz58PY8fqOaJbbtET/r//XuDl3HuvjnbbvVtHvvn56UABQ40hDCg8cxYIXJixIAwdBJECpCilNgBdACNOlUlDz8ZEp8YSmhhBO+cG2NnZ29okg6FSENGT9lOn6mCChx+Gb76B1au1pzRjBjRrpueNliyBDh20cIH2sDZt0iHgFw6jNWyoPyaepkayDWitlGoOnAHGAHdeUGY58LFSygFwQg/7vWcNY6wmTkqpxsB8oAFgQY9vfnBBmbuAqbmHycB/RGSPtWy6EEd7RwLrNOB0YgRnEk/Q2Lv15WraYCg3qal6XVDLltrb6dZNh1d//71eQDpiREHZjz7SwjRmDHz1lR7OGz784jrr19fCdSGdO+uPofYgItlKqUeA1ehQ8rkickAp9WDu9VkickgptQrYi36uzxGR/dawx2rRekqphkBDEdmplPIEdgAjLghLvAo4JCJxSqkh6EiRCyfgzqMyovUKIyIci95DQlY2bf3a4Olce4MjTLRe1eabb/SQm7u7HnK74gq9xicrS0evrVmjQ7cPHtTCNWiQDmywq1V5YAzFUVq0XlXDan+2IhIuIjtzf04CDqGjQQqX2SQicbmHW9BjnJcVpRRNvJvjqCAk7gTZlZyxvDg88uJxy3jeYJg/Xy9WDQ3V2bRTU3Uy0E2bdPj2bbfpDArjxukUPHPmGGEyVF8uy5+uUqoZ0BXYWkKx+4Ffi7l/klJqu1Jqe3Z25YuHs6MXge7uZFqyORl/kuq29stQM4mLK/g5PFznahs7Fnx8dN63vXt1QMOVV8LSpTqkumtX2LFDp++pzpkKDAari5NSygP4AZgiIonFlLkGLU5Ti7ouIrNFpIeI9LBWwlJv9ybUc4b49HjOpZwr171Tp049bz+n6dOn884775CcnMzAgQPp1q0bnTp1Ynk58t2LCE899RRBQUF06tSJ73LzvISHh9OvXz+Cg4MJCgrir7/+Iicnh3vuuSe/7HvvWWV+0nAZ+flnnY1hwQJ9nJegdOzYosu3b68j8xISdATdqFGXzVSDwSpYNVpPKeWIFqaFIrK0mDKdgTnAEBGJudQ2p6yawu6I3RW612JJJz0nixwBN0c37JWO3gtuEMz7g98v9r4xY8YwZcoUHnroIQAWL17MqlWrcHFxYdmyZdSpU4fo6Gh69+7NzTffXKZ0SUuXLmX37t3s2bOH6OhoevbsSb9+/Vi0aBE33HADzz33HDk5OaSmprJ7927OnDnD/v16XrI8O+saqiazZ2sxmjRJrw/6+mudn65t2+LvGTUK9u0ruYzBUF2wZrSeAr5ABzy8W0yZJsBSYKw1FnGVFzs7Z5wkm/QcSM9Kx83JDVXkurTz6dq1K+fOnePs2bNERUXh4+NDkyZNyMrK4tlnn2XDhg3Y2dlx5swZIiMjadCgQal1bty4kTvuuAN7e3vq169P//792bZtGz179uS+++4jKyuLESNGEBwcTIsWLThx4gSTJ09m2LBhXH/99ZXxdRhsxLlz8OuvOpHp77/rhKSRkfDxx6XfGxRkdfMMhsuCNT2nPsBYYJ9SanfuuWeBJqDDEoEXAT/gk1xvorQVzKVSkodTFjIzI4hLDSM0FXxcfGjh06JMns7o0aNZsmQJERER+bvPLly4kKioKHbs2IGjoyPNmjUrcquMoihu3qtfv35s2LCBX375hbFjx/LUU08xbtw49uzZw+rVq5k5cyaLFy9m7ty5Ze+0oUrx7bc6wekTT+jtG/r100lVb7/d1pYZDJcPq4mTiGyk6HQYhctMACZYy4aK4Ojoj7tDNPWcs4lKjyM6NZp67vVKvW/MmDFMnDiR6Oho1q9fD+itMvz9/XF0dGTt2rWcOnWqzHb069ePzz77jPHjxxMbG8uGDRt46623OHXqFI0aNWLixImkpKSwc+dOhg4dipOTE6NGjaJly5bcc889Fe2+oQowf74OBc/zgpYu1RvNXZgR3GCoydTqDBFFoZQdLi5N8LEcIc3iTGhiKB5OHrg6upZ4X8eOHUlKSqJRo0Y0bNgQgLvuuoubbrqJHj16EBwcXK79k0aOHMnmzZvp0qULSinefPNNGjRowFdffcVbb72Fo6MjHh4ezJ8/nzNnznDvvfdiyd0u9PXXXy+ldkNV5cABHW33/vsF54rbSdVgqMnUyi0zykJa2gnSM+M4mWqHu5M7rX1bX/K+T1UdswjXupw9qzM29OypQ8CL+nN65hl97exZvRmfwVBZVLdFuMZzKgZn50Cys+Op5+JIRFoiiRmJeLkUsxWowVAKR47owIbQUL11hJub3oqiMImJekhvyBAjTAaDWT9eDHZ2Tjg7N6KOfTrO9o6EJoZiEYutzTJUQ/bt07vAJifrbSomTNCJVz/88Pxyjz+uo/KefdY2dhoMVYka4zmJSKUPuzk6+pOVpYMjwlLTiU6Nxt+9Zr7SVrfh3erEtGk6S/jff+v9kbp21QlbH31Uh41Pn65Dx7/4Qpe98kpbW2ww2J4a4Tm5uLgQExNT6Q9YpRTOzoG42WXh4ejM2aSz5FhyKrWNqoCIEBMTg0ve3tyGcrFnj/aEMjIuvhYWpoVn0iQtTKD3Tlq0SO+P9OqrOlR84kS9ad/06ZfVdIOhylIjPKfAwEDCwsKIioqySv2Zmclk5sQQkyGkh6fXyLknFxcXAgMve97das+hQzBwoPaE1q6FZcugTqHE9vPm6UwP999//n0uLjB3rs4c/uCDkJ6uc+c5OV1e+w2GqkqNiNazNklJu9mxoxv/O9aCPbFxnHz0JJ7OnpfVBsPl58wZvbFecZm9Q0OhTx/IzNTzRc89p/dAWrlSJ121WKBFC50x/Pffi28nNBSiovTaJoPBWlS3aL0aMaxnbTw9g2nQYDy31T9FbFosM7fNtLVJBisTGak39Zs0qejrW7ZorychAVatgqefhp9+gsOHtWCdOKEF6dQpHQBREo0bG2EyGC7EiFMZadLkOdp55tAvoAXvbH6H5MxkW5tksCKrVuk5pC++gM8/Lzh/9CiMHq2DFuLjYcUKCA7W14YMgT/+0FtdXHUV/O9/4Od3/g61BoOhbBhxKiNubq2oW3cEdwREEZ0azafbPrW1SQYrsnKl3vr8hhvgkUfgl1/0vx06aOF6+WU4dkwHMxSmd2/YuFHPHW3apDf+c3a2TR8MhuqMmXMqB/HxG9m9+2peONqWE0lJhDwagpO9mcGuaWRn6zx2o0bBm29Cjx5w8qTeCv2BB+DFF0vfyC8sDN54Q69ZCgi4LGYbDCVi5pxqMF5effD07MktDRM5m3SW7w98b2uTDJXAtm16GC4iQh9v3qznkoYO1cNyK1bA5Mk6793MmWXbYTYwUG9xYYTJYKgYRpzKgVKKxo2foIt7OK28G/H+1vfN4tUawKuvakF66SV9vHKlXot03XX6OChIZ3Mwm/gZDJcPI07lpG7dUbi6NOG2Jq5sP7udv0P/trVJhkvg5EntGfn5wZw5cPCgFqe+fcGr5i1nMxiqDUacyomdnQOBgY/St84xvJ3r8P6W921tkuESmDVL//v77+DhoRfL7t2rh/QMBoPtMOJUARo2vB8PJ09GNw9k2eFlhMSF2NokQwVIS9Nh4iNG6Hx306bp9UtgxMlgsDVGnCqAg4MXDRtO4Aaff3G0c2T6+um2NqlWk5Skt59ISjr//Jw5ep1SQoJOvLpihZ4/CgiATz+Fr7+G2Fgd7AA6EWvjxtC0qQ4ZNxgMtsOEkleQtLSTbN3akm+ievL5wX/YMWkHXRt2tbVZtZJp03TY9nvvwZQp+typU9Csmf7ZxQVatYL9+3Xy1fr19Z5KAB076i0t8hLaHzigF9+ajA2GmkZZQsmVUoOBDwB7YI6IvHHB9QHAciBvuGipiPyv8q01nlOFcXVtRr16oxhR9xC+rj48+fuTJnLPBoSGFmxpPn9+wfkFC/S/S5fq9EEuLvDJJ1qg1q/XXtTVV+ts4oV3WunY0QiToXailLIHZgJDgA7AHUqposYQ/hKR4NyPVYQJjDhdEoGBj+OqEnm0ywD+DPmTX4/9amuTah3PP6+H7B5/HHbt0l6QiBaq/v1h5Ej46CO9luk//wFHRy1GN94IGzaY1EKGasTIkfDVV9ZsoRdwTEROiEgm8C0w3JoNloTVxEkp1VgptVYpdUgpdUAp9WgRZZRS6kOl1DGl1F6lVLV6Z/Xy6o2X19X099hGa99WPPX7U2Rbsm1tVq1h9249b/Too/DMM3pt0tdfwz//6G3Rx42ztYUGQyVx4AD8+KPeTrniOCilthf6XJjWuBEQWug4LPfchVyplNqjlPpVKdXxUgwqCWt6TtnAEyLSHugNPFyEizgEaJ37mQRUu4R1TZpMxZIVyrQewzgYdZDPtn9ma5NqDc8+Cz4+es6pXj0dYbdggd5DycVFJ2g1GEokLQ2WLNE5q6oyixdrl3/UqEupJVtEehT6zL7gelFbiV84V7ETaCoiXYCPgB8vxaCSsJo4iUi4iOzM/TkJOMTFKjwcmC+aLYC3UqqhtWyyBr6+Q3F3D6Kj/RquaXYNL657kdi0WFubVeNJTNSb8z3wAHh763PjxkF4uA4PHzny/E3/DIYiefZZuPVWmDrV1pboCdHo6IvPi2hx6t9fZyO2HmFA40LHgcDZ802RRBFJzv15JeColKprDWMuy5yTUqoZ0BXYesGlMrmRSqlJea5odhV7w9EpjZ4mNfUA03vfQnx6PP9bb7U5QkMuf/8NOTl6F9o8brxRC5XFYob0DGXgwAE9IdmgAbz7Lnz3XfnrEClaUCpSz4ABcO21cGE08v79eqOw22679HZKZhvQWinVXCnlBIwBfipcQCnVQCkdQqSU6oXWkBhrGGN1cVJKeQA/AFNEJPHCy0XcclHIm4jMznNFHRyq3s7y/v5jcHZugmfqd0zoNoGZ22ZyOPqwrc2q0axbp4Mbrryy4JyzM9x7LzRvXpAXz2AoEhH473+1e71zp878e999WgjKw3PPQaNGOq3IpXD8OMTE6IieSZO0fXksXqy3Y77llktroxREJBt4BFiNHulaLCIHlFIPKqUezC02GtivlNoDfAiMEWuFKYuI1T6AY25HHy/m+mfAHYWO/wUallSnm5ubVEVCQz+UtWuRf8O+F6/XveSaL6+RHEuOrc2qsfTqJdK378Xns7NFUlMvvz2Gasb334uAyMyZ+vjMGZEGDUTatxfJyChbHYcPizg66nr69ROxWCpuz3ff6Xpuv13/+8EH+rzFItKmjcjAgRWvOxcgRaz4vK/sjzWj9RTwBXBIRN4tpthPwLjcqL3eQIKIhFvLJmsSEDAJZ+cmJEW8yZuD3mTtybXM2j7L1mbVSBITYccOPQpyIfb24Op62U0ylIW//9ap3c+csa0dMTHw2GPQpYuetASdNuTzz+HQIT3UVxoiOkzU1VVvebxhQ8Gw4OrV0LKlDrQoKzt36qGAr76C4cP12oiJE+Gbb3ToqfWH9Koe1lI9oC96iG4vsDv3MxR4EHgwt4xCL/o6DuwDepRWb1X1nEREzp6dK2vXIpGRP8j1X18vbq+6yfHY47Y2q9px9qzIqlUib74pMm2a/rz6qkhcnL7+yy/65XLNmktoxGIRue02kV9/rQyTDWVh2jT9i3v88cvXZkiIyKBBImvX6uPsbJHrrxdxchL555+Lyw8dKuLpqf8IS2L5ct2X997TdXbrJtKokcg774jY2YnY24u4uYns26fLx8Xpv7cxY0T++utiL2vQIF2HiEhCgsikSSKurroNe3uRc+cq/h3kQjXznGxuQHk/VVmccnKyZOvWdrJ1awc5FRcidV6vI/3m9TPDe2UkPl7/39Wvpfrj6FgwcjJ+vC731FP6XErKJTQWFqYrHTq06OuZmSJTpohs2XIJjZSRVatEXnnF+u3Ymhtu0N+5u7tIdHTJZd97T4vI9deL3HijfqBXhCee0G06OIh88YXIc8/p488/L7r8kSNauMaNK77OjAyRFi1EOnTQfyciIn//XfBHe9NNup4GDURatxbZuVMPFzo4iHh76zLduumhRBEtVL6+IhMmnN9ObKwWu7yhx0vEiFMtFicRkcjI72XtWiQ8/EuZu3OuMB15d9O7tjaryrN5s0izZvolcdo0kXXrRGJiCq4/84z+a12/XqRnz6Lnm8rFmjW6QheXolXuq6/0dX9/kdDQS2ysFPr3F1FKJDLSuu1cTjZsEFm8uODYYhGpW1ekd2/9vb78cvH3nj6tH+TNm+vyDRvqt5GvviqfDenpus3Bg7VnkiceF4rAheT9sX3xRYH4FGbJEn39p5/OP//qqyLTp2tPSkQLqoODLuvjo7235GSRWbP073v6dF3u5Eld5tNPy9e/cmLEqZaLk8VikW3busumTU0kKytVblp0kzi/4iz7I/fb2rQqy4ED+tnTrJkWqaJISRFp2lSkbVs9avL885fY6EcfFTysVqw4/1pOjn4rbtlSxMND5Ior9IPOGqSk6Dd1EPnyS+u0YQv69BGpU0ckK0sfnz6t+/jxx9qz8PPTD+qoKJHPPhOJiCi4d8oU/ZYSEqKPY2JErrmmQFhmzNCfXbtKtiEvyODXXws84ZtuEklLK/m+pCSRzp31vQ0birz+uv6byOOGG0QaNy4QoZKYM0d/F//+e/75/v21N2WxiCxdqtvaurX0+i4BI061XJxERGJj18jatcjp0+9KRFKE1HuznnSd1VUysssYBVTLuPFG/RwrzXHIG+a/5PkmEZGHH9ZzCx4eIg8+eP61H3/UjSxcWPCWfGGZymL1al2/UiKjR1unjctNWlqB4Oa9beR9p5s3i2zapH/u1UvE2bng5/R0LVZubiJjx55fZ0aGnodRquCPoF2780XjQgYNEmnSpGwiciE5OXpy8/rrJd+LEtGCqZTISy+Vv87CzJyp6923Tw812ttbPczUiJMRJxER2b37evnrL1/JyoqXZYeWCdOR5/54ztZm2YwTJwpeoguzdq3+K3zjjbLVc/PN+tl1SfNNIjo0t1cvkZEj9Vtw3gS1xaI9pebNCwx+8snzH7SVydNP66GfO+7QCl3WMOaqzIYNBQKSN5f2wgva5c37xQ0apOeeHnpI5MMPddkHHhB58UX98/5iRhqysrQXtHChLrd0adHlTpyQUocPy4LFInLVVSL16umghhdf1OJ06tSl1RsRob+PF14QGTJEe2pWxoiTEScREUlM3Clr1yLHj2tBuufHe8TuZTtZf3K9jS27vGRkFDzbb775fIHKyRHp3l1rQ1lfGpOT9TBgsWRnlz5sIyISEKAnvefM0cbt2aPP//mnPv7kk4KySUl6wnr48LIZWR66dxe5+uoCz+KPPyq/jYpgsVR8KPO113RfmjcXGTBAnxs2TKRjx4Iy6enn/9Lz5nmcnMr2PWdl6WHXnj2LXl/0/PP64X/6dMX6UJgdO7QgTZ4sEhio57Aqg2uv1WuY6tcXueeeyqmzBIw4GXHK58CBO2T9eldJTz8jiemJ0urDVhL4bqBEp5QSqVRDOHZMP3tBOyogcu+9Bc+SL77Q5+bPL7mecvHIIzrI4b77ip+TSEjQDb/+ug4ZBv1APXFCT2rVr3+xwL30kpT4Rl8RYmIKJsaTkvSD+XKGWReHxaJ/Uf7++jspL0OG6Dm7J57QfUpJ0XM3JUXAZWeLXHedlMtD/ewzuWiMd/dukfvv18OFxUViVoQHHpB8b/CHHyqnzlmzCur88MPKqbMEjDgZcconNfW4rFvnJIcO3SciItvPbBfH/znK8G+Gi+VSVpNXA5KS9Iutj4/IsmX6XN6IzciRIp066Z+7dy9m2iAtTU+C33RTwQKn0ggL05EVHTvqsT/QYX3ffnt+1NU//+hreYZ17y7SqpUeuvH21qGCFxIdff5cyK+/6lDh4cP1w7Eiv88fftB25IVJX3+9FseKsm6d9lYWLKh4HSIFw2z29iLBweUbQ83OFvHy0vNDK1fqevIiH99/v+R7k5L0fFRZSUvTv4Nrr9XBD1dfrdtxddXth4WVva7SiIrSf8z+/pU39HrunP6OQWTjxsqpswSMOBlxOo9jx56UtWuVJCbuFBGRdze9K0xHPtr6kY0tsy4PPigynZcktuf1+iGclSUWi45DAB0hPHOmXttUJPffL/nrU9q3FzlehsXMTzyh/7OfOFGwRqRlS11PkyYFCyvnz9fnDh3Sx3mq2arVxVFVhcmLIsubP2nbVgsaaG+reXP9efjhggeYxaJDjEeMuPih9tBDet4l73yeKBw9Wnpff/9dpEcPPVkXHS0yd64WZqV0JFzhOPwL2bVLf7833HDx0F1e+PNNN+koRtAeT1nFd88eyXeHk5J0XXlvIhs2lK2O8vDmm5LvfbRoIfL22/p3bw02biz6xeVSGDRI/86Skyu33iIw4mTE6TwyM+Nk48a6smvXNWKxWMRischNi24Sx/85yqbT5XhLrCKkp+uI5z//LP75t3KlSDe2Sw6qwINp3Fhk+XKxWMqw2H32bH3Pc8/phnx89HqVkgQqJkY/6O+88/zzOTkFHspbb+lz06bph2aeNxUZqecoSlsYGhpasCL45pv1wzctTXsG48drr2r4cH19wAAthnfcUfDwzGs/j7Zt9RBYHseP63Jvv12yHSdO6O/Ey0vy52lAP+g2bNDC+fDDF9+Xmlqw3ifvnsKLUaOitCfSqlWBt5o3nFnUQlCLRYvknXcWeKEff6zL54WB9+0r+dGIiYkl96siJCfroJIVKyoWlWdrtm3T39llwIiTEaeLCAubKWvXIlFRP4qISFxanLT8oKUEvBMg4UnhNrZO8+uvBZlWSiIvA03ex8NDR2R7eooEBennVMP6ObLL9Uqx+Ptr0fjxR5GuXfUD6u23S34L37lTPzhvuKHgYbN/v5Qa0ve//+kye/cWfb1nT/0R0eOK7dqV3tmi+OADHYFW0oNw/nzdhzwhe+01HRDg4VHgvR05UrQQ9emjh46KcylTU/VQm7e3ntTbt097YE8/XSC2jzyiBWr37vPvzVv38+KL2rvo1k1nMMjry8SJWrTzgkNEtLgPHar78vffBed/+kl7tHnC4+qq2xszRqfxyfsd54nbpQxXGioFI05GnC5CpzVqL1u2tJKcHD2Esydij7jOcJV+8/pJVk4RMdaXibxRp7ysMqtWFVzbsEHkm28KnjMHD+pn1B136OU5b74p8thjIs89GC3fXPuZTOv9pzQOtMgEp9w5hrlzCypLTRW59VZ9ftKk4gXqvvt0SPWFXkzbtnpBVFEcOaKHsoq7LqK9FtDeSfv2epjNmvz1lw5J//57fXz0qBassWNFtm/XAQIeHhd7g9u364f9Y49dXGdOjr4fRH7+ufi2Y2O1p3n11ed/z6NGac8oT4zyMnMvXqzf4JUqOiAjNlYPmTVsKBIeLvJ//6fvCwrSXuPJkzr6sUULXf+YMQX35oWV33FH2b43g9Uw4mTEqUiio3+RtWuR0ND388/N3z1fmI58uKUSI3UsFj1BX0wYcGqqnpeeM0fHBUyerP8KxowR6dJFvzi/845+znsTK8HslClT9PNswAA9mpQ/LLdrlxYTFxfJd6WCgsRSr55+MF8Y6ZCTo9/wQeTrry82LidHP9xuu+3ia/ffrxsvXOemTTqsF3R0VlGJPPPISxHzyitaYZ95pqRv0TrkuZ2urjrdRXFeXp4HUzhmPjlZe3ygvcTSyIsEy3vbSEzUv6fJkwvKZGfrUOauXfXvq359HclYFHv2aLvz5thuv/38UPBNmwo8xcLDVBkZes5p0aLSbTZYFSNORpyKxGKxyO7dg+Svv3wkMzMm/9zArwaK7//5SmxqJUzipqWJ3HWX/rU+/fRFl7Oy9FRJno64kCpNCZHHH9fP/Ph4nVUFtPPyb4cRkq3spR/r8kPCZ32So4eH+vTRJ9zcdJjt9u3aU+raVT+kihOKnBy9+LVhw4vnILZtk2Jjy+fNk/wV9SJafL29tZi9/LJ+oy+NK64oeLjaIlVQUpL2Lnr3Pj9dz4WcO6f71r+/Xve0erWOKFRKv1mUJTghI0MPr+WtM1q0SM6LDMwjb50X6O+4JBYuLAgIKSrE8tNPtaiWFFRisBlGnIw4FUtS0l5Zu9ZOjh6dkn9ud/huUdOVPLaqiGGc8nDunF7JDjpCzdNTJC5O4uL0s8ySkSn3j8/KX1Jx9KjI0aGTJdvZ9bztAdLStDZE7zsrYm8vFqUk2cNfAgiTfj1SxDJqtORHRr3zzsWRURaLfgiXxNatuo6nnjr//PTp+gFcVMTEsWP6nrzkmHm5jAqPQ5bGu+8WPIitnMesWNLSyiYun3xSYGvemOuFiUZLI6+/mzfrQI2AgItFJSNDRzJeeWXJqYDyKG219GWIOjNUDCNORpxK5PDhibJunYOkpBS8XU5YPkEc/+coR6KPlL/Cf/8V+e9/tavj4qLnEXbtEgFZ2n2GXqjvHSsnnNvK94wqSAmWklIQ7VWEl5U/EbV8uYi7uyR0uEIyg3tq8XjrrUuPjLrvPu1hHT5ccK5HD/2QLAqLRXtJedF4d92lszYUlTW6OPKSj0IJMexViF27dBr29esLtlcoD3mZLa69Vg97Pvpo0eXCw6vH92G4JIw4GXEqkfT0cNmwwUP27r0p/1x4Urh4vOYhQxcOLd/i3E8/1b9CR0eRu+8+bw7jUPMhco668uDdSbK38dD8h7Jl5y5dIG9hZPv2+V5WPjk52jPKGxJavFjy396XL6945wsTGanFsV8/Pd4YHq7bmDGj+HtuvVW/5aem6mCC0rY+KIqrrtIeRG1h+vQCQS7PAldDjcOIkxGnUjl16v9k7VokOrpgF9b3N78vTEdmrC/h4VyYjRv1+P6QISIRERIZqZOorl2rpwT6oqOkLF27Sn44s6ennsgW0ZFcrVvne1ny6qsFdeftdbRwYcG5H38sJaldBchbDPvkk3q+Ci4Ofy7MBx/oMnn//vZb+ds8cKDyF1JWZaKj9UtF48ZlG7Yz1FiMOBlxKpWcnHTZsqW1bNnSNj+03GKxyF0/3CVMR5YfLsU7OXtWBxQUWizZq5ecN0Ux5naLWPLmoO65Rw+LPf20Xv+St/L///5P1zdkiA4UyEtTc/vtOjKuLAlUL5WHHtK2NGumk2qW5Dnu2KHL5i3KLSrNueFilizR2z8YajVGnIw4lYm80PLTpwsWYaZmpkqP2T3E4zWP4jcnzMnRXo+bW/4wXt56zscf157Tpk25U0I7d+oFmXmT2OHheu7B3V17XXkRY+vX6wquuUbP6Tg56Xmsy0FGhp5nAh31VxJZWdr7K0tZg8FwHkacjDiVmT17hsmGDZ6Snl4QBh2aECr+b/lL0CdBkpZVhOeybJn+tc2Zk3/qlVd0nEKZ8lw++KC+f9SognMWi86f1qqV/nTqpBXvcnHmjBbGskTQ5W3+VlW2ljAYqgnVTZyUtrn64O7uLikpKbY2o1JITT3Ktm0dqV//Ltq1m5d/ftWxVQxZOIRHr3iU9we/X3CDCPTuDdHR8O+/4OAAQFAQ+PnB+vVlaDQkBAYOhPnzoW/fyu3Q5WDePPjsM9i4Mb//BoOhdJRSqSLibms7yoqdrQ2ozbi5tSYw8HEiIr4kMXFr/vnBrQYzuddkPtj6Ab8d/63ghrVr4Z9/4Omn8x/M+/fDgQMwZkwZG23eHE6cqJ7CBHDvvbBlixEmg6GGYzVxUkrNVUqdU0rtL+a6l1JqhVJqj1LqgFLqXmvZUpVp2vQ5nJwacvTofxGx5J//v+v+j471OjL+x/GEJ4Xrk6+/Dg0awPjx+eW++Qbs7WHUqMttucFgqGkopQYrpf5VSh1TSj1TQrmeSqkcpdRoa9liTc/pS2BwCdcfBg6KSBdgAPCOUsrJivZUSRwcPGnR4v9ISvqHiIj5+eddHV35ZtQ3JGUkceM3N5K6eQOsWQOPPw4uLoAe5fv2Wz1K5+9vqx4YDIaagFLKHpgJDAE6AHcopToUU+7/gNXWtMdq4iQiG4DYkooAnkopBXjkls22lj1Vmfr176JOnSs5cWIqWVnx+ec71e/E4lsXs/fsLo5OvAXx9oYHHsi/vn27HqEr85CewWAwFE8v4JiInBCRTOBbYHgR5SYDPwDnrGmMLeecPgbaA2eBfcCjUnhcqxBKqUlKqe1Kqe3Z2TVPv5Syo3Xrj8nKiubkyRfOuza09VC2hN5AlwMxLLo7GOrUyb/2/vvg5gYjRlxWcw0GQ/XEIe85mvuZdMH1RkBooeOw3HP5KKUaASOBWdY11bbidAOwGwgAgoGPlVJ1iiooIrNFpIeI9HCooRPhnp7dCAj4D2fOfEJS0s6CC8uX033uKrYO7sTdddcxe8dsAA4f1vNNjzwCPj42MtpgMFQnsvOeo7mf2RdcV0Xcc2E49/vAVBHJsYqFhbClON0LLM0NwT8GhADtbGiPzWnefAaOjnU5cuQhHRxx5AiMGwc9etDjh80MbjWYR1Y+wt+n/+aVV8DVFZ580tZWGwyGGkIY0LjQcSB6ZKswPYBvlVIngdHAJ0qpEcVVqJT6QSk1TClVbq2xpTidBgYCKKXqA22BEza0x+Y4OnrTsuVbJCVtJfL4pzByJDg6wpIl2Lu5s+iWRTT1bsrwj6fyzTfCI49AvXq2ttpgMNQQtgGtlVLNc4PTxgA/FS4gIs1FpJmINAOWAA+JyI8l1PkpcCdwVCn1hlKqzA6I1cbIlFLfoKPw6iqlwoCXAEcAEZkFvAJ8qZTah3Ynp4pItLXsqS7Urz+Ws2c+w2HSE8jhLNRvv0HTpgD4uPqwfMxyugzaD45pjHswGTBhegaD4dIRkWyl1CPoKDx7YK6IHFBKPZh7vdzzTCKyBlijlPIC7gB+V0qFAp8DC0Qkq7h7TYaIqoYI6S9PxuXlmcQ81Q+/N89P+7BvH3TpItj3fY92d8xj7fi11HWrayNjDQZDdcFWGSKUUn7A3cBY9DDhQqAv0ElEBhR3n8kQUVVIS4NPP4WgIFxenknSoKbsH7qJ1NRj5xV7+mnw8lJ8/0EPjsUe4/qvrycpI8lGRhsMBkPxKKWWAn8BbsBNInKziHwnIpPRS4iKxYhTVeG55+Chh/QC23nzcPphPXb2Lhw/XhDxsGYNrFqli47o2o+lty1lb+Rexv84HkvRUfgGg8FgSz4WkQ4i8rqIhBe+ICI9SrrRiFNVYd8+6NlTr6y95x6cPZvSpMmzxMQsJzZ2NRaL9pqaNtXh4wBDWg/h7evfZtnhZbz212u2td9gMBgupr1SyjvvQCnlo5R6qCw3GnGqKoSHQ2AgqIKlBo0bP46raxuOHHmYr7/OZNcueO21/OxFADx6xaOM7TyWF9a+wI+Hf7z8dhsMBkPxTBSR+LwDEYkDJpblRiNOVYXwcGjY8LxTdnbOtGnzKQkJZ5g2LZXu3S9OVaSU4rMbP6NnQE9GLx7Nx/98THULcjEYDDUWu9wUdUB+Xr4y5VA14lQVSE+H2NiLxAnAx+dafvttHuHh3rzyymnsiviNuTq6smbcGoa2HsrkXyczccVEMrIzLoPhBoPBUCKrgcVKqYFKqWuBb4BVZbnRiFNVICJC/1uEOEVHw5w5t3HVVato2PDeYr2iOs51+HHMjzx/9fN8sesL+s7rS0hciDWtNhgMhtKYCvwJ/Ae9E8UfwNNludGIU1UgPDeIpQhxmjEDkpPtmDEjnvj4P4mKWlJsNXbKjleufYUfb/+RozFH6Ta7Gz/9+1Ox5Q0Gg8GaiIhFRD4VkdEiMkpEPitrXj4jTlWBYsTpxAn45BOYMAEGDLgVD49gjh9/nJyckhchD283nJ0P7KSlT0tGfDuCL3Z+YS3LDQaDoViUUq2VUkuUUgeVUifyPmW514hTVaAYcfr2W8jKghdeAKXsad36YzIywjh1qvSw8RY+Lfjr3r+4odUNTFgxIT+bucFgMFxG5qHz62UD1wDzga/LcmOZxEkp9ahSqo7SfKGU2qmUur7C5hrOJzxc77V+QRbX1auha1cdYQ7g5dWH+vXHERr6NqmpR0ut1tXRlWW3L2No66E88PMDvPbXa2TlFJvKymAwGCobVxH5A50q75SITAeuLcuNZfWc7hORROB6oB56u4s3KmKpoQjOnoX69bVA5ZKUBJs2wQ03nF+0RYv/w87OhaNHHy5TyLiLgwtLb1vKbR1v47k/n6PH5z34+/Tfld0Dg8FgKIr03O0yjiqlHlFKjaSM2arLKk55cepDgXkisoeiN6YyVIQi1jitXQvZ2XD9Bf6ps3MDWrR4jbi43zl37psyVe/s4My3o75l2e3LiEuLo++8vjyy8hFSMmtwAl2DwVAVmILOq/dfoDs6Aez4stxYVnHaoZT6DS1Oq5VSnoBJ5lZZFCFOv/2mt2C/6qqLiwcEPIinZy+OHXuMrKy4MjWhlGJEuxEcfPggU66YwifbPqHLrC5sOLWhMnpgMBgM55G74PY2EUkWkTARuTc3Ym9LWe4vqzjdDzwD9BSRVPS+TPdWzGTDRRQjTtdcA87OFxdXyp42bT4jKyuGEyeeKVdTHk4evDf4Pdbdsw6LWOj/ZX+GfzucPRF7LqUHBoPBcB65IePdC2eIKA9lFacrgX9FJF4pdTfwPJBQkQYNF5CdDVFR54lTSAgcPXrxkF5hPD2DCQycQnj4bGJjfyt3s/2a9mPvf/Yy45oZrD+5nuDPghn/43hiUmMq0guDwWAoil3AcqXUWKXULXmfstxYVnH6FEhVSnVBr+49hQ4JNFwqkZEgcp44/ZarNRcGQ1xI8+av4ObWkUOHxpKREVHupj2cPHiu33OEPBrCM32eYdG+RbSf2Z5v939r8vMZDIbKwBeIQUfo3ZT7ubEsN5ZVnLJFP62GAx+IyAeAZwUMNVzI2bP634CA/FOrV0OTJtCmTcm32tu70rHjd+TkJHH48Dikgns6+bj68Pp1r7Nj0g6aeTfjjh/uYPT3o4lKiapQfQaDwQCQO8904ee+stxbVnFKUkpNQ2+z+0vuRJdjRQ02FOKCBbipqfDHH3pIrywjte7uHWnV6gPi4n7n9Ok3L8mUzvU7s/n+zfzfdf/Hz0d+JujTIL7e8zUJ6WYE12AwlB+l1Dyl1NwLP2W5t6zidDuQgV7vFAE0At6qoL2GwlwgTvPmQWIijC9TsGXerROoV+9WTp58gaSkXZdkjr2dPU/3eZrtE7cT4BnAuB/H4femH1fPu5oPtnxAbFrsJdVvMBhqFT8Dv+R+/gDqAMlluVGVdW5BKVUf6Jl7+I+InCu/nZeOu7u7pKTUoPU506fD//4HGRlkK0fattXrcf/+u2yeUx5ZWTFs29YJR0c/unXbhr29S+k3lUK2JZu/T//N6uOrWXl0JXsi9+Bs78yoDqO4M+hOBrUchJN9mbZmMRgMNkYplSoi7ja2wQ5YIyKlZokoa/qi24B/gFuB24CtSqnRpdwzVyl1Tim1v4QyA5RSu5VSB5RS68tiS40jPBzq1gVHR5Yu1clen3qqfMIE4OjoR9u2X5CSsp+TJ1+sFNMc7Bzo36w/rw18jd0P7mb3A7uZ0G0CK4+u5MZvbqT+2/V5bNVjZjGvwWAoK62BJmUpWCbPSSm1BxiU5y0ppeqh1a9LCff0Q7tv80UkqIjr3sAmYLCInFZK+ZfFG6txntPNN8OpU8juPfTsqYf0Dh06L5NRufj33wcJD59NcPBavL37V66tuWRkZ7DmxBoW7V/EN/u+oY1fGxaNWkS3ht2s0p7BYLh0bOE5KaWSgMIiEwFME5EfSru3rHNOdhcIR0xp94rIBqCkCYo7gaUicjq3vE2GCW1O7gLcdetgxw548smKCxNAy5Zv4+raioMH7yQz0zrRds4OzgxrM4yFtyxkzbg1JGcm03tObx5b9Rin4k9ZpU2DwVD9EBFPEalT6NOmLMIEZRenVUqp1Uqpe5RS96Ant1ZW1OBc2gA+Sql1SqkdSqlxl1hf9eTsWdL9Anj4YT3XNO4SvwUHBw86dvyerKwYDh0aW+Hw8rJybfNr2fufvdzV+S4+3vYxLT9syW3f38an2z7lnzP/mO3iDYZqhFJqsFLqX6XUMaXURelnlFLDlVJ7c6djtiul+pZS30illFehY2+l1Igy2VKOgIhRQB90wtcNIrKsDPc0A34uZljvY6AHMBBwBTYDw0TkSBFlJwGTAJycnLpnZNSQB15ODuLszFf1p/JgzKusWgUDBlRO1WfPzubIkQdo3vw1mjadVjmVlkJoQigfbP2Ar/Z8RXRqNADO9s70DuzNgGYDuLPTnbTxK2XxlsFgsAqlDevlLhE6AgwCwoBtwB0icrBQGQ8gRUREKdUZWCwi7Uqoc7eIBF9wbpeIdC3VXmtmAihFnJ4BXHL390Ap9QWwSkS+L6nOGjHntHMnuLuT6eaNU5MGTFYfMXDpI4wYUXlNiAiHDt3FuXPf0anTCvz8hlZe5WVo+3TCabad3cbm0M2sP7WeXRG7sIiFm9rcxB1Bd3Ay/iR7z+2lcZ3GPN3naeq61b1s9hkMtZEyiNOVwHQRuSH3eBqAiLxeQvm5ItK+hDr3ikjnC87tE5FOpdpbkjgVMZmVf0nbLHVKrLxkcWoPfAzcADihowHHiEix0X1QA8QpPByaN4eMDI54dqdN0g7++M8SBn4yqtKbys5OZvfu/qSlHaFr1414eBQbv2J1zqWc45NtnzBz28x8r6qJVxPCEsPwcPJgWt9pTOk9BReHSw+BNxgMF6OUygT2FTo1W0RmF7o+Gh2gNiH3eCxwhYg8ckE9I4HX0fsyDRORzSW0OReIB2aitWQy4CMi95Rqr7U8J6XUN8AAoC4QCbxEblYJEZmVW+YpdHZzCzBHRN4vrd5qL05TpyJvv818/ye5LmIBjTgLe/ZA586l31sBMjLOsnPnFYgI3btvxdm5kVXaKStpWWnsP7efNn5t8HLx4sC5A0z7YxorjqwgyD+Ir0d+TXCDYJvaaDDURMrgOd0K3HCBOPUSkcnFlO8HvCgi15VQpzvwApBX5jfgVREp9SFu1WE9a1CtxSk+HmnShFV2QxmV+S3fL8piWPsT0LatVZtNTt7Drl19cXVtTXDwBhwcPKzaXkX49eiv3P/T/USlRvFA9wdwcXAhLi2Oc6nnOJt0lqiUKLxdvGng0YD2ddvz+JWP09S7qa3NNhiqDZU9rJdbJgS9lVJ0pdtrxOky8uqr8PzzBLOL578PZnSJy5grl5iYlezbdxN+fsMIClqGnvusWsSkxvDwyof57sB3uDm64ePiQz33egR4BlDXrS4J6QlEpkSyM3wnAJO6TeLhXg/T1q8tFdwyxmCoNZRBnBzQAREDgTPogIg7ReRAoTKtgOO5ARHdgBVAoBQjJEqp34FbRSQ+99gH+DZPAEu014jTZSI1FWnalPWpPXm87Up27Ch/FohL5cyZTzh69GEaNXqU1q3fv7yNl4McSw72dsWLZ2hCKDM2zGDu7rlkW7Jp6NGQQS0H8frA1wnwDCj2PoOhNlOWRbhKqaHA+4A9OtjhVaXUg6CnY5RSU4FxQBaQBjwlIhtLqO+iyLwqEa1nDaqtOM2cCY88Qj/W8+Tyftx8s23MOHbsccLC3qNly3dp3Pgx2xhRSZxOOM2qY6v4M+RPVhxZQX33+qwZt4YWPi2KLJ+enc7G0xvxdfU12SwMtQ4bZYjYAYzMS7aQGyS3VERK/Q9oxOlyIIIEBbH3uDv3tt/Kjp3qsntNBabkcODA7URH/0D79guoX/8u2xhSyfxz5h+GLByCs70zX4/8mhzJ4UziGc4mneVs0lmOxh5l4+mNpGWnYafsmH3jbO7vdr+tzTYYLhs2EqfBwGwgL3dqP2CSiKwu9V4jTpeBzZvhqquYwOfcvHyCzbymPHJy0tm3bwgJCRvp1OkXfH1L2A++GrH/3H4GfT2IiOTzdwX2dfWlcZ3G9G/an+taXMfMbTNZfXw1b173Jk/1ecpG1hoMlxdbZSVXSvmjkyjsBlyAc7np7Uq+z4iT9cm4+z6yFy3mxm7h/LnN02ZeU2GysxPYtUuvgerYccllXaRrTc4mnWXj6Y009GhIozqNCPAMuGjtVGZOJuOWjeO7A9/RyrcVbf3a0savDS19WtLCpwVdGnQxc1eGGoeNPKcJwKNAIFqcegOby7JlhhEna5OYSIZfQ77OvpOu2z+ne3dbG1RAZuY59u4dQnLyHtq1m0uDBrUnvWGOJYeP/vmITaGbOBJzhCMxR0jLTsu/3qtRL0a2G8noDqNp5dsK0IEYM7fNxF7Z83Cvh42AGaoVNhKnfeh9ALeISLBSqh3wsojcXuq9Rpysy6lnP6Pp6w/y9q1beXJxL1ubcxHZ2Yns338L8fF/0LLl2zRu/IStTbIJIkJkSiTHY4+z4dQGlh1exraz2wDo1rAbrXxbsfTQUkQEQXCwc+DuTnfj7+5PdGo0dsqOG9vcyKCWg3BxcCEzJ5OI5AgaejTE0d7Rxr0zGGwmTttEpKdSajc620RGUfn2irzXiJP1yMmBI3V6IJmZBJzbg7dPFRjPKwKLJYNDh8YSFfU9TZu+RLNmL5l1Q+howO8PfM93B77jcPRh7ut6H49f+ThZOVm8velt5u2eR47kUNetLqlZqSRmJOLp5ImPqw+hCaEIgrO9M0H+QQT5B9HIUw8zBtYJpJl3M5r7NKeOc4kZwAyGSsNG4rQMnQVoCnAtEAc4ikip8whGnKzIV0/tZ/zbndg+9gN6zP+vrc0pEZEc/v13IhER8wgMfIKWLd8yAlUK2ZZs7JU9SikyczL5M+RPlh5aSmpWKi19WhLgGcCx2GPsjtzN4ejDhCeFkyM5+ffbKTvu6XIPr1z7CgGeAYgIx2KP4eXihb+7vw17ZqiJ2HqbdqVUf8ALneA7s9TyRpysw4ED8HWXt3kj5ykkNAwVaNucdmVBxMKxY1M4c+YjGjacQOvWn2Jn52Brs2oMFrEQlRJFaGIoJ+NPsuHUBmZtn4WjvSP9m/Zn29lt+UlxA+sE0jOgJ2M7j+XGNjeaoUHDJWNrcSovRpysQGYm9O4Nb+0fQv+mITgcPWxrk8qMiHDy5IucOjWDunVH0r79IuztTaZwa3E89jjP/fkcuyN2c2XjK+nTuA+JGYnsCN/BupPrOJt0lgDPAK5rcR0igkUsXNHoCm4Pur3M3lXeho/ODs7W7IqhimPEycpUB3F68UV445VMUp19cJhwL3z8sa1NKjdhYR9w7NgUvLz607HjEpyczH5Ll5tsSza/Hv2VWTtmsS9yHw52DmRbsglNDMVe2XNV46uwiIWEjAQaeTZiXJdxjGg3AjdHN0SEw9GH+WTbJ3y15yuUUtzW4TbGB4/nysArS0wPZbg8ZFuy+fnIz8Snx3N357txKDRKEZcWh4+rT/6xRSzM2DCDm9rcRNeGpWb+KRIjTlamqotTZib4+cHjPf/i5bX9YOlSGDnS1mZViMjIRRw+fB9OTg0IClqKp6dJ+VMV2H9uPwv3LmTdqXW4Obrh6eTJnsg9nIw/ibujO26ObiRkJJCZk4mTvROjO4zG0c6RJQeXkJKVgoeTBz0CetDatzWxabGcSzmHq6MrLX1a0ty7OV4uXrg7uuPv7k+PgB74uPqQmZPJxtMb2Xh6IymZKWRZsrBX9vi5+eHr6ou/uz/13OrRxKsJjb0an2dvaEIoDTwaVNuhyeTMZNwd3fPnYBMzEjkRd4IO9TrgZO90UfnMnEx+PforzX2a08m/U/59GdkZnIg7wfG44+w4u4Mvdn1BaGIoAH0a92HBLQvIyM7gqd+fYsWRFdwXfB/v3vAudsqOscvGsvzf5UzrO43XBr5WoX4YcbIyVV2c/vwTBg6Ew2Om03bxKxAdDT4+pd9YRUlM3M6BAyPJyoqmdetPaNDgHhMoUQWxiIUNpzaw5OASciw5eLt4E+AZcN7wX3JmMiv+XcGm0E1sPbOVk/Enqedej3pu9UjJSuF47HHi0uMuqruVbysikiNIzkxGoXCyd8LR3pGsnCwycjIuKj+uyzjeGvQWbo5uPPfHc3z0z0dcEXgFy25fRgOPBgBEJEcQnx5f5ozyOZYc1p9az8n4k9zS/ha8XbwvKiMiRKdGcyDqAAejDnIu5RyJGYmkZaXR2KsxrXxbEdwgmDZ+bUptT0T4/cTvvPrXq2w4tQE3RzeaejUlPTudkPgQAIIbBLPwloV0qNch/77Vx1bz6KpH+TfmXwAaeDSgQ70OhMSFcCrhFBax5Jcd2Hwgj/R6hJTMFB5a+RAWsZCenY6rgyvD2gxj8YHFBHgG4OnkyZGYI7x7w7tM7jW5wv//jDhZmaouTk88oUfxUrtfjX1WOmzbZmuTLpnMzHMcPDiG+Pi11Ks3mjZtPsPR0dfWZhmsQEJ6AkmZSaRmpRKaEMrWM1vZfnY7/u7+DG09lGubX4uHU8F+YKlZqcSkxhCdGs25lHP8GfIn7215Dw8nDzycPAhLDOO2jrex4sgK/Fz9+GjIRyz/dzkL9i4gy5KFn6sffZv0pV3ddjT1akqAZwCO9o442DmQmJFIWGIYR2KO8OPhHwlPDgfAzdGN8V3G09SrKXsi9+QLUWxa7EVi6enkiZO9EzFpMfnnujboyh1Bd5BlyWJT6CaOxR7j6iZXc3Pbm/Fx9WH1sdX8dOQn9kbupZFnI+7reh/JmcmcSjiFg50DXep3wcfFhxfXvUhyZjKTe00mPj2e3RG72XZ2G618W/HGwDdIykzit+O/cTzuOC19WtLGrw2tfFvlf+q6FQyVh8SF8PDKh2nq1ZTpA6ZT36M+/5z5h/E/judcyjkWj17MwBYDL+l3a8TJylR1cWrfHtoEJLN8g49WqjfesLVJlYJIDqGhbxMS8jyOjvXp0GER3t79bG2WoQpyKOoQk3+dTFRqFJ8O+5SrGl/FrvBd3PztzYQlhuHq4Mr9Xe8nuEEwG0M3sil0EyFxIWRZsoqsz9XBlcGtBnNH0B009W7KrO2zWLRvERk5GTTxakKQfxANPRri5+pHA48GdPTvSMd6HWno2RA7ZQdASmYKx+OOszZkLQv2LWD72e0AtK/bnuY+zfnr1F8kZSYBOsS/d2Bv7g2+l3FdxhU5dAfa+7v/p/tZeXQlfq5+BPkHMaz1MP57xX8rLfgkzzst/EJQUYw4WZmqLE4nTkDLlrBs0q+MmD0UfvsNBg2ytVmVSlLSTg4eHENa2nGaN/8fTZpMQ+U+AAyGkohIjmDZoWWM7jCaeu71zruWY8khMiWS8KRwsi3ZZFmy8HTyJLBOIL6uvhcNZSWkJ2ARy3lBA+XhVPwpPJ098XXVIwCZOZmsP7me5Mxkrml+TZHDhsWRt/i6qg93G3GyMlVZnHK3bCL2vifxWfARxMWBm5utzap0srOTOHLkAc6d+wZv74G0azcPF5fGpd9oMBhsRnUTJ/PKW4msXAmtWwk+W1fBVVfVSGECcHDwpH37hbRp8zmJiVvYti2IiIivqG4vOgaDoepixKmSSEvTkXpTOv2h00PccYetTbIqSikCAibQs+dePDy6cPjwPRw4MIqsrJjSbzYYDIZSMMN6lcTKlTBsGEQHD8Qv8hCEhIBz7ViRr4Ml3iMk5FkcHevRvv18fHwuLbLIYDBULmZYLxel1Fyl1Dml1P5SyvVUSuUopUZby5bLwbJl0M/lH/x2/wmPP15rhAlAKXuaNHmSbt22YG/vyZ4913H48P1kZkbZ2jSDwVBNsZrnpJTqByQD80UkqJgy9sDvQDowV0SWlFZvVfSc0tKgYUNY43ULPRLXwunT4Olpa7NsQk5OCidP/o+wsHext/egefPXCAh4wET0GQw2xnhOueTuER9bSrHJwA/AOWvZcTlYsQIaJhyix+llOlyvlgoTgL29Oy1b/h89euzFw6MbR48+xK5dfUhO3mtr0wwGQzXCZq+zSqlGwEhgVhnKTlJKbVdKbc/Ozra+ceVkwZfZzHX6D+LmBv+t2vs2XS7c3dvTpcsa2rX7mrS0Y2zf3o2jR/9LZma0rU0zGAzVAFuOtbwPTBUptPtaMYjIbBHpISI9HByq1v5CkZFwzaqpXJm5HvXZZ1CvXuk31RKUUjRocDe9eh2mYcP7OXNmJlu3tuTUqTfIyUmztXkGg6EKY9VoPaVUM+DnouaclFIhQN6S6rpAKjBJRH4sqc6qNue0cty3DP36DmLumozfgg9tbU6VJiXlICdOTCUm5mecnRvTvPkM6te/28xHGQyXgeo252Qzcbqg3Je55apHQMR998ESbWpOUgr7PK4kOOZPcCo6B5fhfOLj13P8+JMkJW3H07MHbdvOwcOji63NMhhqNGURJ6XUYOADwB6YIyJvXHD9LmBq7mEy8B8R2WMNe60ZSv4NsBloq5QKU0rdr5R6UCn1oLXavCyIaGFq25YT107gdaax7ZmlRpjKgbd3f7p120r79gtITz/N9u3dOXFiGllZ8bY2zWCoteRGT88EhgAdgDuUUh0uKBYC9BeRzsArwGyr2WMW4ZaTkBBo0YJzMz6j7duTaNYMNm0CV1fbmVSdycqK5fjxJ4mImIdSztStezMNGtyHr+8NVT6RpsFQnSjNc1JKXQlMF5Ebco+nAYjI68WU9wH2i0gja9hrBvvLy14dEv34l11QSm90a4Sp4jg6+tKu3Vy6d99JQMAk4uL+ZN++IezY0YPo6J9Mvj6DofJwyIt6zv1MuuB6IyC00HFY7rniuB/4tbKNzKNqhb5VQXbu1PlbW7eGnBw48d0e2qD48VgQS36F5s1tbWHNwNOzK56eXWnZ8m0iIxdx6tQM9u8fjqdnL1q1+gAvr962NtFgqO5ki0iPEq4XNVRR5NuhUuoatDj1rQzDisJ4TiUQGgo9eugNBD08oH592P/NXkLsWvH2p+4MHmxrC2sednZONGx4D716HaZt2y/IyAhl164rOXjwblJSDtjaPIOhJhMGFN77JhA4e2EhpVRnYA4wXESslunZzDmVwJIlcOut8PLLkJAA8fHwwao2uF3RGbulpQYWGiqB7OxkTp9+ndDQdxDJoE6dPgQEPIi//23Y2ZkgFIOhrJRhzskBOAIMBM4A24A7ReRAoTJNgD+BcSKyyZr2mmG9Eti+HVwds5k61UHncU1JAc9jEHy3rU2rNTg4eNCixasEBk4hIuIrwsNnc/jwWE6ceIqAgIcICPgPTk51bW2mwVDtEZFspdQjwGp0KPlcETmQF2EtIrOAFwE/4JPcgKXShgorjPGcSuC1oEVMOTQJt4VzYMwY2LoVeveGH3+E4cMviw2G8xER4uJ+JyzsfWJjf8Xe3oPAwCkEBj6Bo6O3rc0zGKos1W0RrplzKgoR5MWXePbAXbhZUuC99/T5PblrzTp3tp1ttRylFL6+19O580p69jyAr+9QTp2awZYtzTh27AlSU4/a2kSDwVAJGM/pQkRg0iSYM4e53EvQ6Pb0WvK0FqbZs2H+fD0BZdbgVBmSk/dw6tSrREcvQyQbH5/rqF//burWHYmDQx1bm2cwVAmqm+dkxOlCPv4YJk/m4M3P0PGn19i3Lpag6wO0YO3ercVr40brtW+oMBkZZwkPn0NExJekp4dgZ+eCv/8dNGnyDG5ubWxtnsFgU4w4WRmritPff8OAATB4ME+2Xs7MT+1ISgKHcXfCr7/qhU5jx8LMmdZp31ApiAiJiVuJjPyKiIgvsVgyqVdvNA0b3o+397XY2Zk4IEPtw4iTlbGaOEVGQteuesXt9u30H+5NVpZOTcTatXDttbrcrFnwwAOV377BKmRmRhIa+h5nz35KTk4ijo7++Pvfhr//ndSp09ukSDLUGqqbOJmAiDy+/x7Cw2HxYnI8vdm5Uy/ABaB/f2jZUv/cxWTPrk44OdWnZcs3uOqqSDp2/AEvr6s5e/Zzdu26iq1bW3Dy5P/IyIiwtZkGg+ECjDjlceoUuLhA164cOQLJyYXEyc4OJk8GLy8IKnH3D0MVxd7ehXr1biEoaAl9+kTSrt2XuLq24uTJl9iypQkHD95NUtJuW5tpMBhyMcN6edx+uw54+Pdf5s+H8ePhwAHokJcwXkQrlqdn5bdtsBmpqUc4c2YmERFzyclJxtd3MAEBD+PtPQAHBw9bm2cwVBrVbVjPiFMevXtr4fn9d/7zH1iwQKcrsrev/KYMVY+srDjOnv2UsLD3ycqKQikHPD2voF69W/D3vxNn5wa2NtFguCSMOFkZa4mTBASwv/EQ7k7/gr17Ydgw+PnnSm/GUMXJyUknIWEj8fF/EBu7muTkXYAdPj6DqF//TurWHWHWThmqJUacrIxVxCkjA1xceInprOr1EmPHwt13g7d35TZjqH6kpBwmMvJrIiMXkpFxCjs7F+rVu51mzV7E1bWFrc0zGMqMEScrYxVxOnECWrbkCZ+5vBN7b+XWbagR6LVTm4mMXEhExFxEsmnQ4H4aNBiPp2dPs3bKUOWpbuJk/kcBnD4NgFfnpjY2xFBVUUrh5XUVXl5X0bTpc5w69Srh4Z8THv4Z9vZ18PEZSL16o/HzuwkHBxM0YzBcKkacgPg9p/AGAq9qYmtTDNUAZ+cA2rSZSfPm/yMu7k/i4tYQE/Mz0dHLsLNzwdv7Gry9++Pl1R9Pzx7GqzIYKoD5XwOEbz2NN9Dh+kBbm2KoRjg6+uHvfyv+/rciYiEhYRNRUYuJi1vDiRO/AuDg4Iuv7xDq1h1B3bo3YWfnbGOrDYbqgZlzAv7pMpEme1fgkx6hNxU0GC6RzMxzxMevJSZmJTExv5CdHYODgx8NGoylfv3xeHh0MamTDJeV6jbnZDVxUkrNBW4EzonIRWkVlFJ3AVNzD5OB/4jIntLqtYo4+d6Ae2YcHZP/qdR6DQYAkRzi4v4gPHwO0dE/IpKFq2sb/P1vx9d3qBn6M1wWjDjlVaxUP7TozC9GnK4CDolInFJqCDBdRK4ord7KFqfsbDjm1J70lh0JPrqk0uo1GIoiMzOa6OgfOHduMfHx6wAL9vZe+PoOws/vZvz8huHo6GtrMw01kOomTlZ7XRORDUqpZiVc31TocAtgkwmfvXuEtnKa0DZDbdG8oZbh5FSXgIAHCAh4gKysGOLi/iA29jdiY1cSFbUEsMfLqy9+fsPw87sJd/d2tjbZYLAJVWUs4X7g1+IuKqUmAZMAnJycKrXh3X/E0I1U/HuYSD3D5UUHVNyGv/9tiFhIStpBdPRyYmJ+5sSJpzlx4mk8Pa8gIOAB/P1vw96+2rz0GgyXjFUDInI9p5+LGtYrVOYa4BOgr4jElFZnUcN6WVlZhIWFkZ6eXm4b489l4p0WDvXq6b2cDFbFxcWFwMBAHB0dbW1KlSY9/TRRUT8QHv45qamHUMoZL68++PhcR716t+Dm1tbWJhqqGdVtWM+m4qSU6gwsA4aIyJGy1FmUOIWEhODp6Ymfn1+5I6BO7YmjadZxaN8e3KvN761aIiLExMSQlJRE8+bNbW1OtUBESEj4m+joH4mLW0NKio4Z8vS8gvr178bb+2rc3DqagApDqVQ3cbLZX7RSqgmwFBhbVmEqjvT0dJo1a1ZuYcrKApWVqQ8qebjQcDFKKfz8/IiKirK1KdUGpRTe3n3x9u4LQEbGWc6d+4aIiK84dmwyAHZ2rtSpcyV+fjfi53cTbm6tbGmywVApWE2clFLfAAOAukqpMOAlwBFARGYBLwJ+wCe5opItIj2Krq1M7ZX7nsREcCITUXYoB/PmeTkwa3suDWfnABo3foLAwMdJSztOUtI2EhO3Ehe3huPHH+f48cdxcWmOt/cAfHyuo27dkdjbu9rabIOh3FgzWu+OUq5PACZYq/2ykJAAvioTnJ3APDQN1QilFG5urXBza0X9+vq/WlraCWJifiE+fi3R0cuJiJiHg4MfAQET8fO7GUfHejg51cPBwcvG1hsMpVNrt2kX0Z6Ti30m6hKH9OLj4/nkk08qdO/QoUOJj4+/pPYNBgBX1xYEBk4mKGgpffpE0aXLn3h79+P06TfZtesq/vmnNRs3erNzZx/Cw+eSnZ1sa5MNVQyl1GCl1L9KqWNKqWeKuN5OKbVZKZWhlHrSqrbUhPRFhw4don379uWqJzUVDh6ErvZ7sPfxgmbNKmzTyZMnufHGG9m/f/9F13JycrCvhtvpiggigp1d5b+/VOT3Zag46emhpKTsJysrmvT0k5w7t4jU1MMo5Yi7eyc8Pbvj5dUXX98bcHKqb2tzDVaitIAIpZQ9cAQYBIQB24A7RORgoTL+QFNgBBAnIm9by94aN9EyZQrs3l16ucxMyMqw4E4LPaxXgvMUHAzvv1/89WeeeYbjx48THBzMoEGDGDZsGC+//DINGzZk9+7dHDx4kBEjRhAaGkp6ejqPPvookyZNAqBZs2Zs376d5ORkhgwZQt++fdm0aRONGjVi+fLluLqeP1+wYsUKZsyYQWZmJn5+fixcuJD69euTnJzM5MmT2b59O0opXnrpJUaNGsWqVat49tlnycnJoW7duvzxxx9Mnz4dDw8PnnxSv/gEBQXxc+62v0OGDOGaa65h8+bN/Pjjj7zxxhts27aNtLQ0Ro8ezcsvvwzAtm3bePTRR0lJScHZ2Zk//viDoUOH8tFHHxEcHAxAnz59+PTTT+ncuXPpvxCD1XBxaYyLS+P846ZNnycxcTPR0T+RnLyDqKjvCQ//HAAPj665SWpH4u4eZOYIaxe9gGMicgJAKfUtMBzIFycROQecU0oNs7YxNU6cykpOtuBKmp5rcri0NTdvvPEG+/fvZ3euKq5bt45//vmH/fv354dMz507F19fX9LS0ujZsyejRo3Cz8/vvHqOHj3KN998w+eff85tt93GDz/8wN13331emb59+7JlyxaUUsyZM4c333yTd955h1deeQUvLy/27dsHQFxcHFFRUUycOJENGzbQvHlzYmNjS+3Lv//+y7x58/KHKV999VV8fX3Jyclh4MCB7N27l3bt2nH77bfz3Xff0bNnTxITE3F1dWXChAl8+eWXvP/++xw5coSMjAwjTFWQwntTAYhYSE7eQ2zsKmJjV3Ly5HROnnwJF5dmeHn1pU6dPvj5DTtP4AzVEgel1PZCx7NFZHah40ZAaKHjMKDUlHLWosaJU0keTh45OULCrhB8iEW1bg1elT901atXr/PW8nz44YcsW7YMgNDQUI4ePXqRODVv3jzf6+jevTsnT568qN6wsDBuv/12wsPDyczMzG9jzZo1fPvtt/nlfHx8WLFiBf369csv4+tbes62pk2b0rt37/zjxYsXM3v2bLKzswkPD+fgwYMopWjYsCE9e/YEoE6dOgDceuutvPLKK7z11lvMnTuXe+65p9T2DLZHKTs8Pbvi6dmVpk2nkZkZSXT0j8TGriY29nciIxdw9KgddeveTMOGk3B3D8LJqQF2dmYhdTWjtIjootxkm8371DhxKguZZ6LwJZb0uo1w8bJO5JJ7oQW969atY82aNWzevBk3NzcGDBhQZDYL50L7ddjb25OWlnZRmcmTJ/P4449z8803s27dOqZPnw7oOaILh2CKOgfg4OCAxWLJPy5sS2G7Q0JCePvtt9m2bRs+Pj7cc889pKenF1uvm5sbgwYNYvny5SxevJjt27dfVMZQ9XFyqp+f/09ESEs7SkTEl/lZ1TUKZ+dGeHgE4+ERjI/PDXh59THDgNWbMKCwexwInLWRLbUzWk/FxZKCG06NG1RKfZ6eniQlJRV7PSEhAR8fH9zc3Dh8+DBbtmypcFsJCQk0atQIgK+++ir//PXXX8/HH3+cfxwXF8eVV17J+vXrCQkJAcgf1mvWrBk7d+4EYOfOnfnXLyQxMRF3d3e8vLyIjIzk1191+sN27dpx9uxZtm3bBkBSUhLZ2dkATJgwgf/+97/07NmzTJ6aoWqjQ9bb0KLFa1x5ZSidOq2kTZvPaNbsJby9B5CWFsKpU6+ze/fVbN3ampCQF4iIWEBc3FoyMiJsbb6hfGwDWiulmiulnIAxwE+2MqbWeU45OWCflU6Gkw929pXzlufn50efPn0ICgpiyJAhDBt2/lzh4MGDmTVrFp07d6Zt27bnDZuVl+nTp3PrrbfSqFEjevfunS8szz//PA8//DBBQUHY29vz0ksvccsttzB79mxuueUWLBYL/v7+/P7774waNYr58+cTHBxMz549adOmTZFtdenSha5du9KxY0datGhBnz59AJ1897vvvmPy5MmkpaXh6urKmjVr8PDwoHv37tSpU4d77723wn00VE3s7Jzx8xty0fns7CSio5cSETGfU6depfBIUJ06vfHzG46X11W4u3fE0dHvovsNVQMRyVZKPQKsBuyBuSJyQCn1YO71WUqpBsB2oA5gUUpNATqISGJl21PrQsmjwrOod2YPGf6NcW5iwmYrm7NnzzJgwAAOHz5cbBi6CSWvuWRnJ5OZeYaMjDMkJm4mKmoZyck78q87OTXE27s/3t7X4Os7xARZXEZMbr0qjAgknkunHuDs5WJrc2oc8+fP57nnnuPdd9+1yvooQ9XHwcEDB4e2uLm1xcfnWpo2fY6MjLMkJ+8lNfUASUk7iY9fy7lz3wIKX98baNDgPpydG2GxpGNn54ynZy8TbGGoXZ5TTAwkhUTRjFPQqRMUCkAwXD6M51S7ERFSU//NTWA7l4yMsPOuOzj4Urfuzfj4DMLdvRNubm2xszOJmS8V4zlVUUQgMhL8HdKRHHXJKYsMBkPFUErh7t6O5s1fplmzF0lI+DvXa3IhKyuK6OgfiYpaRkTEl7nlHXF370ydOr3w9OyFh0cw7u7tsbMzL5c1mVojTklJOmWRp2s6ytHFJHo1GKoAStnj7d3vvHP16o3CYskiNfVfUlL2kZy8h6SkbURGLuDs2U9z73PA1bU1bm5tcXPrgJ/fjdSp09uEstcgao04OTiAnx84JaebHW8NhiqOnZ0jHh5BeHgE5WddF8khNfUoKSl7SE7eQ0rKQVJTDxMT8zOnT7+Gi0tzfH2H4Ojoh719HZydA3B1bYmLS0scHcu/EanBttQacXJzg+ZNLbAzQ6uUwWCoVihlj7t7O9zd2+Hvf3v++ezsRKKjfyQyciGRkQvJyUnkwsQGdnYuODkF4ObWnrp1b6Zu3eEmyW0Vp9aIEwB5mRBcbB+p5+HhQXKy2bLAYLhUHBzq0KDBOBo0GAfoXIE5OclkZISRlnac9PQTZGSE5Ya3b+XIkV84cuRBXF1b4+7eMffTCXf3zri5tUYn5zbYGiNOtZTs7GwczO6/hhqIUnY4ONTBwaED7u4dzrsmIqSk7MvNyL6TlJSDREcvB3Q6LwcHH/z8bqZevZG4ubXHwcEbBwcvlHIyw4KXmZr3dCppz4zMTMjIAA+P8gVElLJnxtSpU2natCkPPfQQoLM4eHp68sADDzB8+HDi4uLIyspixowZDB8+vMSmittao6itL4rbJqOwV7ZkyRJ+/vlnvvzyS+655x58fX3ZtWsX3bp14/bbb2fKlCn5WR7mzZtH27ZtycnJYerUqaxevRqlFBMnTqRDhw58/PHH+clrf//9dz799FOWLl1a9u/RYLAxSik8PDrj4VGQLT8nJ53U1EOkpOwlLu4PYmKWExn51YV35g4NNiyUT/Da3CAM42lZg5onTiVhsYCdXaVH6o0ZM4YpU6bki9PixYtZtWoVLi4uLFu2jDp16hAdHU3v3r25+eabS3wDK2prDYvFUuTWF0Vtk1EaR44cYc2aNdjb25OYmMiGDRtwcHBgzZo1PPvss/zwww/Mnj2bkJAQdu3ahYODA7Gxsfj4+PDwww8TFRVFvXr1mDdvnklRZKgR2Nu75Gdlb9BgPBZLJgkJf5ORcYacnASysxOwWNLIyUkjI+M0ycm7iY5eysmTL+LoWBdv72txdg7EyckfN7eO+Phcg719tVlOVGWpeeJU0p4ZBw+CoyO0bl2pTXbt2pVz585x9uxZoqKi8PHxoUmTJmRlZfHss8+yYcMG7OzsOHPmDJGRkTRoUHzC2aK21oiKiipy64uitskojVtvvTV/Z96EhATGjx/P0aNHUUqRlZWVX++DDz6YP+yX197YsWNZsGAB9957L5s3b2b+/Pnl/aoMhiqPnZ0TPj7XlFgmKyuO2NjVxMSsIDFxEzExP2OxpAKglBNeXn1y8wgqHBy88fUdjI/P9Tg4eFyGHtQMap44FYeInnPy9LRK9aNHj2bJkiVEREQwZswYABYuXEhUVBQ7duzA0dGRZs2aFblVRh7Fba1R3BYVxZ0vfO7C9gpvifHCCy9wzTXXsGzZMk6ePMmAAQNKrPfee+/lpptuwsXFhVtvvdXMWRlqLY6OPtSvP4b69cfkn8vOTiYpaSsxMb8SH7+OzEydlT0j4yzh4Z+jlBNubu1wdKyHk5M/zs6NcXFpiotLU5ydm+Di0hQHhzq26lKVw2pPF6XUXOBG4JyIBBVxXQEfAEOBVOAeEdlpLXvIzNTDelYKhhgzZgwTJ04kOjqa9evXA9oz8ff3x9HRkbVr13Lq1KkS6yhua40rr7yShx9+mJCQkPxhPV9f3/xtMt7P9Rbj4uLw8fGhfv36HDp0iLZt27Js2TI8ixHkwttvfPnll/nnr7/+embNmsWAAQPyh/V8fX0JCAggICCAGTNm8Pvvv1/iN2Yw1CwcHDzw8RmIj8/A885bLFkkJPxNTMzPpKUdJSsrisTErWRk/IBI5gV1+ODi0ixXsBrj7ByIq2tLPD174uzcuFYFZVjz1fdL4GOguLGfIUDr3M8VwKdYc0tgK0fqdezYkaSkJBo1akTDhg0BuOuuu7jpppvo0aMHwcHBtGvXrsQ6ittao169ekVufVHcNhlvvPEGN954I40bNyYoKKjYkPWnn36a8ePH8+6773Lttdfmn58wYQJHjhyhc+fOODo6MnHiRB555JH8PkVFRdGhQ4ci6zQYDOdjZ+eIj88AfHwGnHdexEJmZiTp6afIyDhFenre5ySpqUeIi1tLTk5CfnlHR3+aNJlK48aPX1b7bYVVE78qpZoBPxfjOX0GrBORb3KP/wUGiEh4SXVWOPFrcjJEREDTpnreyVAhHnnkEbp27cr9999f4TpM4leDoWxkZyeRmnqYpKRtJCb+g6/vDfkZM8qLSfxadhoBoYWOw3LPXSROSqlJwCTQG91VCA8PaNWqYvcaAOjevTvu7u688847tjbFYKgVODh4UqdOT+rU6UmjRg/Z2pzLii3FqajB0yLdOBGZDcwG7TlZ0yhD8ezYsaP0QgaDwVAJ2HJHuDCg8DaYgcDZilZW3falqq2Y35PBYCgLthSnn4BxStMbSChtvqk4XFxciImJMQ++Ko6IEBMTg4tJH2UwGErBmqHk3wADgLpKqTDgJcARQERmASvRYeTH0KHkFU43EBgYSFhYGFFRUZdqtsHKuLi4EBgYaGszDAZDFadGbNNuMBgMhpKpbtF6thzWMxgMBoOhSIw4GQwGg6HKYcTJYDAYDFWOajfnpJSyAGkVvN0ByK5Ec6oCpk/VA9On6kFN7pOriFQbh6TaidOloJTaLiI9bG1HZWL6VD0wfaoemD5VHaqNihoMBoOh9mDEyWAwGAxVjtomTrNtbYAVMH2qHpg+VQ9Mn6oItWrOyWAwGAzVg9rmORkMBoOhGmDEyWAwGAxVjlojTkqpwUqpf5VSx5RSz9janoqglGqslFqrlDqklDqglHo097yvUup3pdTR3H99bG1reVBK2Suldimlfs49rtb9AVBKeSulliilDuf+vq6szv1SSj2W+ze3Xyn1jVLKpTr2Ryk1Vyl1Tim1v9C5YvuhlJqW+8z4Vyl1g22sLpli+vRW7t/eXqXUMqWUd6FrVb5PUEvESSllD8wEhgAdgDuUUh1sa1WFyAaeEJH2QG/g4dx+PAP8ISKtgT9yj6sTjwKHCh1X9/4AfACsEpF2QBd0/6plv5RSjYD/Aj1EJAiwB8ZQPfvzJTD4gnNF9iP3/9YYoGPuPZ/kPkuqGl9ycZ9+B4JEpDNwBJgG1apPtUOcgF7AMRE5ISKZwLfAcBvbVG5EJFxEdub+nIR+4DVC9+Wr3GJfASNsYmAFUEoFAsOAOYVOV9v+ACil6gD9gC8ARCRTROKp3v1yAFyVUg6AG3pj0GrXHxHZAMRecLq4fgwHvhWRDBEJQW/v0+ty2FkeiuqTiPwmInmZLragN3OFatInqD3i1AgILXQclnuu2qKUagZ0BbYC9fM2asz919+GppWX94GnAUuhc9W5PwAtgChgXu5w5RyllDvVtF8icgZ4GzgNhKM3Bv2NatqfIiiuHzXluXEf8Gvuz9WmT7VFnFQR56ptDL1SygP4AZgiIom2tqeiKKVuBM6JyA5b21LJOADdgE9FpCuQQvUY8iqS3DmY4UBzIABwV0rdbVurLgvV/rmhlHoOPR2wMO9UEcWqZJ9qiziFAY0LHQeihyWqHUopR7QwLRSRpbmnI5VSDXOvNwTO2cq+ctIHuFkpdRI91HqtUmoB1bc/eYQBYSKyNfd4CVqsqmu/rgNCRCRKRLKApcBVVN/+XEhx/ajWzw2l1HjgRuAuKVjQWm36VFvEaRvQWinVXCnlhJ4Q/MnGNpUbpZRCz2McEpF3C136CRif+/N4YPnltq0iiMg0EQkUkWbo38mfInI31bQ/eYhIBBCqlGqbe2ogcJDq26/TQG+llFvu3+BA9Hxnde3PhRTXj5+AMUopZ6VUc6A18I8N7Cs3SqnBwFTgZhFJLXSp+vRJRGrFBxiKjlo5Djxna3sq2Ie+aBd8L7A79zMU8ENHGR3N/dfX1rZWoG8DgJ9zf64J/QkGtuf+rn4EfKpzv4CXgcPAfuBrwLk69gf4Bj1vloX2Iu4vqR/Ac7nPjH+BIba2vxx9OoaeW8p7TsyqTn0SEZO+yGAwGAxVj9oyrGcwGAyGaoQRJ4PBYDBUOYw4GQwGg6HKYcTJYDAYDFUOI04Gg8FgqHIYcTIYrIxSakBexnWDwVA2jDgZDAaDocphxMlgyEUpdbdS6h+l1G6l1Ge5+0wlK6XeUUrtVEr9oZSql1s2WCm1pdB+OT6551sppdYopfbk3tMyt3qPQvs7LczNtIBS6g2l1MHcet62UdcNhiqHESeDAVBKtQduB/qISDCQA9wFuAM7RaQbsB54KfeW+cBU0fvl7Ct0fiEwU0S6oPPPheee7wpMQe8n1gLoo5TyBUYCHXPrmWHNPhoM1QkjTgaDZiDQHdimlNqde9wCvZXHd7llFgB9lVJegLeIrM89/xXQTynlCTQSkWUAIpIuBXnN/hGRMBGxoNPJNAMSgXRgjlLqFqBwDjSDoVZjxMlg0CjgKxEJzv20FZHpRZQrKd9XUdsR5JFR6OccwEH0ZnC90FnmRwCrymeywVBzMeJkMGj+AEYrpfwBlFK+Sqmm6P8jo3PL3AlsFJEEIE4pdXXu+bHAetF7a4UppUbk1uGslHIrrsHcfbm8RGQlesgvuNJ7ZTBUUxxsbYDBUBUQkYNKqeeB35RSdugMzw+jNwrsqJTaASSg56VAb60wK1d8TgD35p4fC3ymlPpfbh23ltCsJ7BcKeWC9roeq+RuGQzVFpOV3GAoAaVUsoh42NoOg6G2YYb1DAaDwVDlMJ6TwWAwGKocxnMyGAwGQ5XDiJPBYDAYqhxGnAwGg8FQ5TDiZDAYDIYqhxEng8FgMFQ5/h9J97kpQQrwZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#199번이 198번과 비교했을때 더 크면 stop (과적합 stop)\n",
    "\n",
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "class CustomHistory(tf.keras.callbacks.Callback):   #Callback으로 부터 상속 받은 CustomHistory\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []  # 변수를 만들어줌\n",
    "        self.val_acc = [] \n",
    "    def on_epoch_end(self,batch,logs={}):   #Callback안에 있는 함수 override. 한 epoch끝날때 마다 logs에있는 loss를 train_loss에  apppend,#logs에있는 loss를 val_loss에  apppend\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('accuracy')) \n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        if self.epoch % 10 == 0:  #10으로 나누어지면\n",
    "            print(\"epoch:{}, loss:{},val_loss:{}\".format(self.epoch,logs.get('loss'),logs.get('val_loss')\n",
    "                                                        ))\n",
    "        self.epoch += 1  #epoch 하나씩 늘고 \n",
    "\n",
    "# 1. 데이터 셋 준비하기 \n",
    "# 훈련셋, 검증셋 분리 \n",
    "(X_train, Y_train), (X_test,Y_test) = mnist.load_data() \n",
    "\n",
    "# 훈련셋과 검증셋 분리  (X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]  #50000개부터 끝까지 \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "        \n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32')/255.0    #0부터255너무떨어져있어서 나눠서 normalization ***\n",
    "X_val = X_val.reshape(10000,784).astype('float32')/255.0  # '데이터 784개' 한꺼번에 1차원으로 들어가  *******************************************\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0 \n",
    "        \n",
    "\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴 \n",
    "#1부터50000까지 700개를 random하게 뽑자\n",
    "train_rand_idxs = np.random.choice(50000,700) \n",
    "val_rand_idxs = np.random.choice(10000,300) \n",
    "X_train = X_train[train_rand_idxs]\n",
    "Y_train = Y_train[train_rand_idxs]\n",
    "#300개의 index만 사용\n",
    "X_val = X_val[val_rand_idxs]      #X_val, Y_val이 같아야   \n",
    "Y_val = Y_val[val_rand_idxs]   \n",
    "    \n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "# 0  => 1 0 0 0 0 0 0 0 0 0\n",
    "# 3 => 0 0 0 1 0 0 0 0 0 0 \n",
    "Y_train =  utils.to_categorical(Y_train)    # to_categorical사용하여면 () 안에 변수는 '숫자'여야\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)    \n",
    "\n",
    "#2. 모델 구성하기\n",
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_dim=784, activation=\"relu\"))  #layer output 2개 \n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"sgd\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#4.모델학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping()  # 성급한 조기 종료 *********************************************\n",
    "early_stopping = EarlyStopping(patience=30) #patience인자 수 만큼 Loss가 오를 수 있음. 적절한 조기종료 *********#val_loss 20번 늘어나느 것을 허용**************************\n",
    "hist = model.fit(X_train, Y_train, epochs=1000, batch_size=10, validation_data=(X_val,Y_val), verbose=1,\n",
    "                callbacks=[early_stopping]) # 조기 종료 ****************************************************\n",
    "\n",
    "\n",
    "#5.학습과정 표시하기 \n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y',label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')   #val_loss 검증셋 데이어틔 loss   #200번이 넘어가면서 너무 과적합해서 loss가 높아져. 회귀선과 더 멀어짐\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx()  #x축을 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r', label=\"val accuracy\") # accuracy 저조함. 좋은 model 아님.\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")\n",
    "\n",
    "# graph를 보면 val_loss살짝 올라가는 것 용납못해서 바로 끊어버림  (그러나 이것은 성급한 조기 종료) \n",
    "# ==> 개선:  약간 올라갔다 내려갔다 거릴 수도 있다. 이것까지는 봐주고 끊어버는 것이 좋다. 그 뒤에 또 올라가 그러면 끊어버림  (적절한 조기종료)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patience= 50번  완만하게 올라간다. 그러면 다시  30번으로 줄여. 적절한 조기 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verbose = 1, which includes both progress bar and one line per epoch. \n",
    "#verbose = 0, means silent. \n",
    "#verbose = 2, one line per epoch i.e. epoch no./total no. of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T01:59:15.983544Z",
     "start_time": "2021-03-24T01:59:15.519928Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 894us/step - loss: 1.4560 - accuracy: 0.5006\n",
      "\n",
      "loss_and_metrics: [1.4560354948043823, 0.5005999803543091]\n"
     ]
    }
   ],
   "source": [
    "# 6. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print()\n",
    "print('loss_and_metrics:', loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:03:23.374911Z",
     "start_time": "2021-03-24T02:03:23.361932Z"
    }
   },
   "outputs": [],
   "source": [
    "#7. 모델 사용하기 \n",
    "idx = np.random.choice(X_test.shape[0],5)  #10000개 (X_test.shape[0]) 중  5개만 뽑아라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:07:56.869755Z",
     "start_time": "2021-03-24T02:07:56.852820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xhat = X_test[idx]\n",
    "xhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:23:02.478350Z",
     "start_time": "2021-03-24T02:23:02.430497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.9311994e-05, 2.9810168e-02, 8.1240898e-03, 1.7379250e-01,\n",
       "        1.5859904e-06, 3.8357171e-01, 3.5275989e-05, 2.8906221e-04,\n",
       "        4.0269127e-01, 1.5949660e-03],\n",
       "       [5.2720035e-05, 9.1762738e-03, 5.9487233e-03, 2.3405357e-01,\n",
       "        4.6358974e-08, 3.6953133e-01, 1.1871423e-06, 7.6916192e-05,\n",
       "        3.8082126e-01, 3.3805173e-04],\n",
       "       [8.8899069e-02, 1.7044485e-03, 2.4195345e-01, 2.5306188e-02,\n",
       "        1.5032665e-02, 2.5361225e-02, 6.3052721e-04, 4.1532573e-01,\n",
       "        2.6024336e-02, 1.5976235e-01],\n",
       "       [8.8976383e-01, 7.2064763e-12, 1.0643570e-01, 1.7951272e-03,\n",
       "        1.6439518e-13, 1.7114102e-05, 2.0844842e-18, 1.9729910e-03,\n",
       "        1.4009773e-05, 1.2589932e-06],\n",
       "       [5.3345636e-02, 4.0882155e-03, 1.7948580e-01, 2.1631831e-02,\n",
       "        4.8758999e-02, 2.9018806e-02, 3.4902259e-03, 3.9886746e-01,\n",
       "        3.0199461e-02, 2.3111355e-01]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat= model.predict(xhat) #xhat을 넣으면 결과가 뭐니\n",
    "yhat\n",
    "#0일 확률 8.93e-03   1일 확률 2.98    2일확률 0.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:24:18.008135Z",
     "start_time": "2021-03-24T02:24:17.998187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 0, 7], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(yhat,axis=1) #예측치        # axis=1  열은 고정시키고 행에서 비교  \n",
    "                                      # 1st array안에서 8번째 방의 숫이 가장 크다   2nd array안에서  8번째 방의 숫이 가장 크다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:24:44.785016Z",
     "start_time": "2021-03-24T02:24:44.780055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 7, 0, 6], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(Y_test[idx],axis=1) #실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:25:06.957732Z",
     "start_time": "2021-03-24T02:25:06.946762Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 번째 실제값: 3 \t예측값: 8\n",
      "1 번째 실제값: 5 \t예측값: 8\n",
      "2 번째 실제값: 7 \t예측값: 7\n",
      "3 번째 실제값: 0 \t예측값: 0\n",
      "4 번째 실제값: 6 \t예측값: 7\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i,\"번째 실제값:\",np.argmax(Y_test[idx][i]), #왜 axis=1넣으면 안되는 이유: Y_test[idx] 가 1차원\n",
    "         \"\\t예측값:\",np.argmax(yhat[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:26:40.977562Z",
     "start_time": "2021-03-24T02:26:40.964578Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 위 확인용\n",
    "Y_test[1]        \n",
    "# 확인용 끝             #1차원 배열. 따라서 1차원이기에 np.argmax(Y_test[idx][i]) 뒤에 axis=1를 넣치 않는다. 아니면 에러 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:16:15.242258Z",
     "start_time": "2021-03-24T02:16:15.017328Z"
    }
   },
   "outputs": [],
   "source": [
    "#8. 모델 저장하기\n",
    "model.save('model/mnist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:17:57.552389Z",
     "start_time": "2021-03-24T02:17:57.375513Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, 0, 7], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. 모델 재사용하기 \n",
    "from tensorflow.keras.models import load_model \n",
    "model2 = load_model(\"model/mnist.h5\")\n",
    "model2.predict_classes(xhat) #  predict_classes예측한 결과를 원핫인코딩을 풀어서 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <3> 위 모델(DNN - deep neural network)의 accuracy 늘리기\n",
    "<ol>\n",
    "    <li> 데이터 확보 </li>\n",
    "    <li> 레이어 </li>\n",
    "    <li> 활성화 함수: 은닉층에는 주로 relu, elu,\n",
    "                       맨 마지막 output 층에서는 sigmoid (이진분류), softmax(다중분류)</li>\n",
    "    <li> optimizer, epoch 등을 조정 </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T04:45:57.976643Z",
     "start_time": "2021-03-24T04:20:15.444302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.6608 - accuracy: 0.8221 - val_loss: 0.1913 - val_accuracy: 0.9452\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.1635 - accuracy: 0.9519 - val_loss: 0.1261 - val_accuracy: 0.9646\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.1079 - accuracy: 0.9683 - val_loss: 0.1113 - val_accuracy: 0.9665\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0812 - accuracy: 0.9767 - val_loss: 0.0962 - val_accuracy: 0.9717\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0599 - accuracy: 0.9828 - val_loss: 0.0861 - val_accuracy: 0.9751\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 0.0487 - accuracy: 0.9862 - val_loss: 0.0813 - val_accuracy: 0.9773\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0348 - accuracy: 0.9899 - val_loss: 0.0805 - val_accuracy: 0.9771\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0267 - accuracy: 0.9938 - val_loss: 0.0792 - val_accuracy: 0.9782\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0192 - accuracy: 0.9953 - val_loss: 0.0786 - val_accuracy: 0.9776\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0153 - accuracy: 0.9968 - val_loss: 0.0789 - val_accuracy: 0.9784\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0110 - accuracy: 0.9976 - val_loss: 0.0854 - val_accuracy: 0.9761\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0088 - accuracy: 0.9983 - val_loss: 0.0743 - val_accuracy: 0.9805\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0069 - accuracy: 0.9989 - val_loss: 0.0779 - val_accuracy: 0.9797\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0818 - val_accuracy: 0.9791\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0799 - val_accuracy: 0.9802\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0026 - accuracy: 0.9999 - val_loss: 0.0767 - val_accuracy: 0.9813\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 41s 8ms/step - loss: 0.0020 - accuracy: 0.9999 - val_loss: 0.0783 - val_accuracy: 0.9805\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 40s 8ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0788 - val_accuracy: 0.9807\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0798 - val_accuracy: 0.9805\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0801 - val_accuracy: 0.9813\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0819 - val_accuracy: 0.9810\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 39s 8ms/step - loss: 9.7714e-04 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9803\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 38s 8ms/step - loss: 9.0599e-04 - accuracy: 1.0000 - val_loss: 0.0830 - val_accuracy: 0.9807\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 8.1999e-04 - accuracy: 1.0000 - val_loss: 0.0843 - val_accuracy: 0.9808\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 7.3646e-04 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9813\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 7.3024e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9807\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 6.4267e-04 - accuracy: 1.0000 - val_loss: 0.0848 - val_accuracy: 0.9807\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 6.0576e-04 - accuracy: 1.0000 - val_loss: 0.0855 - val_accuracy: 0.9804\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 5.6423e-04 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 5.3607e-04 - accuracy: 1.0000 - val_loss: 0.0867 - val_accuracy: 0.9812\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 5.0933e-04 - accuracy: 1.0000 - val_loss: 0.0868 - val_accuracy: 0.9810\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 4.7140e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9809\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 4.5910e-04 - accuracy: 1.0000 - val_loss: 0.0874 - val_accuracy: 0.9812\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 4.4376e-04 - accuracy: 1.0000 - val_loss: 0.0877 - val_accuracy: 0.9812\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 4.2045e-04 - accuracy: 1.0000 - val_loss: 0.0883 - val_accuracy: 0.9813\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 3.9156e-04 - accuracy: 1.0000 - val_loss: 0.0894 - val_accuracy: 0.9808\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 3.6445e-04 - accuracy: 1.0000 - val_loss: 0.0889 - val_accuracy: 0.9813\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 3.6925e-04 - accuracy: 1.0000 - val_loss: 0.0895 - val_accuracy: 0.9815\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 3.4828e-04 - accuracy: 1.0000 - val_loss: 0.0901 - val_accuracy: 0.9812\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 35s 7ms/step - loss: 3.2464e-04 - accuracy: 1.0000 - val_loss: 0.0900 - val_accuracy: 0.9807\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 36s 7ms/step - loss: 3.2377e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9810\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 37s 7ms/step - loss: 3.0702e-04 - accuracy: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2b50e6f9160>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#199번이 198번과 비교했을때 더 크면 stop (과적합 stop)\n",
    "\n",
    "import tensorflow as tf\n",
    "np.random.seed(3)\n",
    "class CustomHistory(tf.keras.callbacks.Callback):   #Callback으로 부터 상속 받은 CustomHistory\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_acc = []  # 변수를 만들어줌\n",
    "        self.val_acc = [] \n",
    "    def on_epoch_end(self,batch,logs={}):   #Callback안에 있는 함수 override. 한 epoch끝날때 마다 logs에있는 loss를 train_loss에  apppend,#logs에있는 loss를 val_loss에  apppend\n",
    "        self.train_loss.append(logs.get('loss'))\n",
    "        self.val_loss.append(logs.get('val_loss'))\n",
    "        self.train_acc.append(logs.get('accuracy')) \n",
    "        self.val_acc.append(logs.get('val_accuracy'))\n",
    "        if self.epoch % 10 == 0:  #10으로 나누어지면\n",
    "            print(\"epoch:{}, loss:{},val_loss:{}\".format(self.epoch,logs.get('loss'),logs.get('val_loss')\n",
    "                                                        ))\n",
    "        self.epoch += 1  #epoch 하나씩 늘고 \n",
    "\n",
    "# 1. 데이터 셋 준비하기 \n",
    "# 훈련셋, 검증셋 분리 \n",
    "(X_train, Y_train), (X_test,Y_test) = mnist.load_data() \n",
    "\n",
    "# 훈련셋과 검증셋 분리  (X_train, Y_train을 검증셋과 훈련셋으로 분리)\n",
    "X_val = X_train[50000:]  #50000개부터 끝까지 \n",
    "Y_val = Y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "Y_train = Y_train[:50000]\n",
    "        \n",
    "# normalize 하기 위해 색상값으로 나눠\n",
    "X_train = X_train.reshape(50000,784).astype('float32')/255.0    #0부터255너무떨어져있어서 나눠서 normalization ***\n",
    "X_val = X_val.reshape(10000,784).astype('float32')/255.0  # '데이터 784개' 한꺼번에 1차원으로 들어가  *******************************************\n",
    "X_test = X_test.reshape(10000,784).astype('float32')/255.0 \n",
    "        \n",
    "\n",
    "# 훈련셋과 검증셋 700개, 300개씩만 가져옴 \n",
    "#1부터50000까지 700개를 random하게 뽑자\n",
    "# train_rand_idxs = np.random.choice(50000,700) \n",
    "# val_rand_idxs = np.random.choice(10000,300) \n",
    "# X_train = X_train[train_rand_idxs]\n",
    "# Y_train = Y_train[train_rand_idxs]\n",
    "# #300개의 index만 사용\n",
    "# X_val = X_val[val_rand_idxs]      #X_val, Y_val이 같아야   \n",
    "# Y_val = Y_val[val_rand_idxs]   \n",
    "    \n",
    "    \n",
    "# 원 핫 인코딩 = 라벨링 전환 \n",
    "# 0  => 1 0 0 0 0 0 0 0 0 0\n",
    "# 3 => 0 0 0 1 0 0 0 0 0 0 \n",
    "Y_train =  utils.to_categorical(Y_train)    # to_categorical사용하여면 () 안에 변수는 '숫자'여야\n",
    "Y_val = utils.to_categorical(Y_val)\n",
    "Y_test = utils.to_categorical(Y_test)    \n",
    "\n",
    "#2. 모델 구성하기        *****************************accuracy늘리기 ***********************************\n",
    "model = Sequential()\n",
    "model.add(Dense(units=612, input_dim=784, activation=\"relu\"))  \n",
    "model.add(Dense(units=1300, input_dim=784, activation=\"relu\"))  \n",
    "model.add(Dense(units=258, input_dim=784, activation=\"relu\"))  \n",
    "model.add(Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "#3. 모델 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer = \"sgd\", metrics=['accuracy'])\n",
    "\n",
    "\n",
    "#4.모델학습시키기\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "# early_stopping = EarlyStopping()  # 성급한 조기 종료 \n",
    "early_stopping = EarlyStopping(patience=30) #patience인자 수 만큼 Loss가 오를 수 있음. 적절한 조기종료 *********#val_loss 20번 늘어나느 것을 허용**************************\n",
    "hist = model.fit(X_train, Y_train, epochs=50, batch_size=10, validation_data=(X_val,Y_val), verbose=1,\n",
    "                callbacks=[early_stopping]) # 조기 종료     #batch_size=10은   10개를 1개로봄 \n",
    "\n",
    "#5.학습과정 표시하기 \n",
    "fig, loss_ax = plt.subplots()\n",
    "loss_ax.plot(hist.history['loss'], 'y',label=\"train loss\")\n",
    "loss_ax.plot(hist.history['val_loss'],'g',label='val loss')   #val_loss 검증셋 데이어틔 loss   #200번이 넘어가면서 너무 과적합해서 loss가 높아져. 회귀선과 더 멀어짐\n",
    "loss_ax.set_xlabel(\"epochs\")\n",
    "loss_ax.set_ylabel(\"loss\")\n",
    "\n",
    "acc_ax = loss_ax.twinx()  #x축을 공유하는 acc_ax\n",
    "acc_ax.plot(hist.history['accuracy'],'b', label=\"train accuracy\")\n",
    "acc_ax.plot(hist.history['val_accuracy'],'r', label=\"val accuracy\") # accuracy 저조함. 좋은 model 아님.\n",
    "acc_ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "loss_ax.legend(loc=\"upper left\")\n",
    "acc_ax.legend(loc=\"lower left\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 모델 사용 및 평가\n",
    "idx = np.random.choice(X_test.shape[0],5)\n",
    "xhat= X_test[idx]\n",
    "yhat = model.predict_classes(xhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 모델 평가하기\n",
    "loss_and_metrics = model.evaluate(X_test, Y_test, batch_size=32)\n",
    "print(\"loss:\",loss_and_metrics[0])\n",
    "print(\"accuracy:\",loss_and_metrics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9. 모델 저장\n",
    "model.save('model/mnist_v1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
