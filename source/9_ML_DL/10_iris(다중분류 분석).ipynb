{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:07:09.172634Z",
     "start_time": "2021-03-24T09:07:09.168664Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns      #iris데이터 가져오기 위해\n",
    "import pandas as pd        # 원핫인코딩  # get_dummies()  \n",
    "from sklearn.model_selection import train_test_split  # 훈련셋과 테스트셋 분리 \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:06:01.892866Z",
     "start_time": "2021-03-24T09:06:01.861949Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>setosa</th>\n",
       "      <th>versicolor</th>\n",
       "      <th>virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     setosa  versicolor  virginica\n",
       "0         1           0          0\n",
       "50        0           1          0\n",
       "100       0           0          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. 데이터 셋\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "# display(iris.head(2))\n",
    "iris_X = iris.iloc[:, :-1].to_numpy()\n",
    "iris_Y = iris.iloc[:, -1]\n",
    "# iris_Y = utils.to_categorical(iris_Y) # 숫자가 아니면 to_categorical 불가\n",
    "iris_Y = pd.get_dummies(iris_Y)\n",
    "iris_Y[::50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:17:45.614234Z",
     "start_time": "2021-03-24T09:17:45.599300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((105, 4), (105, 3), (45, 4), (45, 3))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "model_save_folder = './model/'\n",
    "if not os.path.exists(model_save_folder):\n",
    "    os.mkdir(model_save_folder)   # 절대경로\n",
    "file = model_save_folder + 'iris-{epoch:03d}-val{val_accuracy:.4f}.h5'   #001 002 003 이렇게 들어옴\n",
    "\n",
    "early_stopping = EarlyStopping(patience=40)\n",
    "checkpoint = ModelCheckpoint(filepath=file, monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "#1. 데이터 셋\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "#display(iris.head(2))\n",
    "\n",
    "#2. x,y분리\n",
    "#x ==> 앞 4줄 , y==> 맨 마지막 줄\n",
    "iris_X = iris.iloc[:, :-1].to_numpy()\n",
    "iris_Y = iris.iloc[:,-1]\n",
    "iris_Y = pd.get_dummies(iris_Y).to_numpy()   #iris_Y가 숫자가 아니기때문에  .to_categorical()쓸 수 없고, get_dummies()를 쓴다 \n",
    "\n",
    "#3.훈련셋과 테스트셋 분리 \n",
    "# 1 0 0 = setosa /  0 1 0 =>   / \n",
    "train_X, test_X, train_Y, test_Y = train_test_split(iris_X, iris_Y, test_size=0.3, random_state=1)\n",
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:18:31.097229Z",
     "start_time": "2021-03-24T09:18:22.495455Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 1s 178ms/step - loss: 1.3428 - accuracy: 0.2879 - val_loss: 1.1084 - val_accuracy: 0.4762\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.47619, saving model to ./model\\iris-001-val0.4762.h5\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1769 - accuracy: 0.3832 - val_loss: 1.0798 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.47619\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0771 - accuracy: 0.3660 - val_loss: 1.0731 - val_accuracy: 0.2857\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.47619\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9944 - accuracy: 0.4375 - val_loss: 1.0702 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.47619 to 0.52381, saving model to ./model\\iris-004-val0.5238.h5\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9286 - accuracy: 0.7321 - val_loss: 1.0516 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.52381\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8926 - accuracy: 0.7254 - val_loss: 1.0180 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.52381\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8275 - accuracy: 0.7454 - val_loss: 0.9792 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.52381\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7812 - accuracy: 0.7321 - val_loss: 0.9342 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.52381\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7379 - accuracy: 0.7321 - val_loss: 0.8905 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.52381\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7072 - accuracy: 0.7254 - val_loss: 0.8467 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.52381\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6589 - accuracy: 0.7387 - val_loss: 0.8038 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.52381\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6400 - accuracy: 0.7187 - val_loss: 0.7618 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.52381\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5885 - accuracy: 0.7454 - val_loss: 0.7290 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.52381\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5745 - accuracy: 0.7321 - val_loss: 0.6963 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.52381\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5516 - accuracy: 0.7321 - val_loss: 0.6674 - val_accuracy: 0.5238\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.52381\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5085 - accuracy: 0.7454 - val_loss: 0.6421 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.52381 to 0.57143, saving model to ./model\\iris-016-val0.5714.h5\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4905 - accuracy: 0.7454 - val_loss: 0.6212 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.57143\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4780 - accuracy: 0.7321 - val_loss: 0.6046 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.57143\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4581 - accuracy: 0.7467 - val_loss: 0.5955 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.57143\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4507 - accuracy: 0.7467 - val_loss: 0.5922 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.57143\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4159 - accuracy: 0.7587 - val_loss: 0.5859 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.57143\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4282 - accuracy: 0.7333 - val_loss: 0.5706 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.57143\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4068 - accuracy: 0.7467 - val_loss: 0.5563 - val_accuracy: 0.6190\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.57143 to 0.61905, saving model to ./model\\iris-023-val0.6190.h5\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3887 - accuracy: 0.7679 - val_loss: 0.5442 - val_accuracy: 0.6667\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.61905 to 0.66667, saving model to ./model\\iris-024-val0.6667.h5\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3839 - accuracy: 0.7971 - val_loss: 0.5308 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.66667 to 0.71429, saving model to ./model\\iris-025-val0.7143.h5\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3655 - accuracy: 0.8502 - val_loss: 0.5162 - val_accuracy: 0.7143\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.71429\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3791 - accuracy: 0.8514 - val_loss: 0.5021 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.71429 to 0.80952, saving model to ./model\\iris-027-val0.8095.h5\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3636 - accuracy: 0.8740 - val_loss: 0.4939 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.80952\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3608 - accuracy: 0.8806 - val_loss: 0.4888 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.80952\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3408 - accuracy: 0.8806 - val_loss: 0.4818 - val_accuracy: 0.8095\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.80952\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3467 - accuracy: 0.8686 - val_loss: 0.4687 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.80952 to 0.85714, saving model to ./model\\iris-031-val0.8571.h5\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3297 - accuracy: 0.8952 - val_loss: 0.4596 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85714\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3160 - accuracy: 0.9019 - val_loss: 0.4510 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85714\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3214 - accuracy: 0.9044 - val_loss: 0.4410 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85714\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3026 - accuracy: 0.9324 - val_loss: 0.4324 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85714\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.3051 - accuracy: 0.9257 - val_loss: 0.4276 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85714\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2814 - accuracy: 0.9390 - val_loss: 0.4202 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85714\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.2970 - accuracy: 0.9270 - val_loss: 0.4021 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85714\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2830 - accuracy: 0.9483 - val_loss: 0.3920 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.85714 to 0.90476, saving model to ./model\\iris-039-val0.9048.h5\n",
      "Epoch 40/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2699 - accuracy: 0.9762 - val_loss: 0.3876 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90476\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2611 - accuracy: 0.9616 - val_loss: 0.3859 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90476\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2568 - accuracy: 0.9616 - val_loss: 0.3818 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90476\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.2594 - accuracy: 0.9483 - val_loss: 0.3711 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90476\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2657 - accuracy: 0.9562 - val_loss: 0.3550 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90476\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2459 - accuracy: 0.9775 - val_loss: 0.3555 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90476\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.2464 - accuracy: 0.9708 - val_loss: 0.3542 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90476\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2322 - accuracy: 0.9549 - val_loss: 0.3563 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90476\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.2472 - accuracy: 0.9416 - val_loss: 0.3444 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90476\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.2193 - accuracy: 0.9695 - val_loss: 0.3330 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90476\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.2272 - accuracy: 0.9708 - val_loss: 0.3165 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90476\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2116 - accuracy: 0.9841 - val_loss: 0.3069 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90476\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2119 - accuracy: 0.9775 - val_loss: 0.3067 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90476\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.1985 - accuracy: 0.9841 - val_loss: 0.3066 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90476\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.2105 - accuracy: 0.9708 - val_loss: 0.2959 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90476\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2116 - accuracy: 0.9708 - val_loss: 0.2924 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90476\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.2040 - accuracy: 0.9708 - val_loss: 0.2874 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90476\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1793 - accuracy: 0.9841 - val_loss: 0.2878 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90476\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1873 - accuracy: 0.9708 - val_loss: 0.2789 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90476\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1863 - accuracy: 0.9708 - val_loss: 0.2701 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90476\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1790 - accuracy: 0.9708 - val_loss: 0.2625 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90476\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1659 - accuracy: 0.9841 - val_loss: 0.2535 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90476\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.1715 - accuracy: 0.9841 - val_loss: 0.2485 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90476\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.1558 - accuracy: 0.9841 - val_loss: 0.2479 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90476\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1566 - accuracy: 0.9841 - val_loss: 0.2497 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90476\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1443 - accuracy: 0.9775 - val_loss: 0.2461 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90476\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1447 - accuracy: 0.9775 - val_loss: 0.2369 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90476\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1431 - accuracy: 0.9775 - val_loss: 0.2324 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90476\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1486 - accuracy: 0.9775 - val_loss: 0.2270 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90476\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1473 - accuracy: 0.9775 - val_loss: 0.2277 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90476\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1494 - accuracy: 0.9708 - val_loss: 0.2228 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90476\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1405 - accuracy: 0.9708 - val_loss: 0.2226 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90476\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1424 - accuracy: 0.9708 - val_loss: 0.2303 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90476\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1376 - accuracy: 0.9708 - val_loss: 0.2279 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90476\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1260 - accuracy: 0.9775 - val_loss: 0.2160 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90476\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1268 - accuracy: 0.9775 - val_loss: 0.2078 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90476\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1229 - accuracy: 0.9775 - val_loss: 0.2027 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90476\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1207 - accuracy: 0.9775 - val_loss: 0.1993 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90476\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1128 - accuracy: 0.9775 - val_loss: 0.2034 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90476\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1195 - accuracy: 0.9775 - val_loss: 0.2144 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90476\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1205 - accuracy: 0.9708 - val_loss: 0.2090 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90476\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1146 - accuracy: 0.9775 - val_loss: 0.2010 - val_accuracy: 0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90476\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1098 - accuracy: 0.9775 - val_loss: 0.1914 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90476\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1047 - accuracy: 0.9854 - val_loss: 0.1863 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90476\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1015 - accuracy: 0.9775 - val_loss: 0.1940 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90476\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.1022 - accuracy: 0.9775 - val_loss: 0.2012 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90476\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1114 - accuracy: 0.9775 - val_loss: 0.1958 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90476\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1125 - accuracy: 0.9708 - val_loss: 0.1812 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90476\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1035 - accuracy: 0.9854 - val_loss: 0.1764 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90476\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0951 - accuracy: 0.9921 - val_loss: 0.1834 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90476\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.1023 - accuracy: 0.9708 - val_loss: 0.1884 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90476\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0966 - accuracy: 0.9775 - val_loss: 0.2026 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90476\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.1108 - accuracy: 0.9708 - val_loss: 0.1892 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90476\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0896 - accuracy: 0.9775 - val_loss: 0.1792 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90476\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0998 - accuracy: 0.9775 - val_loss: 0.1695 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90476\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.1064 - accuracy: 0.9854 - val_loss: 0.1680 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90476\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0980 - accuracy: 0.9775 - val_loss: 0.1771 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90476\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0783 - accuracy: 0.9841 - val_loss: 0.1826 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.90476\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0769 - accuracy: 0.9775 - val_loss: 0.1689 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.90476\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0893 - accuracy: 0.9854 - val_loss: 0.1611 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.90476\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0941 - accuracy: 0.9854 - val_loss: 0.1595 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.90476\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0863 - accuracy: 0.9854 - val_loss: 0.1689 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.90476\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0801 - accuracy: 0.9775 - val_loss: 0.1864 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.90476\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.0775 - accuracy: 0.9775 - val_loss: 0.1792 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.90476\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0885 - accuracy: 0.9775 - val_loss: 0.1593 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.90476\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0698 - accuracy: 0.9921 - val_loss: 0.1544 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.90476\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0846 - accuracy: 0.9921 - val_loss: 0.1566 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.90476\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0684 - accuracy: 0.9921 - val_loss: 0.1559 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.90476\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0729 - accuracy: 0.9921 - val_loss: 0.1676 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.90476\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0809 - accuracy: 0.9708 - val_loss: 0.1721 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.90476\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0833 - accuracy: 0.9775 - val_loss: 0.1742 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.90476\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0671 - accuracy: 0.9775 - val_loss: 0.1626 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.90476\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0852 - accuracy: 0.9708 - val_loss: 0.1547 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.90476\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0802 - accuracy: 0.9854 - val_loss: 0.1543 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.90476\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0760 - accuracy: 0.9854 - val_loss: 0.1618 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.90476\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0709 - accuracy: 0.9841 - val_loss: 0.1758 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.90476\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0805 - accuracy: 0.9775 - val_loss: 0.1598 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.90476\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0788 - accuracy: 0.9854 - val_loss: 0.1519 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.90476\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0811 - accuracy: 0.9854 - val_loss: 0.1516 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.90476\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0806 - accuracy: 0.9854 - val_loss: 0.1639 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.90476\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0831 - accuracy: 0.9775 - val_loss: 0.1829 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.90476\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0899 - accuracy: 0.9708 - val_loss: 0.1651 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.90476\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0618 - accuracy: 0.9841 - val_loss: 0.1541 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.90476\n",
      "Epoch 123/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0750 - accuracy: 0.9854 - val_loss: 0.1484 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.90476\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.0843 - accuracy: 0.9854 - val_loss: 0.1534 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.90476\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0725 - accuracy: 0.9775 - val_loss: 0.1624 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.90476\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0819 - accuracy: 0.9708 - val_loss: 0.1689 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.90476\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0805 - accuracy: 0.9775 - val_loss: 0.1632 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.90476\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0770 - accuracy: 0.9775 - val_loss: 0.1504 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.90476\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0746 - accuracy: 0.9854 - val_loss: 0.1473 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.90476\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0645 - accuracy: 0.9921 - val_loss: 0.1502 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.90476\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0739 - accuracy: 0.9775 - val_loss: 0.1555 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.90476\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0822 - accuracy: 0.9708 - val_loss: 0.1596 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.90476\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.1584 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.90476\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0568 - accuracy: 0.9841 - val_loss: 0.1538 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.90476\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0731 - accuracy: 0.9854 - val_loss: 0.1463 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.90476\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0577 - accuracy: 0.9921 - val_loss: 0.1464 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.90476\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0732 - accuracy: 0.9854 - val_loss: 0.1484 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.90476\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0710 - accuracy: 0.9775 - val_loss: 0.1563 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.90476\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0634 - accuracy: 0.9775 - val_loss: 0.1639 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.90476\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0803 - accuracy: 0.9708 - val_loss: 0.1537 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.90476\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0754 - accuracy: 0.9775 - val_loss: 0.1482 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.90476\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0659 - accuracy: 0.9921 - val_loss: 0.1469 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.90476\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0769 - accuracy: 0.9854 - val_loss: 0.1456 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.90476\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0710 - accuracy: 0.9921 - val_loss: 0.1551 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.90476\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0631 - accuracy: 0.9775 - val_loss: 0.1566 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.90476\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0797 - accuracy: 0.9708 - val_loss: 0.1484 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.90476\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0560 - accuracy: 0.9841 - val_loss: 0.1475 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.90476\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0793 - accuracy: 0.9854 - val_loss: 0.1460 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.90476\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0524 - accuracy: 0.9921 - val_loss: 0.1470 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.90476\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0742 - accuracy: 0.9854 - val_loss: 0.1483 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.90476\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0677 - accuracy: 0.9775 - val_loss: 0.1552 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.90476\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0718 - accuracy: 0.9775 - val_loss: 0.1608 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.90476\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0811 - accuracy: 0.9708 - val_loss: 0.1509 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.90476\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.1472 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.90476\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.0593 - accuracy: 0.9921 - val_loss: 0.1457 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.90476\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0543 - accuracy: 0.9921 - val_loss: 0.1458 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.90476\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0565 - accuracy: 0.9921 - val_loss: 0.1461 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.90476\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0656 - accuracy: 0.9854 - val_loss: 0.1484 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.90476\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0564 - accuracy: 0.9841 - val_loss: 0.1610 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.90476\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0567 - accuracy: 0.9841 - val_loss: 0.1559 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.90476\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0553 - accuracy: 0.9775 - val_loss: 0.1454 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.90476\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0782 - accuracy: 0.9854 - val_loss: 0.1475 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.90476\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0674 - accuracy: 0.9921 - val_loss: 0.1466 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.90476\n",
      "Epoch 164/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0532 - accuracy: 0.9921 - val_loss: 0.1521 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.90476\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0742 - accuracy: 0.9708 - val_loss: 0.1548 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.90476\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0533 - accuracy: 0.9841 - val_loss: 0.1537 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.90476\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0599 - accuracy: 0.9775 - val_loss: 0.1459 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.90476\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0768 - accuracy: 0.9854 - val_loss: 0.1484 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.90476\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0773 - accuracy: 0.9854 - val_loss: 0.1458 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.90476\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0632 - accuracy: 0.9921 - val_loss: 0.1554 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.90476\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0569 - accuracy: 0.9775 - val_loss: 0.1633 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.90476\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0583 - accuracy: 0.9775 - val_loss: 0.1527 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.90476\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0750 - accuracy: 0.9708 - val_loss: 0.1459 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.90476\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0735 - accuracy: 0.9854 - val_loss: 0.1464 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.90476\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0707 - accuracy: 0.9854 - val_loss: 0.1485 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.90476\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0660 - accuracy: 0.9775 - val_loss: 0.1624 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.90476\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0573 - accuracy: 0.9775 - val_loss: 0.1656 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.90476\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0555 - accuracy: 0.9775 - val_loss: 0.1521 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.90476\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0747 - accuracy: 0.9708 - val_loss: 0.1466 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.90476\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0513 - accuracy: 0.9921 - val_loss: 0.1473 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.90476\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0650 - accuracy: 0.9854 - val_loss: 0.1465 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.90476\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0663 - accuracy: 0.9775 - val_loss: 0.1523 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.90476\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0718 - accuracy: 0.9708 - val_loss: 0.1582 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.90476\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0562 - accuracy: 0.9775 - val_loss: 0.1599 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.90476\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0565 - accuracy: 0.9775 - val_loss: 0.1499 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.90476\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0566 - accuracy: 0.9775 - val_loss: 0.1470 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.90476\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0538 - accuracy: 0.9921 - val_loss: 0.1494 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.90476\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0760 - accuracy: 0.9854 - val_loss: 0.1499 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.90476\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0648 - accuracy: 0.9854 - val_loss: 0.1475 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.90476\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0523 - accuracy: 0.9841 - val_loss: 0.1580 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.90476\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0543 - accuracy: 0.9841 - val_loss: 0.1560 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.90476\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0751 - accuracy: 0.9708 - val_loss: 0.1478 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.90476\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.0482 - accuracy: 0.9921 - val_loss: 0.1498 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.90476\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0600 - accuracy: 0.9921 - val_loss: 0.1477 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.90476\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0583 - accuracy: 0.9921 - val_loss: 0.1478 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.90476\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0560 - accuracy: 0.9921 - val_loss: 0.1480 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.90476\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0586 - accuracy: 0.9921 - val_loss: 0.1482 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.90476\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0487 - accuracy: 0.9921 - val_loss: 0.1481 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.90476\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.0578 - accuracy: 0.9921 - val_loss: 0.1486 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.90476\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0643 - accuracy: 0.9854 - val_loss: 0.1494 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.90476\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.0656 - accuracy: 0.9854 - val_loss: 0.1486 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.90476\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Dense(64, input_dim=4, activation=\"relu\"))   #입력 4개   #2의 승수를 좋아함 예:64. 그러나 60를 넣어도 상관없음\n",
    "model.add(Dense(50,activation=\"relu\"))\n",
    "model.add(Dense(30,activation=\"relu\"))\n",
    "model.add(Dense(3,activation=\"softmax\"))\n",
    "\n",
    "#3. 학습과정 설정\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "#4. 학습시키기\n",
    "\n",
    "hist = model.fit(train_X,train_Y,batch_size=50, epochs=300, validation_split=0.2, callbacks=[early_stopping, checkpoint]) #좋아 데이터만 것만 저장\n",
    "\n",
    "\n",
    "# 5. 모델 학습 과정 표시하기\n",
    "# 모델 학습 과정 표시하기\n",
    "fig, loss_ax = plt.subplots()\n",
    "\n",
    "loss_ax.plot(fit_hist.history['loss'],'y', label='train loss')\n",
    "loss_ax.plot(fit_hist.history['val_loss'],'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax = loss_ax.twinx()\n",
    "acc_ax.plot(fit_hist.history['accuracy'],'b', label='train acc')\n",
    "acc_ax.plot(fit_hist.history['val_accuracy'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:07:13.047467Z",
     "start_time": "2021-03-24T09:07:13.039470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 \n",
    "real = np.argmax(test_Y,axis=1) #실제값\n",
    "real "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:07:15.084781Z",
     "start_time": "2021-03-24T09:07:15.078797Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 2, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측\n",
    "real = np.argmax(test_Y, axis=1) # 실제값\n",
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:08:27.103482Z",
     "start_time": "2021-03-24T09:08:26.986309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tjoeun\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 2, 0, 0, 2, 1, 0, 2, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 2, 1, 0, 0, 1, 2, 1, 2, 1, 2, 2, 0, 1, 0, 1, 2, 2, 0, 2, 2,\n",
       "       1], dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict_classes(test_X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:08:28.663337Z",
     "start_time": "2021-03-24T09:08:28.654360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(pred==real) #0끼리 같고, 1끼리 같고, 2끼리 같고 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:08:35.481706Z",
     "start_time": "2021-03-24T09:08:35.440666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>real</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred   0   1   2\n",
       "real            \n",
       "0     14   0   0\n",
       "1      0  18   0\n",
       "2      0   1  12"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_result = pd.crosstab(real,pred)\n",
    "ct_result.index.name =\"real\"\n",
    "ct_result.columns.name = \"pred\"\n",
    "ct_result   #real data1인데 predict한것 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:06:15.267785Z",
     "start_time": "2021-03-24T09:05:58.172Z"
    }
   },
   "outputs": [],
   "source": [
    "# 평가\n",
    "score = model.evaluate(test_X,test_Y,batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:06:15.269779Z",
     "start_time": "2021-03-24T09:05:58.174Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"평가된 loss:\", score[0])\n",
    "print(\"평가된 accuracy:\", score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:06:15.270777Z",
     "start_time": "2021-03-24T09:05:58.176Z"
    }
   },
   "outputs": [],
   "source": [
    "iris.iloc[51]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T09:06:15.271774Z",
     "start_time": "2021-03-24T09:05:58.178Z"
    }
   },
   "outputs": [],
   "source": [
    "#확인용\n",
    "np.argmax(  model.predict_classes(np.array([  [ 6.4, 3.2, 4.5, 1.5  ] ]))  )\n",
    "# 1이 출력됨. versicolor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
